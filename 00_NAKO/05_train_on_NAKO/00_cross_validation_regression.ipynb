{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import statsmodels as sm\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Scikeras wrapper for Keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# (Hypothetical) TabPFN Regressor\n",
    "# If the TabPFN package does not provide a regressor, remove or replace this import\n",
    "from tabpfn import TabPFNRegressor  # Placeholder for a potential TabPFNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# MLP Model Definition\n",
    "###############################################################################\n",
    "def create_mlp_model(input_shape):\n",
    "    \"\"\"\n",
    "    Create a simple MLP model for regression.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(1024, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        # Final layer for regression: linear activation, 1 output\n",
    "        Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "###############################################################################\n",
    "# CUDA / Memory Cleanup\n",
    "###############################################################################\n",
    "def clean_up_cuda(model):\n",
    "    \"\"\"\n",
    "    Free up GPU memory and clear Keras session.\n",
    "    \"\"\"\n",
    "    # Delete the Keras model\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    \n",
    "    # Run garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Free CUDA memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    \n",
    "    print(\"CUDA memory cleared and model deleted.\")\n",
    "\n",
    "###############################################################################\n",
    "# Regression Metrics & Aggregation\n",
    "###############################################################################\n",
    "def evaluate_regression_performance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute regression metrics for predictions.\n",
    "    Returns a dictionary with MSE, MAE, and R2.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    results = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    return results\n",
    "\n",
    "def print_regression_performance(results):\n",
    "    \"\"\"\n",
    "    Print regression performance metrics nicely.\n",
    "    \"\"\"\n",
    "    print(f\"MSE: {results['mse']:.4f}\")\n",
    "    print(f\"MAE: {results['mae']:.4f}\")\n",
    "    print(f\"R²:  {results['r2']:.4f}\")\n",
    "\n",
    "def aggregate_cv_metrics_and_print(all_results, model_name, tag=\"Validation\"):\n",
    "    \"\"\"\n",
    "    Aggregate cross-validation metrics (MSE, MAE, R2)\n",
    "    and return mean + std across folds.\n",
    "    \"\"\"\n",
    "    aggregated = {\n",
    "        'mse': [],\n",
    "        'mae': [],\n",
    "        'r2': []\n",
    "    }\n",
    "    \n",
    "    for result in all_results:\n",
    "        aggregated['mse'].append(result['mse'])\n",
    "        aggregated['mae'].append(result['mae'])\n",
    "        aggregated['r2'].append(result['r2'])\n",
    "        \n",
    "    summary = {\n",
    "        'mean_mse':  np.mean(aggregated['mse']),\n",
    "        'std_mse':   np.std(aggregated['mse']),\n",
    "        'mean_mae':  np.mean(aggregated['mae']),\n",
    "        'std_mae':   np.std(aggregated['mae']),\n",
    "        'mean_r2':   np.mean(aggregated['r2']),\n",
    "        'std_r2':    np.std(aggregated['r2']),\n",
    "    }\n",
    "    print(f\"\\n {model_name} Classifier Performance {tag}:\")\n",
    "    print_cv_summary(summary)\n",
    "    return summary\n",
    "\n",
    "def print_cv_summary(summary):\n",
    "    \"\"\"\n",
    "    Print the aggregated CV summary (MSE, MAE, R²).\n",
    "    \"\"\"\n",
    "    print(f\"Mean MSE:  {summary['mean_mse']:.4f} ± {summary['std_mse']:.4f}\")\n",
    "    print(f\"Mean MAE:  {summary['mean_mae']:.4f} ± {summary['std_mae']:.4f}\")\n",
    "    print(f\"Mean R²:   {summary['mean_r2']:.4f} ± {summary['std_r2']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aparc.thickness_aseg.volume_aparc.volume.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages_all_ids_healthy.csv\")\n",
    "n_splits = 5\n",
    "\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "df_sampled, _ = train_test_split(merged_df, train_size=10000, stratify=merged_df[\"label_age_group\"], random_state=42)\n",
    "df_sampled[\"label_Age\"].value_counts()\n",
    "\n",
    "y = df_sampled[\"label_Age\"]\n",
    "col_to_drop = [col for col in label_df.columns]\n",
    "X = df_sampled.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_age_group\n",
       "2.0    4655\n",
       "3.0    4323\n",
       "4.0    3265\n",
       "1.0    1786\n",
       "0.0    1621\n",
       "5.0     234\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df[\"label_age_group\"].value_counts().sort_values(ascending=False)\n",
    "\n",
    "merged_df[\"label_age_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_age_group\n",
      "3.0    2953\n",
      "2.0    2953\n",
      "4.0    2953\n",
      "1.0    1786\n",
      "0.0    1621\n",
      "5.0     234\n",
      "Name: count, dtype: int64\n",
      "Total samples: 12500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Get class distribution\n",
    "class_counts = merged_df[\"label_age_group\"].value_counts()\n",
    "\n",
    "# Step 1: Retain all samples from the 3 smallest classes\n",
    "smallest_classes = class_counts.nsmallest(3).index\n",
    "df_smallest = merged_df[merged_df[\"label_age_group\"].isin(smallest_classes)]\n",
    "\n",
    "# Step 2: Calculate remaining samples needed to reach 10,000\n",
    "remaining_size = 12500- len(df_smallest)\n",
    "\n",
    "# Step 3: Select the remaining larger classes\n",
    "remaining_classes = class_counts.nlargest(len(class_counts) - 3).index\n",
    "df_remaining = merged_df[merged_df[\"label_age_group\"].isin(remaining_classes)]\n",
    "\n",
    "# Step 4: Determine the number of samples to take per remaining class proportionally\n",
    "samples_per_class = remaining_size // len(remaining_classes)\n",
    "\n",
    "# Downsample the remaining classes to fill the dataset\n",
    "balanced_majority = df_remaining.groupby(\"label_age_group\").apply(\n",
    "    lambda x: x.sample(n=min(len(x), samples_per_class), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Combine both parts to form the final balanced dataset\n",
    "balanced_df = pd.concat([df_smallest, balanced_majority])\n",
    "\n",
    "# Verify the final class distribution\n",
    "print(balanced_df[\"label_age_group\"].value_counts())\n",
    "print(\"Total samples:\", len(balanced_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'Sex', 'label_Age', 'Site', 'label_age_group']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_Age\n",
       "23.00    30\n",
       "25.00    28\n",
       "21.00    28\n",
       "22.00    23\n",
       "24.00    17\n",
       "40.00    13\n",
       "26.00    13\n",
       "20.75    13\n",
       "32.00    11\n",
       "48.00    11\n",
       "21.75    11\n",
       "20.25    11\n",
       "20.50    11\n",
       "29.00    11\n",
       "24.25    10\n",
       "22.75    10\n",
       "22.50    10\n",
       "22.25    10\n",
       "49.00     9\n",
       "23.75     9\n",
       "37.00     9\n",
       "19.75     8\n",
       "21.50     8\n",
       "47.00     8\n",
       "19.00     8\n",
       "23.25     8\n",
       "24.75     7\n",
       "30.00     7\n",
       "31.00     7\n",
       "43.00     7\n",
       "50.00     7\n",
       "41.00     7\n",
       "23.50     6\n",
       "36.00     6\n",
       "21.25     6\n",
       "45.00     6\n",
       "27.00     6\n",
       "33.00     6\n",
       "42.00     6\n",
       "20.00     6\n",
       "46.00     5\n",
       "38.00     5\n",
       "28.00     5\n",
       "19.25     5\n",
       "39.00     4\n",
       "44.00     4\n",
       "35.00     3\n",
       "34.00     3\n",
       "25.50     3\n",
       "18.25     3\n",
       "18.75     3\n",
       "19.50     2\n",
       "25.25     2\n",
       "24.50     2\n",
       "25.75     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/final_folder/aparc.thickness_aparc.volume_aseg.volume.csv\")\n",
    "label_df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/final_folder/aparc.thickness_aparc.volume_aseg.volume_label.csv\")\n",
    "\n",
    "label_df_control = label_df_control[['ID', 'label_Age']]\n",
    "df_control = df_control[df.columns]\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X_control = merged_df_control.drop([\"ID\", \"label_Age\"], axis=1)\n",
    "y_control = merged_df_control[\"label_Age\"]\n",
    "\n",
    "merged_df_control[\"label_Age\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "478 478\n",
      "192 192\n"
     ]
    }
   ],
   "source": [
    "#check len of X and y\n",
    "print(len(X), len(y))\n",
    "print(len(X_control), len(y_control))\n",
    "#columns number\n",
    "print(X.shape[1], X_control.shape[1])\n",
    "\n",
    "for col in X.columns:\n",
    "    if col not in X_control.columns:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_with_Pearson(X, X_val, X_control, y, threshold=0.6):\n",
    "    correlation_matrix = X.corr().abs()\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X = X.drop(columns=to_drop)\n",
    "    X_val = X_val.drop(columns=to_drop)\n",
    "    X_control = X_control.drop(columns=to_drop)\n",
    "    return X, X_val, X_control\n",
    "\n",
    "def feature_extration_with_PCA(X, X_val, X_control, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    X_control_pca = pca.transform(X_control)\n",
    "    return X_pca, X_val_pca, X_control_pca\n",
    "\n",
    "def feature_extration_with_BE(X, X_val, X_control, y, significance_level=0.05):\n",
    "    # Add constant for intercept\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    while True:\n",
    "        # Fit the OLS model\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Get the p-values for each feature\n",
    "        p_values = model.pvalues\n",
    "        \n",
    "        # Find the feature with the highest p-value\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value > significance_level:\n",
    "            # Remove the feature with the highest p-value\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            print(f\"Removing {feature_to_remove} with p-value {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "            X_val = X_val.drop(columns=[feature_to_remove])\n",
    "            X_control = X_control.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Return the final selected feature set (excluding the intercept)\n",
    "    return X.drop(columns=['const']), X_val.drop(columns=['const']), X_control.drop(columns=['const'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 308.2916\n",
      "MAE: 14.2036\n",
      "R²:  -0.9598\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 64.5651\n",
      "MAE: 6.2332\n",
      "R²:  0.5896\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MLP Performance on Control:\n",
      "MSE: 475.5439\n",
      "MAE: 19.8767\n",
      "R²:  -4.9137\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "TabPFN Regressor Performance on Validation:\n",
      "MSE: 43.9305\n",
      "MAE: 5.1934\n",
      "R²:  0.7207\n",
      "TabPFN Regressor Performance on Control:\n",
      "MSE: 482.1966\n",
      "MAE: 20.3210\n",
      "R²:  -4.9964\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 48.651500\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 52.2136\n",
      "MAE: 5.7855\n",
      "R²:  0.6681\n",
      "LightGBM Performance on Control:\n",
      "MSE: 487.6876\n",
      "MAE: 20.6497\n",
      "R²:  -5.0647\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "=== Fold 2 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 308.6062\n",
      "MAE: 14.1670\n",
      "R²:  -1.0275\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 57.7125\n",
      "MAE: 6.0419\n",
      "R²:  0.6208\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MLP Performance on Control:\n",
      "MSE: 464.9082\n",
      "MAE: 19.6677\n",
      "R²:  -4.7814\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "TabPFN Regressor Performance on Validation:\n",
      "MSE: 41.9809\n",
      "MAE: 5.0714\n",
      "R²:  0.7242\n",
      "TabPFN Regressor Performance on Control:\n",
      "MSE: 493.0909\n",
      "MAE: 20.5501\n",
      "R²:  -5.1319\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002000 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 48.721750\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 50.9612\n",
      "MAE: 5.6857\n",
      "R²:  0.6652\n",
      "LightGBM Performance on Control:\n",
      "MSE: 493.0637\n",
      "MAE: 20.6923\n",
      "R²:  -5.1316\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "=== Fold 3 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 297.6692\n",
      "MAE: 13.8970\n",
      "R²:  -0.9945\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 62.6267\n",
      "MAE: 6.3418\n",
      "R²:  0.5804\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "MLP Performance on Control:\n",
      "MSE: 376.2916\n",
      "MAE: 17.7047\n",
      "R²:  -3.6794\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "TabPFN Regressor Performance on Validation:\n",
      "MSE: 42.3383\n",
      "MAE: 5.1105\n",
      "R²:  0.7163\n",
      "TabPFN Regressor Performance on Control:\n",
      "MSE: 478.7853\n",
      "MAE: 20.2676\n",
      "R²:  -4.9540\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001892 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 48.576125\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 51.6032\n",
      "MAE: 5.7359\n",
      "R²:  0.6542\n",
      "LightGBM Performance on Control:\n",
      "MSE: 490.0241\n",
      "MAE: 20.6459\n",
      "R²:  -5.0938\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "=== Fold 4 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 313.0782\n",
      "MAE: 14.1977\n",
      "R²:  -1.0528\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 62.1215\n",
      "MAE: 6.2275\n",
      "R²:  0.5927\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MLP Performance on Control:\n",
      "MSE: 433.6283\n",
      "MAE: 18.9139\n",
      "R²:  -4.3924\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "TabPFN Regressor Performance on Validation:\n",
      "MSE: 43.8510\n",
      "MAE: 5.1842\n",
      "R²:  0.7125\n",
      "TabPFN Regressor Performance on Control:\n",
      "MSE: 489.9396\n",
      "MAE: 20.4447\n",
      "R²:  -5.0927\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001882 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 48.690250\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 52.5472\n",
      "MAE: 5.7212\n",
      "R²:  0.6555\n",
      "LightGBM Performance on Control:\n",
      "MSE: 486.4264\n",
      "MAE: 20.5366\n",
      "R²:  -5.0490\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "=== Fold 5 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 302.9806\n",
      "MAE: 13.9655\n",
      "R²:  -0.9490\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 60.8794\n",
      "MAE: 6.2130\n",
      "R²:  0.6084\n",
      "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n",
      "MLP Performance on Control:\n",
      "MSE: 460.9485\n",
      "MAE: 19.7469\n",
      "R²:  -4.7322\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      "TabPFN Regressor Performance on Validation:\n",
      "MSE: 46.3543\n",
      "MAE: 5.3189\n",
      "R²:  0.7018\n",
      "TabPFN Regressor Performance on Control:\n",
      "MSE: 479.7013\n",
      "MAE: 20.2849\n",
      "R²:  -4.9654\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001860 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12750\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 50\n",
      "[LightGBM] [Info] Start training from score 48.690375\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 54.2111\n",
      "MAE: 5.8500\n",
      "R²:  0.6513\n",
      "LightGBM Performance on Control:\n",
      "MSE: 488.9671\n",
      "MAE: 20.6211\n",
      "R²:  -5.0806\n",
      "CUDA memory cleared and model deleted.\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# K-Fold Cross-Validation Setup\n",
    "###############################################################################\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Training & Evaluation\n",
    "###############################################################################\n",
    "mlp_results = []\n",
    "lgb_results = []\n",
    "tabpfn_results = []\n",
    "random_results = []\n",
    "\n",
    "mlp_results_eval = []\n",
    "lgb_results_eval = []\n",
    "tabpfn_results_eval = []\n",
    "result_dict = {}\n",
    "\n",
    "model_dict = {}\n",
    "best_mse_mlp = float('inf')\n",
    "best_mse_lgb = float('inf')\n",
    "best_mse_tab = float('inf')\n",
    "deconfounding_strategies = [\"PCA\", \"BE\", \"Correlation\", \"Nothing\"]\n",
    "for deconfounding_strategy in deconfounding_strategies:\n",
    "    print(f\"\\n=== Deconfounding Strategy: {deconfounding_strategy} ===\")\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled   = scaler.transform(X_val)\n",
    "        X_control_scaled = scaler.fit_transform(X_control)\n",
    "\n",
    "        if deconfounding_strategy == \"BE\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled = feature_extration_with_BE(X_train_scaled, X_val_scaled, X_control_scaled, y_train)\n",
    "        elif deconfounding_strategy == \"PCA\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled= feature_extration_with_PCA(X_train_scaled, X_val_scaled, X_control_scaled,  n_components=50)\n",
    "        elif deconfounding_strategy == \"Correlation\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled = feature_extraction_with_Pearson(X_train_scaled, X_val_scaled, X_control_scaled, y_train, threshold=0.6)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Random Baseline\n",
    "        # -------------------------------\n",
    "        # We'll generate random predictions from a normal distribution \n",
    "        # matching the train target's mean and std\n",
    "        random_predictions = np.random.normal(loc=y_train.mean(), scale=y_train.std(), size=len(y_val))\n",
    "        random_perf = evaluate_regression_performance(y_val, random_predictions)\n",
    "        print(\"Random Baseline Performance:\")\n",
    "        print_regression_performance(random_perf)\n",
    "        random_results.append(random_perf)\n",
    "        \n",
    "        # -------------------------------\n",
    "        # MLP\n",
    "        # -------------------------------\n",
    "        # KerasRegressor or direct model\n",
    "        mlp_model = create_mlp_model(input_shape=X_train_scaled.shape[1])\n",
    "        mlp_model.fit(X_train_scaled, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32,\n",
    "                    verbose=0)\n",
    "        \n",
    "        y_pred_mlp = mlp_model.predict(X_val_scaled).ravel()  # ensure shape (n,)\n",
    "        mlp_perf = evaluate_regression_performance(y_val, y_pred_mlp)\n",
    "        print(\"\\nMLP Performance on Validation:\")\n",
    "        print_regression_performance(mlp_perf)\n",
    "        mlp_results.append(mlp_perf)\n",
    "        \n",
    "        # Evaluate on control data\n",
    "        y_pred_mlp_ctrl = mlp_model.predict(X_control_scaled).ravel()\n",
    "        mlp_perf_ctrl = evaluate_regression_performance(y_control, y_pred_mlp_ctrl)\n",
    "        print(\"MLP Performance on Control:\")\n",
    "        print_regression_performance(mlp_perf_ctrl)\n",
    "        mlp_results_eval.append(mlp_perf_ctrl)\n",
    "        \n",
    "        # Keep best MLP model based on MSE\n",
    "        if mlp_perf['mse'] < best_mse_mlp:\n",
    "            best_mse_mlp = mlp_perf['mse']\n",
    "            model_dict[\"mlp\"] = mlp_model\n",
    "        \n",
    "        # Clean up\n",
    "        clean_up_cuda(mlp_model)\n",
    "\n",
    "        # -------------------------------\n",
    "        # (Hypothetical) TabPFN Regressor\n",
    "        # -------------------------------\n",
    "        # NOTE: If TabPFNClassifier is the only option, you must skip or replace this.\n",
    "        try:\n",
    "            tabclf = TabPFNRegressor()  # Ideally TabPFNRegressor() if available\n",
    "            tabclf.fit(X_train_scaled, y_train)\n",
    "            y_pred_tab = tabclf.predict(X_val_scaled)  # For regression, this should be continuous\n",
    "            tab_perf = evaluate_regression_performance(y_val, y_pred_tab)\n",
    "            print(\"\\nTabPFN Regressor Performance on Validation:\")\n",
    "            print_regression_performance(tab_perf)\n",
    "            tabpfn_results.append(tab_perf)\n",
    "            \n",
    "            # Evaluate on control data\n",
    "            y_pred_tab_ctrl = tabclf.predict(X_control_scaled)\n",
    "            tab_perf_ctrl = evaluate_regression_performance(y_control, y_pred_tab_ctrl)\n",
    "            print(\"TabPFN Regressor Performance on Control:\")\n",
    "            print_regression_performance(tab_perf_ctrl)\n",
    "            tabpfn_results_eval.append(tab_perf_ctrl)\n",
    "            \n",
    "            if tab_perf['mse'] < best_mse_tab:\n",
    "                best_mse_tab = tab_perf['mse']\n",
    "                model_dict[\"tabpfn\"] = tabclf\n",
    "            \n",
    "            clean_up_cuda(tabclf)\n",
    "        except Exception as e:\n",
    "            print(\"TabPFN Regressor not available or failed. Skipping...\")\n",
    "            print(e)\n",
    "        \n",
    "        # -------------------------------\n",
    "        # LightGBM\n",
    "        # -------------------------------\n",
    "        lgb_train = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "        lgb_eval  = lgb.Dataset(X_val_scaled,   label=y_val, reference=lgb_train)\n",
    "        \n",
    "        lgb_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        lgbclf = lgb.train(\n",
    "            params=lgb_params, \n",
    "            train_set=lgb_train, \n",
    "            valid_sets=[lgb_train, lgb_eval], \n",
    "            num_boost_round=1000\n",
    "        )\n",
    "        \n",
    "        y_pred_lgb = lgbclf.predict(X_val_scaled)\n",
    "        lgb_perf = evaluate_regression_performance(y_val, y_pred_lgb)\n",
    "        print(\"\\nLightGBM Performance on Validation:\")\n",
    "        print_regression_performance(lgb_perf)\n",
    "        lgb_results.append(lgb_perf)\n",
    "        \n",
    "        # Evaluate on control data\n",
    "        y_pred_lgb_ctrl = lgbclf.predict(X_control_scaled)\n",
    "        lgb_perf_ctrl = evaluate_regression_performance(y_control, y_pred_lgb_ctrl)\n",
    "        print(\"LightGBM Performance on Control:\")\n",
    "        print_regression_performance(lgb_perf_ctrl)\n",
    "        lgb_results_eval.append(lgb_perf_ctrl)\n",
    "        \n",
    "        if lgb_perf['mse'] < best_mse_lgb:\n",
    "            best_mse_lgb = lgb_perf['mse']\n",
    "            model_dict[\"lgb\"] = lgbclf\n",
    "        \n",
    "        clean_up_cuda(lgbclf)\n",
    "\n",
    "        random_summary = aggregate_cv_metrics_and_print(random_results, \"Random\")\n",
    "        tabpfn_summary = aggregate_cv_metrics_and_print(tabpfn_results, \"TabPFN\")\n",
    "        lgb_summary = aggregate_cv_metrics_and_print(lgb_results, \"LGBM\")\n",
    "        mlp_summary = aggregate_cv_metrics_and_print(mlp_results, \"MLP\")\n",
    "\n",
    "        tabpfn_eval_summary = aggregate_cv_metrics_and_print(tabpfn_results_eval, \"TabPFN\", \"Control\")\n",
    "        lgb_eval_summary = aggregate_cv_metrics_and_print(lgb_results_eval, \"LGBM\", \"Control\")\n",
    "        mlp_eval_summary = aggregate_cv_metrics_and_print(mlp_results_eval, \"MLP\", \"Control\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    result_dict[deconfounding_strategy] = {\n",
    "        \"TabPFN\": {\n",
    "                \"results\": tabpfn_summary,\n",
    "                \"results_eval\": tabpfn_eval_summary,\n",
    "                \"cv_results\": tabpfn_results,\n",
    "                \"cv_results_eval\": tabpfn_results_eval\n",
    "        },\n",
    "        \"LGBM\": {\n",
    "                \"results\": lgb_summary,\n",
    "                \"results_eval\": lgb_eval_summary,\n",
    "                \"cv_results\": lgb_results,\n",
    "                \"cv_results_eval\": lgb_results_eval\n",
    "        },\n",
    "        \"Random\": {\n",
    "                \"results\": random_summary,\n",
    "                \"cv_results\": random_results\n",
    "        },\n",
    "        \"MLP\": {\n",
    "                \"results\": mlp_summary,\n",
    "                \"results_eval\": mlp_eval_summary,\n",
    "                \"cv_results\": mlp_results,\n",
    "                \"cv_results_eval\": mlp_results_eval\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for result, models in result_dict.items():\n",
    "    print(f\"\\nResults for {result*100:.0f}% of the data:\")\n",
    "    for model, results in models.items():\n",
    "        print(f\"  {model} - Results: {results['results']}\")\n",
    "        if 'results_eval' in results:\n",
    "            print(f\"  {model} - Evaluation Results: {results['results_eval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nsave_dir = \"../98_models/\"\\nwith open(os.path.join(save_dir, \"best_regressor.pkl\"), \"rb\") as f:\\n    loaded_model = pickle.load(f)\\n    # For example, if it\\'s a LightGBM model, you can just do:\\n    y_pred_control = loaded_model.predict(X_control_scaled)\\n    performance_control = evaluate_regression_performance(y_control, y_pred_control)\\n    print(\"\\nLoaded Model Performance on Control Data:\")\\n    print_regression_performance(performance_control)\\n'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Example: Load a saved model & evaluate on control data\n",
    "###############################################################################\n",
    "# If you have a saved regression model:\n",
    "\"\"\"\n",
    "import pickle\n",
    "save_dir = \"../98_models/\"\n",
    "with open(os.path.join(save_dir, \"best_regressor.pkl\"), \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    # For example, if it's a LightGBM model, you can just do:\n",
    "    y_pred_control = loaded_model.predict(X_control_scaled)\n",
    "    performance_control = evaluate_regression_performance(y_control, y_pred_control)\n",
    "    print(\"\\nLoaded Model Performance on Control Data:\")\n",
    "    print_regression_performance(performance_control)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing feature_1 with p-value 1.0000\n",
      "Removing const with p-value 0.9728\n",
      "Removing feature_2 with p-value 0.4933\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['const'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# Perform backward elimination\u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m selected_features \u001b[38;5;241m=\u001b[39m \u001b[43mbackward_elimination\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mSelected features:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(selected_features\u001b[38;5;241m.\u001b[39mcolumns)\n",
      "Cell \u001b[0;32mIn[39], line 41\u001b[0m, in \u001b[0;36mbackward_elimination\u001b[0;34m(X, y, significance_level)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Return the final selected feature set (excluding the intercept)\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mconst\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5345\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5346\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5351\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5352\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['const'] not found in axis\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load example data (replace with your dataset)\n",
    "# Assume 'X' contains independent variables and 'y' contains the dependent variable\n",
    "# Add a constant for the intercept term in the regression model\n",
    "def backward_elimination(X, y, significance_level=0.05):\n",
    "    # Add constant for intercept\n",
    "    X = sm.add_constant(X)\n",
    "    while True:\n",
    "        # Fit the OLS model\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Get the p-values for each feature\n",
    "        p_values = model.pvalues\n",
    "        \n",
    "        # Find the feature with the highest p-value\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value > significance_level:\n",
    "            # Remove the feature with the highest p-value\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            print(f\"Removing {feature_to_remove} with p-value {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # Return the final selected feature set (excluding the intercept)\n",
    "    return X.drop(columns=['const'])\n",
    "\n",
    "# Example usage with dummy data\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample dataset (replace with actual data)\n",
    "    data = {\n",
    "        'feature_1': [0, 3, 1, 2, 1],\n",
    "        'feature_2': [4, 15, 25, 35, 45],\n",
    "        'feature_3': [1, 2, 3, 4, 5],\n",
    "        'target': [100, 200, 300, 400, 500]\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Separate features and target\n",
    "    X = df.drop(columns=['target'])\n",
    "    y = df['target']\n",
    "\n",
    "    # Perform backward elimination\n",
    "    selected_features = backward_elimination(X, y)\n",
    "\n",
    "    print(\"\\nSelected features:\")\n",
    "    print(selected_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
