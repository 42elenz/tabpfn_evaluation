{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dfs form a folder and merge them on ID\n",
    "\"\"\" path = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/\"\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(path + file)\n",
    "    else:\n",
    "        df = pd.merge(df, pd.read_csv(path + file), on='ID') \"\"\"\n",
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df = label_df[['ID', 'label_age_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes on ID\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"label_age_group\"].value_counts()\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "#get a sample exact from the data  10000 but having the same distribution of the labels\n",
    "df_sampled, _ = train_test_split(merged_df, train_size=10000, stratify=merged_df[\"label_age_group\"], random_state=42)\n",
    "\n",
    "#drop specific labels for label_age_group\n",
    "df_sampled = df_sampled[df_sampled.label_age_group != 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled[\"label_age_group\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_sampled[\"label_age_group\"]\n",
    "X = df_sampled.drop([\"ID\", \"label_age_group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get coutns from y_train and y_test\n",
    "print(y_train.value_counts())\n",
    "print(y_test.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(1024, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = TabPFNClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "# ROC AUC for multiclass using 'macro' average\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify on onther dataset\n",
    "df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/aseg.volume_aparc.thickness_aparc.volume.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df_control = label_df[['ID', 'label_age_group']]\n",
    "df_control = df_control[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label and the data\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X_control = merged_df_control.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "y_control = merged_df_control[\"label_age_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_control = clf.predict(X_control)\n",
    "y_pred_proba_control = clf.predict_proba(X_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unqie from ypred\n",
    "np.unique(y_pred_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get vlaue count for label age group\n",
    "print(merged_df_control[\"label_age_group\"].value_counts())\n",
    "#get how often unique values are in y_pred_control\n",
    "np.unique(y_pred_control, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "# Get the classes present in the validation data\n",
    "present_classes = np.unique(y_control)\n",
    "\n",
    "# Get the indices of these classes in the original prediction probabilities\n",
    "original_classes = clf.classes_\n",
    "class_indices = [np.where(original_classes == cls)[0][0] for cls in present_classes]\n",
    "\n",
    "# Select only the probability columns for present classes\n",
    "y_pred_proba_filtered = y_pred_proba_control[:, class_indices]\n",
    "\n",
    "# Binarize the true labels using only the present classes\n",
    "y_train_bin = label_binarize(y_control, classes=present_classes)\n",
    "\n",
    "# Calculate ROC AUC only for present classes\n",
    "auc_control = roc_auc_score(y_train_bin, y_pred_proba_filtered, \n",
    "                           multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "#auc = roc_auc_score(y_control, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "#auc_control = roc_auc_score(y_train, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "acc = accuracy_score(y_control, y_pred_control)\n",
    "balanced_acc = balanced_accuracy_score(y_control, y_pred_control)\n",
    "report = classification_report(y_control, y_pred_control)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_control))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_control.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred_control)\n",
    "\n",
    "print(f\" Control ROC AUC: {auc_control}\")\n",
    "print(f\" Control Accuracy: {acc}\")\n",
    "print(f\" Control Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\" Control Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# Train LightGBM model\n",
    "lgb_train = lgb.Dataset(X_train, label=y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, label=y_test, reference=lgb_train)\n",
    "\n",
    "params = {\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': len(y.unique()),\n",
    "    'metric': 'multi_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "print(\"Training LightGBM model...\")\n",
    "print(f\"lenght of X_train: {len(X_train)}\")\n",
    "clf = lgb.train(params, lgb_train, valid_sets=[lgb_train, lgb_eval], num_boost_round=1000)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = clf.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "# Evaluate performance\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# Compare to random prediction\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)\n",
    "\n",
    "print(f\"ROC AUC: {auc:.4f}\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc:.4f}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc:.4f}\")\n",
    "print(report)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training LightGBM model...for control\")\n",
    "print(f\"lenght of X_train: {len(X_control)}\")\n",
    "\n",
    "# Predict on control dataset\n",
    "y_pred_control_proba = clf.predict(X_control)\n",
    "y_pred_control = np.argmax(y_pred_control_proba, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "# Get the classes present in the validation data\n",
    "present_classes = np.unique(y_control)\n",
    "\n",
    "# Get the indices of these classes in the original prediction probabilities\n",
    "class_indices = [np.where(original_classes == cls)[0][0] for cls in present_classes]\n",
    "\n",
    "# Select only the probability columns for present classes\n",
    "y_pred_proba_filtered = y_pred_proba_control[:, class_indices]\n",
    "\n",
    "# Binarize the true labels using only the present classes\n",
    "y_train_bin = label_binarize(y_control, classes=present_classes)\n",
    "\n",
    "# Calculate ROC AUC only for present classes\n",
    "auc_control = roc_auc_score(y_train_bin, y_pred_proba_filtered, \n",
    "                           multi_class='ovr', average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate control set performance\n",
    "acc_control = accuracy_score(y_control, y_pred_control)\n",
    "balanced_acc_control = balanced_accuracy_score(y_control, y_pred_control)\n",
    "report_control = classification_report(y_control, y_pred_control)\n",
    "\n",
    "# Compare to random prediction\n",
    "random_y_control = np.random.randint(0, n_classes, size=y_control.shape)\n",
    "random_balanced_acc_control = balanced_accuracy_score(random_y_control, y_pred_control)\n",
    "\n",
    "print(f\"Control ROC AUC: {auc_control:.4f}\")\n",
    "print(f\"Control Accuracy: {acc_control:.4f}\")\n",
    "print(f\"Control Balanced Accuracy: {balanced_acc_control:.4f}\")\n",
    "print(f\"Control Random Balanced Accuracy: {random_balanced_acc_control:.4f}\")\n",
    "print(report_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
