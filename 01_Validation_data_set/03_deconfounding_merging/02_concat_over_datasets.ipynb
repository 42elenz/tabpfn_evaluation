{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output directories\n",
    "input_directory = \"../00_data/\"\n",
    "output_directory = \"../00_data/final_folder/\"\n",
    "mri_folder = \"deconfounded_but_age\"\n",
    "demographic_file = \"all_ages_all_ids.csv\"\n",
    "\n",
    "#ID,label_Age,Sex,Site,label_age_group, BMI possible\n",
    "data_to_keep_in_demographic = [\"label_age_group\", \"ID\", \"label_Age\"]\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "# Get a list of all subdirectories\n",
    "subfolders = [os.path.join(input_directory, folder) for folder in os.listdir(input_directory) if os.path.isdir(os.path.join(input_directory, folder))]\n",
    "\n",
    "# Find unique filenames across all subfolders\n",
    "file_map = {}\n",
    "demographic_files = []\n",
    "for folder in subfolders:\n",
    "    if 'ds' in folder:\n",
    "        demographic_files.append(os.path.join(folder, demographic_file))\n",
    "        for file in os.listdir(os.path.join(folder, mri_folder)):\n",
    "            sorted_name = \"_\".join(sorted(file.replace(\".csv\", \"\").split(\"_\"))) + \".csv\"\n",
    "            if sorted_name not in file_map:\n",
    "                file_map[sorted_name] = []\n",
    "            file_map[sorted_name].append(os.path.join(folder, mri_folder, file))\n",
    "\n",
    "# Process each file type found in the folders\n",
    "for file_name, file_paths in file_map.items():\n",
    "    all_dfs = []\n",
    "    all_dfs_demographic = []\n",
    "\n",
    "    for folder in subfolders:\n",
    "        if 'ds' not in folder:\n",
    "            continue\n",
    "        for file_path in file_paths:\n",
    "            df = pd.read_csv(file_path)\n",
    "            #check columns if there is something with age or Age and drop them us to lower\n",
    "            if any('age' in col.lower() for col in df.columns):\n",
    "                print(f\"Found age-related column in {file_path}\")\n",
    "                df = df.drop(columns=[col for col in df.columns if 'age' in col.lower()])\n",
    "            #df['Source'] = os.path.basename(file_path)  # Track original file\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    #concatenate demographic files\n",
    "    for demographic_file in demographic_files:\n",
    "        df = pd.read_csv(demographic_file)\n",
    "        #df['Source'] = demographic_file\n",
    "        all_dfs_demographic.append(df)\n",
    "    merged_df_demographic = pd.concat(all_dfs_demographic, ignore_index=True)\n",
    "    merged_df_demographic = merged_df_demographic[data_to_keep_in_demographic]\n",
    "    if all_dfs:\n",
    "        # Concatenate all DataFrames for the current file type\n",
    "        merged_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        # Drop any duplicate rows\n",
    "        merged_df = merged_df.drop_duplicates(subset='ID', keep='first')\n",
    "        merged_df_demographic = merged_df_demographic.drop_duplicates(subset='ID', keep='first')\n",
    "        # Merge the demographic data\n",
    "        merged_df = pd.merge(merged_df, merged_df_demographic, on='ID', how='inner')\n",
    "        #data to keep without ID\n",
    "        col_to_drop = [col for col in data_to_keep_in_demographic if 'ID' not in col]\n",
    "        mri_data = merged_df.drop(columns=col_to_drop)\n",
    "        label_data = merged_df[data_to_keep_in_demographic]\n",
    "        # Save the merged file\n",
    "        output_path = os.path.join(output_directory, file_name)\n",
    "        mri_data.to_csv(output_path, index=False)\n",
    "        label_data.to_csv(output_path.replace(\".csv\", \"_label.csv\"), index=False)\n",
    "        print(f\"Merged and saved: {output_path}\")\n",
    "\n",
    "print(\"All matching files have been merged and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chekc for double IDs in merged_df\n",
    "ids = merged_df['ID']\n",
    "ids = ids[ids.duplicated()]\n",
    "\n",
    "ids_demo = merged_df_demographic['ID']\n",
    "ids_demo = ids_demo[ids_demo.duplicated()]\n",
    "\n",
    "print(f\"Double IDs in merged_df: {ids}\")\n",
    "print(f\"Double IDs in merged_df_demographic: {ids_demo}\")\n",
    "\n",
    "#check that all Ids in demo and merged_df\n",
    "ids_demo = set(ids_demo)\n",
    "ids = set(ids)\n",
    "diff = ids_demo - ids\n",
    "print(f\"IDs in demo but not in merged_df: {diff}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
