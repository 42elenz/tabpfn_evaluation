{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.api import OLS, add_constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed and saved: ../00_data/00_ds000030/deconfounded_but_age/aparc.volume.csv\n",
      "Processed and saved: ../00_data/00_ds000030/deconfounded_but_age/aparc.thickness.csv\n",
      "Processed and saved: ../00_data/00_ds000030/deconfounded_but_age/aseg.volume.csv\n",
      "Processed and saved: ../00_data/02_ds002790/deconfounded_but_age/aseg.volume.csv\n",
      "Processed and saved: ../00_data/02_ds002790/deconfounded_but_age/aparc.volume.csv\n",
      "Processed and saved: ../00_data/02_ds002790/deconfounded_but_age/aparc.thickness.csv\n",
      "Processed and saved: ../00_data/01_ds002785/deconfounded_but_age/aparc.thickness.csv\n",
      "Processed and saved: ../00_data/01_ds002785/deconfounded_but_age/aparc.volume.csv\n",
      "Processed and saved: ../00_data/01_ds002785/deconfounded_but_age/aseg.volume.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.api import OLS, add_constant\n",
    "\n",
    "for folder in os.listdir(\"../00_data/\"):\n",
    "    # Define folder paths\n",
    "    input_folder = f\"../00_data/{folder}/freesurfer_finished/\"  # Folder containing the brain data files\n",
    "    output_folder = f\"../00_data/{folder}/deconfounded_but_age/\"  # Folder to save the corrected files\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Load the covariates data\n",
    "    covariates_file = f\"../00_data/{folder}/all_ages_all_ids.csv\"\n",
    "    covariates_data = pd.read_csv(covariates_file)\n",
    "\n",
    "    # Rename columns to a consistent format\n",
    "    columns_to_rename = {\"ID\": \"ID\", \"basis_sex\": \"Sex\", \"basis_uort\": \"Site\", \"label_Age\": \"Age\"}\n",
    "    covariates_data.rename(columns={k: v for k, v in columns_to_rename.items() if k in covariates_data.columns}, inplace=True)\n",
    "\n",
    "    # Define required covariate columns\n",
    "    required_covariates = [\"ID\", \"Sex\", \"Site\", \"Age\"]\n",
    "\n",
    "    # Filter covariate data to keep only available columns\n",
    "    covariates_data = covariates_data[[col for col in required_covariates if col in covariates_data.columns]]\n",
    "\n",
    "\n",
    "    # Map categorical values to numerical ones\n",
    "    if \"Site\" in covariates_data.columns:\n",
    "        site_mapping = {site: idx for idx, site in enumerate(covariates_data[\"Site\"].unique())}\n",
    "        covariates_data[\"Site\"] = covariates_data[\"Site\"].map(site_mapping)\n",
    "    sex_mapping = {\"Male\": 0, \"Female\": 1}\n",
    "    covariates_data[\"Sex\"] = covariates_data[\"Sex\"].map(sex_mapping)\n",
    "    covariates_data[\"ID\"] = covariates_data[\"ID\"].astype(str)\n",
    "\n",
    "    # Process each brain data file in the input folder\n",
    "    for file_name in os.listdir(input_folder):\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            brain_volume_file = os.path.join(input_folder, file_name)\n",
    "            brain_data_filename = os.path.splitext(file_name)[0]\n",
    "\n",
    "            # Load the brain volume data\n",
    "            brain_data = pd.read_csv(brain_volume_file)\n",
    "            brain_data.rename(columns={\"eid\": \"ID\"}, inplace=True)\n",
    "            brain_data[\"ID\"] = brain_data[\"ID\"].astype(str)\n",
    "            \n",
    "            if \"sub-\" in brain_data[\"ID\"].iloc[0]:\n",
    "                brain_data[\"ID\"] = brain_data[\"ID\"].str.replace(\"sub-\", \"\")\n",
    "\n",
    "            # Merge brain data with covariates\n",
    "            merged_data = pd.merge(brain_data, covariates_data, on=\"ID\", how=\"inner\")\n",
    "\n",
    "            # Define numerical columns for analysis\n",
    "            numerical_cols = merged_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "            # Handle NaN values\n",
    "            nan_counts = merged_data.isnull().sum()\n",
    "            if nan_counts.sum() > 0:\n",
    "                merged_data[numerical_cols] = merged_data[numerical_cols].apply(\n",
    "                    lambda col: col.fillna(col.mean())\n",
    "                )\n",
    "\n",
    "            # Step 1: Pre-Correction Analysis\n",
    "            pre_correction_results = []\n",
    "            for col in numerical_cols:\n",
    "                if col not in [\"Sex\", \"Site\", \"BMI\"]:\n",
    "                    group1 = merged_data[merged_data[\"Sex\"] == 0][col]\n",
    "                    group2 = merged_data[merged_data[\"Sex\"] == 1][col]\n",
    "                    t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n",
    "                    pre_correction_results.append({\"Variable\": col, \"t-statistic\": t_stat, \"p-value\": p_value})\n",
    "\n",
    "            pre_correction_df = pd.DataFrame(pre_correction_results)\n",
    "\n",
    "            # Identify significant variables\n",
    "            significant_vars = pre_correction_df[pre_correction_df[\"p-value\"] < 0.05][\"Variable\"].tolist()\n",
    "\n",
    "            # Step 2: Residualization\n",
    "            corrected_data = merged_data.copy()\n",
    "            predictors = [\"Sex\", \"BMI\"]\n",
    "\n",
    "            if \"Site\" in merged_data.columns:\n",
    "                predictors.append(\"Site\")\n",
    "\n",
    "            for col in significant_vars:\n",
    "                X = add_constant(merged_data[predictors])\n",
    "                y = merged_data[col]\n",
    "                model = OLS(y, X).fit()\n",
    "                residuals = y - model.predict(X)\n",
    "                corrected_data[col] = residuals + y.mean()\n",
    "\n",
    "            # Save corrected data\n",
    "            corrected_data = corrected_data.drop(columns=[col for col in [\"Sex\", \"Site\", \"Age\", \"BMI\", \"label_Age_group\"] if col in corrected_data.columns])\n",
    "            corrected_file_name = f\"{brain_data_filename}.csv\"\n",
    "            full_file_path = os.path.join(output_folder, corrected_file_name)\n",
    "            corrected_data.to_csv(full_file_path, index=False)\n",
    "\n",
    "            print(f\"Processed and saved: {full_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Define folder paths\\ninput_folder = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/freesurfer_finished/\"  # Folder containing the brain data files\\noutput_folder = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/\"  # Folder to save the corrected files\\n#make sure the output folder exists\\n\\n# Load the covariates data (this file is shared across all analyses)\\ncovariates_file = \"../00_data/Val_demographics_covariates.csv\"  # Adjust the path as needed\\ncovariates_data = pd.read_csv(covariates_file)\\n#covariates_data = covariates_data.drop(columns=[\"p20252_i2\", \"p34\"])\\ncovariates_data.rename(\\n    columns={\"ID\": \"ID\", \"basis_sex\": \"Sex\", \"basis_uort\": \"Site\", \"basis_age\": \"Age\"},\\n    inplace=True,\\n)\\nsite_mapping = {site: idx for idx, site in enumerate(covariates_data[\"Site\"].unique())}\\ncovariates_data[\"Site\"] = covariates_data[\"Site\"].map(site_mapping)\\nsex_mapping = {\"Male\": 0, \"Female\": 1}\\ncovariates_data[\"Sex\"] = covariates_data[\"Sex\"].map(sex_mapping)\\ncovariates_data[\"ID\"] = covariates_data[\"ID\"].astype(str)\\n\\n# Ensure output folder exists\\nos.makedirs(output_folder, exist_ok=True)\\n\\n# Process each brain data file in the input folder\\nfor file_name in os.listdir(input_folder):\\n    if file_name.endswith(\".csv\"):\\n        brain_volume_file = os.path.join(input_folder, file_name)\\n        brain_data_filename = os.path.splitext(file_name)[0]\\n\\n        # Load the brain volume data\\n        brain_data = pd.read_csv(brain_volume_file)\\n        brain_data.rename(columns={\"eid\": \"ID\"}, inplace=True)\\n        brain_data[\"ID\"] = brain_data[\"ID\"].astype(str)\\n        if \"sub-\" in brain_data[\"ID\"].iloc[0]:\\n            brain_data[\"ID\"] = brain_data[\"ID\"].str.replace(\"sub-\", \"\")\\n\\n\\n        # Merge brain data with covariates\\n        merged_data = pd.merge(brain_data, covariates_data, on=\"ID\", how=\"inner\")\\n\\n        # Define numerical columns for analysis\\n        numerical_cols = brain_data.select_dtypes(include=[np.number]).columns.tolist()\\n\\n        # Handle NaN values\\n        nan_counts = merged_data.isnull().sum()\\n        if nan_counts.sum() > 0:\\n            merged_data[numerical_cols] = merged_data[numerical_cols].apply(\\n                lambda col: col.fillna(col.mean())\\n            )\\n\\n        # Step 1: Pre-Correction Analysis\\n        pre_correction_results = []\\n        for col in numerical_cols:\\n            if col not in [\"Sex\", \"Site\"]:\\n                group1 = merged_data[merged_data[\"Sex\"] == 0][col]\\n                group2 = merged_data[merged_data[\"Sex\"] == 1][col]\\n                t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\\n                pre_correction_results.append({\"Variable\": col, \"t-statistic\": t_stat, \"p-value\": p_value})\\n        pre_correction_df = pd.DataFrame(pre_correction_results)\\n\\n        # Identify significant variables\\n        significant_vars = pre_correction_df[pre_correction_df[\"p-value\"] < 0.05][\"Variable\"].tolist()\\n\\n        # Step 2: Residualization\\n        corrected_data = merged_data.copy()\\n        for col in significant_vars:\\n            predictors = [\"Sex\", \"Site\"]\\n            X = add_constant(merged_data[predictors])\\n            y = merged_data[col]\\n            model = OLS(y, X).fit()\\n            residuals = y - model.predict(X)\\n            corrected_data[col] = residuals + y.mean()\\n\\n        # Save corrected data\\n        corrected_data = corrected_data.drop(columns=[\"Sex\", \"Site\", \"Age\"])\\n        corrected_file_name = f\"{brain_data_filename}.csv\"\\n        os.makedirs(output_folder, exist_ok=True)\\n        full_file_path = os.path.join(output_folder, corrected_file_name)\\n        corrected_data.to_csv(full_file_path, index=False)\\n\\n        print(f\"Processed and saved: {full_file_path}\")\\n '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Define folder paths\n",
    "input_folder = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/freesurfer_finished/\"  # Folder containing the brain data files\n",
    "output_folder = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/\"  # Folder to save the corrected files\n",
    "#make sure the output folder exists\n",
    "\n",
    "# Load the covariates data (this file is shared across all analyses)\n",
    "covariates_file = \"../00_data/Val_demographics_covariates.csv\"  # Adjust the path as needed\n",
    "covariates_data = pd.read_csv(covariates_file)\n",
    "#covariates_data = covariates_data.drop(columns=[\"p20252_i2\", \"p34\"])\n",
    "covariates_data.rename(\n",
    "    columns={\"ID\": \"ID\", \"basis_sex\": \"Sex\", \"basis_uort\": \"Site\", \"basis_age\": \"Age\"},\n",
    "    inplace=True,\n",
    ")\n",
    "site_mapping = {site: idx for idx, site in enumerate(covariates_data[\"Site\"].unique())}\n",
    "covariates_data[\"Site\"] = covariates_data[\"Site\"].map(site_mapping)\n",
    "sex_mapping = {\"Male\": 0, \"Female\": 1}\n",
    "covariates_data[\"Sex\"] = covariates_data[\"Sex\"].map(sex_mapping)\n",
    "covariates_data[\"ID\"] = covariates_data[\"ID\"].astype(str)\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Process each brain data file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        brain_volume_file = os.path.join(input_folder, file_name)\n",
    "        brain_data_filename = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # Load the brain volume data\n",
    "        brain_data = pd.read_csv(brain_volume_file)\n",
    "        brain_data.rename(columns={\"eid\": \"ID\"}, inplace=True)\n",
    "        brain_data[\"ID\"] = brain_data[\"ID\"].astype(str)\n",
    "        if \"sub-\" in brain_data[\"ID\"].iloc[0]:\n",
    "            brain_data[\"ID\"] = brain_data[\"ID\"].str.replace(\"sub-\", \"\")\n",
    "\n",
    "\n",
    "        # Merge brain data with covariates\n",
    "        merged_data = pd.merge(brain_data, covariates_data, on=\"ID\", how=\"inner\")\n",
    "\n",
    "        # Define numerical columns for analysis\n",
    "        numerical_cols = brain_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        # Handle NaN values\n",
    "        nan_counts = merged_data.isnull().sum()\n",
    "        if nan_counts.sum() > 0:\n",
    "            merged_data[numerical_cols] = merged_data[numerical_cols].apply(\n",
    "                lambda col: col.fillna(col.mean())\n",
    "            )\n",
    "\n",
    "        # Step 1: Pre-Correction Analysis\n",
    "        pre_correction_results = []\n",
    "        for col in numerical_cols:\n",
    "            if col not in [\"Sex\", \"Site\"]:\n",
    "                group1 = merged_data[merged_data[\"Sex\"] == 0][col]\n",
    "                group2 = merged_data[merged_data[\"Sex\"] == 1][col]\n",
    "                t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n",
    "                pre_correction_results.append({\"Variable\": col, \"t-statistic\": t_stat, \"p-value\": p_value})\n",
    "        pre_correction_df = pd.DataFrame(pre_correction_results)\n",
    "\n",
    "        # Identify significant variables\n",
    "        significant_vars = pre_correction_df[pre_correction_df[\"p-value\"] < 0.05][\"Variable\"].tolist()\n",
    "\n",
    "        # Step 2: Residualization\n",
    "        corrected_data = merged_data.copy()\n",
    "        for col in significant_vars:\n",
    "            predictors = [\"Sex\", \"Site\"]\n",
    "            X = add_constant(merged_data[predictors])\n",
    "            y = merged_data[col]\n",
    "            model = OLS(y, X).fit()\n",
    "            residuals = y - model.predict(X)\n",
    "            corrected_data[col] = residuals + y.mean()\n",
    "\n",
    "        # Save corrected data\n",
    "        corrected_data = corrected_data.drop(columns=[\"Sex\", \"Site\", \"Age\"])\n",
    "        corrected_file_name = f\"{brain_data_filename}.csv\"\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        full_file_path = os.path.join(output_folder, corrected_file_name)\n",
    "        corrected_data.to_csv(full_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {full_file_path}\")\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
