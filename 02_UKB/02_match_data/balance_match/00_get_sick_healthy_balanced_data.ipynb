{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "label_df =\"WK_digits_rememberd.csv\"\n",
    "command_label = f\"dx download file-Gx8pB38Jk6kP63J7Ykbb2gPF --output /opt/notebooks/{label_df} --overwrite\"\n",
    "\n",
    "label_df_alc = \"alc_multi_label.csv\"\n",
    "command_label_alc = f\"dx download file-GxJYyQjJk6kPfqG079ZBPYg6 --output /opt/notebooks/{label_df_alc} --overwrite\"\n",
    "\n",
    "multi_label_df = \"merged_multitarget_df_with_demographics.csv\"\n",
    "command_multi_label = f\"dx download file-GxK2v3jJk6k9FppfBZqGQj1v --output /opt/notebooks/{multi_label_df} --overwrite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_table = \"aparc.thickness_aparc.volume_aseg.volume.csv\"\n",
    "command = f\"dx download file-GxG4P20Jk6k9kG9pv7Bxx2pk --output '/opt/notebooks/{mri_table}' --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subprocess.run(command_label, shell=True, check=True)\n",
    "subprocess.run(command_label_alc, shell=True, check=True)\n",
    "subprocess.run(command_multi_label, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_wm = pd.read_csv(f\"/opt/notebooks/{label_df}\")\n",
    "label_df_alc = pd.read_csv(f\"/opt/notebooks/{label_df_alc}\")\n",
    "multi_label_df = pd.read_csv(f\"/opt/notebooks/{multi_label_df}\")\n",
    "mri_df = pd.read_csv(f\"/opt/notebooks/{mri_table}\")\n",
    "mri_df[\"ID\"] = mri_df[\"ID\"].str.replace(\"sub-\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_df.to_csv(f\"/opt/notebooks/{mri_table}\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_wm_range = range(9, 13)  # Scores 9 to 12 inclusive\n",
    "low_wm_range = range(2, 4)    # Scores 2 to 5 inclusive\n",
    "def classify_wm_capacity(score):\n",
    "    if score in high_wm_range:\n",
    "        return 1  # High WM capacity\n",
    "    elif score in low_wm_range:\n",
    "        return 0  # Low WM capacity\n",
    "    else:\n",
    "        return None  # Exclude other scores\n",
    "\n",
    "# Apply classification\n",
    "label_wm['Good_WM_Memory'] = label_wm[\"digits_remembered\"].apply(classify_wm_capacity)\n",
    "df_wm = label_wm.dropna(subset=['Good_WM_Memory'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_wm.head(2)\n",
    "label_wm[\"label_Bad_WM_Memory\"] = 1 - label_wm[\"Good_WM_Memory\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_wm[\"digits_remembered\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_wm[\"label_Bad_WM_Memory\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge wm to multi_label_df\n",
    "merged_df = pd.merge(multi_label_df, label_wm, on=\"ID\", how=\"left\")\n",
    "merged_df = merged_df.drop(columns=[\"digits_remembered\", \"Good_WM_Memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"/opt/notebooks/merged_multitarget_df_with_demographics_wm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"label_HRD_sex_balanced\",\n",
    "    \"label_HRD_balanced\",\n",
    "    \"label_HRD\",\n",
    "    \"label_HRD_Binge>1_no_ol_balanced\",\n",
    "    \"label_HRD_Binge>1_no_ol_sex_balanced\",\n",
    "    \"label_HRD_Binge>1_no_ol_balanced\",\n",
    "    \"label_HRD_Binge>1_no_ol\"\n",
    "]\n",
    "merged_df = merged_df.drop(cols_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"ID\"] = merged_df[\"ID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, mri_df, on=\"ID\", how=\"inner\")\n",
    "#define a sick label. IF in the mulit_label df a column with the name \"label_*\"\" is 1 hte sick column is 1 else 0\n",
    "merged_df['label_sick'] = (merged_df.filter(like='label_') == 1).any(axis=1).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"label_sick\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the columns from mri_df but the \"ID\"\n",
    "cols_to_drop = [col for col in mri_df.columns if col != \"ID\"]\n",
    "merged_df.drop(cols_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in merged_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"/opt/notebooks/merged_multitarget_df_with_demographics_wm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_participant(target_row, df_candidates, relax_order, used_ids,thresholds):\n",
    "    df_candidates = df_candidates[~df_candidates['ID'].isin(used_ids)].copy()\n",
    "    for relax_level in relax_order:\n",
    "        filtered = df_candidates.copy()\n",
    "        for criterion, match_exact in relax_level.items():\n",
    "            if criterion in ['assessment_centre']:\n",
    "                if match_exact:\n",
    "                    filtered = filtered[filtered[criterion] == target_row[criterion]]\n",
    "            elif criterion in ['sex']:\n",
    "                if match_exact:\n",
    "                    #find opposite sex\n",
    "                    filtered = filtered[filtered[criterion] != target_row[criterion]]\n",
    "            else:\n",
    "                if match_exact:\n",
    "                    diff = abs(filtered[criterion] - target_row[criterion])\n",
    "                    filtered = filtered[diff <= thresholds[criterion]]\n",
    "            if filtered.empty:\n",
    "                break\n",
    "        if not filtered.empty:\n",
    "            return filtered.iloc[0]\n",
    "    print(\"NO candidate found\")\n",
    "    return None\n",
    "relax_order = [\n",
    "    {'assessment_centre': True, 'deprivation_index': True, 'bmi': True, 'age_at_assessment': True, 'sex': True},\n",
    "    {'assessment_centre': False, 'deprivation_index': True, 'bmi': True, 'age_at_assessment': True, 'sex': True},\n",
    "    {'assessment_centre': False, 'deprivation_index': False, 'bmi': True, 'age_at_assessment': True, 'sex': True},\n",
    "    {'assessment_centre': False, 'deprivation_index': False, 'bmi': False, 'age_at_assessment': True, 'sex': True},\n",
    "    {'assessment_centre': False, 'deprivation_index': False, 'bmi': False, 'age_at_assessment': False, 'sex': True},\n",
    "]\n",
    "thresholds = {\n",
    "    'age_at_assessment': 2,\n",
    "    'bmi': 3,\n",
    "    'deprivation_index': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "def match_for_label(label, merged_df, relax_order, thresholds):\n",
    "    positive_group = merged_df[merged_df[label] == 1]\n",
    "    negative_group = merged_df[merged_df[label] == 0]\n",
    "\n",
    "    matches = []\n",
    "    used_ids = set() \n",
    "    for _, target_row in positive_group.iterrows():\n",
    "        matched = match_participant(target_row, negative_group, relax_order, used_ids, thresholds)\n",
    "        if matched is not None:\n",
    "            matches.append(matched)\n",
    "            used_ids.add(matched['ID'])\n",
    "    matched_df = pd.DataFrame(matches)\n",
    "    return label, matched_df, positive_group\n",
    "\n",
    "label_cols = [\"label_sick\"]\n",
    "results = Parallel(n_jobs=-1)(delayed(match_for_label)(label, merged_df, relax_order, thresholds) for label in label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "logs_path = \"project-GqzxkVQJ34g6ygFJ4ZbvqBYF:/Esra/00_CLIP/04_trainings_data/02_normative/\"\n",
    "for label, matched_df, positive_group in results:\n",
    "    #concat the the positive and negative matched participants\n",
    "    final_df = pd.concat([positive_group, matched_df])\n",
    "    final_df[\"ID\"] =final_df[\"ID\"].astype(int).astype(str)\n",
    "    final_df.to_csv(f\"/opt/notebooks/Matched_validation_sick_healthy_less_strict.csv\", index=False)\n",
    "    command = f\"dx upload /opt/notebooks/Matched_validation_sick_healthy_less_strict.csv --path {logs_path}\"\n",
    "    print(command)\n",
    "    subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "logs_path = \"project-GqzxkVQJ34g6ygFJ4ZbvqBYF:/Esra/00_CLIP/04_trainings_data/02_normative/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(\"/opt/notebooks/Matched_validation_sick_healthy_less_strict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"ID\"] = final_df[\"ID\"].astype(str)\n",
    "merged_df[\"ID\"] = merged_df[\"ID\"].astype(str)\n",
    "\n",
    "# Get the unique IDs from each DataFrame\n",
    "final_df_ids = set(final_df[\"ID\"])\n",
    "merged_df_ids = set(merged_df[\"ID\"])\n",
    "\n",
    "# Find IDs present in merged_df but not in final_df\n",
    "not_matched_ids = merged_df_ids - final_df_ids\n",
    "\n",
    "# Filter the DataFrame to get rows with unmatched IDs\n",
    "not_matched_df = merged_df[merged_df[\"ID\"].isin(not_matched_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_matched_df.to_csv(f\"/opt/notebooks/healthy_subjects_train_less_strict.csv\", index=False)\n",
    "command = f\"dx upload /opt/notebooks/healthy_subjects_train_less_strict.csv --path {logs_path}\"\n",
    "print(command)\n",
    "subprocess.run(command, shell=True, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = [\"label_Bad_WM_Memory\"]\n",
    "results = Parallel(n_jobs=-1)(delayed(match_for_label)(label, final_df, relax_order, thresholds) for label in label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, matched_df, positive_group in results:\n",
    "    #concat the the positive and negative matched participants\n",
    "    final_df_2 = pd.concat([positive_group, matched_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df[\"label_Bad_WM_Memory\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "postive = df[df[\"label_Bad_WM_Memory\"] == 1]\n",
    "negative = df[df[\"label_Bad_WM_Memory\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#check the distribution of the matched participants for age_at_assessment bmi and so on \n",
    "col_to_check = [\"age_at_assessment\", \"bmi\", \"deprivation_index\", \"sex\", \"assessment_centre\"]\n",
    "for col in col_to_check:\n",
    "    print(col)\n",
    "    print(postive[col].hist())\n",
    "    print(negative[col].hist())\n",
    "    print(postive[col].describe())\n",
    "    print(negative[col].describe())\n",
    "    print(\"\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
