{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dfs form a folder and merge them on ID\n",
    "\"\"\" path = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/\"\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(path + file)\n",
    "    else:\n",
    "        df = pd.merge(df, pd.read_csv(path + file), on='ID') \"\"\"\n",
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df = label_df[['ID', 'label_age_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "Left-Lateral-Ventricle\n",
      "Left-Inf-Lat-Vent\n",
      "Left-Cerebellum-White-Matter\n",
      "Left-Cerebellum-Cortex\n",
      "Left-Thalamus\n",
      "Left-Caudate\n",
      "Left-Putamen\n",
      "Left-Pallidum\n",
      "3rd-Ventricle\n",
      "4th-Ventricle\n",
      "Brain-Stem\n",
      "Left-Hippocampus\n",
      "Left-Amygdala\n",
      "CSF\n",
      "Left-Accumbens-area\n",
      "Left-VentralDC\n",
      "Left-vessel\n",
      "Left-choroid-plexus\n",
      "Right-Lateral-Ventricle\n",
      "Right-Inf-Lat-Vent\n",
      "Right-Cerebellum-White-Matter\n",
      "Right-Cerebellum-Cortex\n",
      "Right-Thalamus\n",
      "Right-Caudate\n",
      "Right-Putamen\n",
      "Right-Pallidum\n",
      "Right-Hippocampus\n",
      "Right-Amygdala\n",
      "Right-Accumbens-area\n",
      "Right-VentralDC\n",
      "Right-vessel\n",
      "Right-choroid-plexus\n",
      "5th-Ventricle\n",
      "WM-hypointensities\n",
      "Left-WM-hypointensities\n",
      "Right-WM-hypointensities\n",
      "non-WM-hypointensities\n",
      "Left-non-WM-hypointensities\n",
      "Right-non-WM-hypointensities\n",
      "Optic-Chiasm\n",
      "CC_Posterior\n",
      "CC_Mid_Posterior\n",
      "CC_Central\n",
      "CC_Mid_Anterior\n",
      "CC_Anterior\n",
      "BrainSegVol\n",
      "lhCortexVol\n",
      "rhCortexVol\n",
      "CortexVol\n",
      "lhCerebralWhiteMatterVol\n",
      "rhCerebralWhiteMatterVol\n",
      "CerebralWhiteMatterVol\n",
      "SubCortGrayVol\n",
      "TotalGrayVol\n",
      "SupraTentorialVol\n",
      "SupraTentorialVolNotVent\n",
      "lh_bankssts_volume\n",
      "lh_caudalanteriorcingulate_volume\n",
      "lh_caudalmiddlefrontal_volume\n",
      "lh_cuneus_volume\n",
      "lh_entorhinal_volume\n",
      "lh_fusiform_volume\n",
      "lh_inferiorparietal_volume\n",
      "lh_inferiortemporal_volume\n",
      "lh_isthmuscingulate_volume\n",
      "lh_lateraloccipital_volume\n",
      "lh_lateralorbitofrontal_volume\n",
      "lh_lingual_volume\n",
      "lh_medialorbitofrontal_volume\n",
      "lh_middletemporal_volume\n",
      "lh_parahippocampal_volume\n",
      "lh_paracentral_volume\n",
      "lh_parsopercularis_volume\n",
      "lh_parsorbitalis_volume\n",
      "lh_parstriangularis_volume\n",
      "lh_pericalcarine_volume\n",
      "lh_postcentral_volume\n",
      "lh_posteriorcingulate_volume\n",
      "lh_precentral_volume\n",
      "lh_precuneus_volume\n",
      "lh_rostralanteriorcingulate_volume\n",
      "lh_rostralmiddlefrontal_volume\n",
      "lh_superiorfrontal_volume\n",
      "lh_superiorparietal_volume\n",
      "lh_superiortemporal_volume\n",
      "lh_supramarginal_volume\n",
      "lh_frontalpole_volume\n",
      "lh_temporalpole_volume\n",
      "lh_transversetemporal_volume\n",
      "lh_insula_volume\n",
      "rh_bankssts_volume\n",
      "rh_caudalanteriorcingulate_volume\n",
      "rh_caudalmiddlefrontal_volume\n",
      "rh_cuneus_volume\n",
      "rh_entorhinal_volume\n",
      "rh_fusiform_volume\n",
      "rh_inferiorparietal_volume\n",
      "rh_inferiortemporal_volume\n",
      "rh_isthmuscingulate_volume\n",
      "rh_lateraloccipital_volume\n",
      "rh_lateralorbitofrontal_volume\n",
      "rh_lingual_volume\n",
      "rh_medialorbitofrontal_volume\n",
      "rh_middletemporal_volume\n",
      "rh_parahippocampal_volume\n",
      "rh_paracentral_volume\n",
      "rh_parsopercularis_volume\n",
      "rh_parsorbitalis_volume\n",
      "rh_parstriangularis_volume\n",
      "rh_pericalcarine_volume\n",
      "rh_postcentral_volume\n",
      "rh_posteriorcingulate_volume\n",
      "rh_precentral_volume\n",
      "rh_precuneus_volume\n",
      "rh_rostralanteriorcingulate_volume\n",
      "rh_rostralmiddlefrontal_volume\n",
      "rh_superiorfrontal_volume\n",
      "rh_superiorparietal_volume\n",
      "rh_superiortemporal_volume\n",
      "rh_supramarginal_volume\n",
      "rh_frontalpole_volume\n",
      "rh_temporalpole_volume\n",
      "rh_transversetemporal_volume\n",
      "rh_insula_volume\n",
      "lh_bankssts_thickness\n",
      "lh_caudalanteriorcingulate_thickness\n",
      "lh_caudalmiddlefrontal_thickness\n",
      "lh_cuneus_thickness\n",
      "lh_entorhinal_thickness\n",
      "lh_fusiform_thickness\n",
      "lh_inferiorparietal_thickness\n",
      "lh_inferiortemporal_thickness\n",
      "lh_isthmuscingulate_thickness\n",
      "lh_lateraloccipital_thickness\n",
      "lh_lateralorbitofrontal_thickness\n",
      "lh_lingual_thickness\n",
      "lh_medialorbitofrontal_thickness\n",
      "lh_middletemporal_thickness\n",
      "lh_parahippocampal_thickness\n",
      "lh_paracentral_thickness\n",
      "lh_parsopercularis_thickness\n",
      "lh_parsorbitalis_thickness\n",
      "lh_parstriangularis_thickness\n",
      "lh_pericalcarine_thickness\n",
      "lh_postcentral_thickness\n",
      "lh_posteriorcingulate_thickness\n",
      "lh_precentral_thickness\n",
      "lh_precuneus_thickness\n",
      "lh_rostralanteriorcingulate_thickness\n",
      "lh_rostralmiddlefrontal_thickness\n",
      "lh_superiorfrontal_thickness\n",
      "lh_superiorparietal_thickness\n",
      "lh_superiortemporal_thickness\n",
      "lh_supramarginal_thickness\n",
      "lh_frontalpole_thickness\n",
      "lh_temporalpole_thickness\n",
      "lh_transversetemporal_thickness\n",
      "lh_insula_thickness\n",
      "rh_bankssts_thickness\n",
      "rh_caudalanteriorcingulate_thickness\n",
      "rh_caudalmiddlefrontal_thickness\n",
      "rh_cuneus_thickness\n",
      "rh_entorhinal_thickness\n",
      "rh_fusiform_thickness\n",
      "rh_inferiorparietal_thickness\n",
      "rh_inferiortemporal_thickness\n",
      "rh_isthmuscingulate_thickness\n",
      "rh_lateraloccipital_thickness\n",
      "rh_lateralorbitofrontal_thickness\n",
      "rh_lingual_thickness\n",
      "rh_medialorbitofrontal_thickness\n",
      "rh_middletemporal_thickness\n",
      "rh_parahippocampal_thickness\n",
      "rh_paracentral_thickness\n",
      "rh_parsopercularis_thickness\n",
      "rh_parsorbitalis_thickness\n",
      "rh_parstriangularis_thickness\n",
      "rh_pericalcarine_thickness\n",
      "rh_postcentral_thickness\n",
      "rh_posteriorcingulate_thickness\n",
      "rh_precentral_thickness\n",
      "rh_precuneus_thickness\n",
      "rh_rostralanteriorcingulate_thickness\n",
      "rh_rostralmiddlefrontal_thickness\n",
      "rh_superiorfrontal_thickness\n",
      "rh_superiorparietal_thickness\n",
      "rh_superiortemporal_thickness\n",
      "rh_supramarginal_thickness\n",
      "rh_frontalpole_thickness\n",
      "rh_temporalpole_thickness\n",
      "rh_transversetemporal_thickness\n",
      "rh_insula_thickness\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "label_age_group\n"
     ]
    }
   ],
   "source": [
    "for col in label_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes on ID\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"label_age_group\"].value_counts()\n",
    "merged_df.dropna(inplace=True)\n",
    "merged_df = merged_df[:5000]\n",
    "\n",
    "#drop specific labels for label_age_group\n",
    "merged_df = merged_df[merged_df.label_age_group != 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged_df[\"label_age_group\"]\n",
    "X = merged_df.drop([\"ID\", \"label_age_group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = TabPFNClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.8006426e-02, 2.3731786e-01, 5.2714503e-01, 1.5932712e-01,\n",
       "        8.1425626e-03, 6.0971695e-05],\n",
       "       [1.9714711e-02, 1.4076862e-01, 6.0184282e-01, 2.2850320e-01,\n",
       "        9.1365017e-03, 3.4197707e-05],\n",
       "       [1.9087957e-02, 9.6702002e-02, 4.9293342e-01, 3.0362391e-01,\n",
       "        8.7134972e-02, 5.1772047e-04],\n",
       "       ...,\n",
       "       [7.4865562e-01, 2.3717251e-01, 1.4094172e-02, 6.4441672e-05,\n",
       "        1.9843835e-06, 1.1266379e-05],\n",
       "       [1.2798468e-05, 3.3025342e-04, 4.2571291e-02, 4.2813656e-01,\n",
       "        5.1963097e-01, 9.3181496e-03],\n",
       "       [1.4870409e-04, 6.1067315e-03, 2.4943218e-01, 6.2254393e-01,\n",
       "        1.2149446e-01, 2.7403640e-04]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4328604e-02, 1.1596132e-01, 4.3027234e-01, 3.4184331e-01,\n",
       "        6.5969616e-02, 1.6248203e-03],\n",
       "       [7.9834503e-01, 1.8716162e-01, 1.4283202e-02, 1.7531322e-04,\n",
       "        1.0635091e-05, 2.4257262e-05],\n",
       "       [5.8953266e-04, 1.7152051e-02, 3.9571822e-01, 5.3615361e-01,\n",
       "        5.0278697e-02, 1.0778865e-04],\n",
       "       ...,\n",
       "       [1.2077820e-02, 7.4445002e-02, 4.5496869e-01, 3.6415887e-01,\n",
       "        9.3537904e-02, 8.1164378e-04],\n",
       "       [7.6668406e-01, 2.1025951e-01, 2.2039991e-02, 8.5297041e-04,\n",
       "        8.4699328e-05, 7.8813006e-05],\n",
       "       [5.1594037e-05, 1.1093366e-03, 4.5414258e-02, 2.9041108e-01,\n",
       "        6.4175522e-01, 2.1258553e-02]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1650,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "# ROC AUC for multiclass using 'macro' average\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8672360971768458\n",
      "Accuracy: 0.5363636363636364\n",
      "Balanced Accuracy: 0.4515987180634366\n",
      "Random Balanced Accuracy: 0.16962069218414957\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.63      0.71      0.67       175\n",
      "         1.0       0.46      0.30      0.37       207\n",
      "         2.0       0.52      0.61      0.56       488\n",
      "         3.0       0.47      0.47      0.47       450\n",
      "         4.0       0.64      0.61      0.63       308\n",
      "         5.0       0.00      0.00      0.00        22\n",
      "\n",
      "    accuracy                           0.54      1650\n",
      "   macro avg       0.45      0.45      0.45      1650\n",
      "weighted avg       0.53      0.54      0.53      1650\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use xgboost\n",
    "xg_clf = xgb.XGBClassifier()\n",
    "xg_clf.fit(X_train, y_train)\n",
    "y_pred = xg_clf.predict(X_test)\n",
    "y_pred_proba = xg_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8309836256750626\n",
      "Accuracy: 0.49454545454545457\n",
      "Balanced Accuracy: 0.39428666244607385\n",
      "Random Balanced Accuracy: 0.16409731610896594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.60      0.53      0.56       346\n",
      "         1.0       0.37      0.19      0.25       405\n",
      "         2.0       0.48      0.61      0.54       966\n",
      "         3.0       0.45      0.47      0.46       903\n",
      "         4.0       0.59      0.57      0.58       631\n",
      "         5.0       0.00      0.00      0.00        49\n",
      "\n",
      "    accuracy                           0.49      3300\n",
      "   macro avg       0.41      0.39      0.40      3300\n",
      "weighted avg       0.48      0.49      0.48      3300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify on onther dataset\n",
    "df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/aseg.volume_aparc.thickness_aparc.volume.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df = label_df[['ID', 'label_age_group']]\n",
    "df_control = df_control[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label and the data\n",
    "merged_df_control = pd.merge(df_control, label_df, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X = merged_df_control.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "y = merged_df_control[\"label_age_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintest split but just getting train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=None, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "162"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#check that the colum order is the same for df and control give back false if not so\n",
    "print(all(X.columns == X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "/zi/home/esra.lenz/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred_control = clf.predict(X_train)\n",
    "y_pred_proba_control = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_score shape: 162\n",
      "y_true shape: (162, 6)\n",
      "y_pred shape: (162,)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_score shape:\", len(y_train))\n",
    "print(\"y_true shape:\", y_pred_proba_control.shape)\n",
    "print(\"y_pred shape:\", y_pred_control.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of classes in y_true not equal to the number of columns in 'y_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ROC\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#auc = roc_auc_score(y_control, y_pred_proba_control, multi_class='ovr', average='macro')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m auc_control \u001b[38;5;241m=\u001b[39m \u001b[43mroc_auc_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_proba_control\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43movr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmacro\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(y_train, y_pred_control)\n\u001b[1;32m      5\u001b[0m balanced_acc \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_train, y_pred_control)\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:635\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_class must be in (\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124movr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 635\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_multiclass_roc_auc_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    639\u001b[0m     labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y_true)\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:752\u001b[0m, in \u001b[0;36m_multiclass_roc_auc_score\u001b[0;34m(y_true, y_score, labels, multi_class, average, sample_weight)\u001b[0m\n\u001b[1;32m    750\u001b[0m     classes \u001b[38;5;241m=\u001b[39m _unique(y_true)\n\u001b[1;32m    751\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(classes) \u001b[38;5;241m!=\u001b[39m y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m--> 752\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    753\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of classes in y_true not equal to the number of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    754\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_score\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    755\u001b[0m         )\n\u001b[1;32m    757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multi_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124movo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes in y_true not equal to the number of columns in 'y_score'"
     ]
    }
   ],
   "source": [
    "#ROC\n",
    "#auc = roc_auc_score(y_control, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "auc_control = roc_auc_score(y_train, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "acc = accuracy_score(y_train, y_pred_control)\n",
    "balanced_acc = balanced_accuracy_score(y_train, y_pred_control)\n",
    "report = classification_report(y_train, y_pred_control)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_train))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_train.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred_control)\n",
    "\n",
    "#print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [217, 1650]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ROC AUC for multiclass using 'macro' average\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#auc = roc_auc_score(y_control, y_pred_proba, multi_class='ovr', average='macro')\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_control\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m balanced_acc \u001b[38;5;241m=\u001b[39m balanced_accuracy_score(y_control, y_pred)\n\u001b[1;32m      6\u001b[0m report \u001b[38;5;241m=\u001b[39m classification_report(y_control, y_pred)\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:227\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m    226\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m--> 227\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    228\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/metrics/_classification.py:98\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \n\u001b[1;32m     73\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(y_true, y_pred)\n\u001b[0;32m---> 98\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    100\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/NAKO_CLIP/lib/python3.11/site-packages/sklearn/utils/validation.py:475\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    473\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 475\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    476\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    477\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    478\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [217, 1650]"
     ]
    }
   ],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "#auc = roc_auc_score(y_control, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_control, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_control, y_pred)\n",
    "report = classification_report(y_control, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_control))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_control.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
