{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import pandas as pd\n",
    "import os\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all dfs form a folder and merge them on ID\n",
    "\"\"\" path = \"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/\"\n",
    "for i, file in enumerate(os.listdir(path)):\n",
    "    if i == 0:\n",
    "        df = pd.read_csv(path + file)\n",
    "    else:\n",
    "        df = pd.merge(df, pd.read_csv(path + file), on='ID') \"\"\"\n",
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df = label_df[['ID', 'label_age_group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in label_df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the dataframes on ID\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"label_age_group\"].value_counts()\n",
    "merged_df.dropna(inplace=True)\n",
    "merged_df = merged_df[:5000]\n",
    "\n",
    "#drop specific labels for label_age_group\n",
    "merged_df = merged_df[merged_df.label_age_group != 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = merged_df[\"label_age_group\"]\n",
    "X = merged_df.drop([\"ID\", \"label_age_group\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = TabPFNClassifier()\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "# ROC AUC for multiclass using 'macro' average\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use xgboost\n",
    "xg_clf = xgb.XGBClassifier()\n",
    "xg_clf.fit(X_train, y_train)\n",
    "y_pred = xg_clf.predict(X_test)\n",
    "y_pred_proba = xg_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_test))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_test.shape)\n",
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verify on onther dataset\n",
    "df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/aseg.volume_aparc.thickness_aparc.volume.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df = label_df[['ID', 'label_age_group']]\n",
    "df_control = df_control[df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the label and the data\n",
    "merged_df_control = pd.merge(df_control, label_df, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X = merged_df_control.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "y = merged_df_control[\"label_age_group\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traintest split but just getting train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=None, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that the colum order is the same for df and control give back false if not so\n",
    "print(all(X.columns == X_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_control = clf.predict(X_train)\n",
    "y_pred_proba_control = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_score shape:\", len(y_train))\n",
    "print(\"y_true shape:\", y_pred_proba_control.shape)\n",
    "print(\"y_pred shape:\", y_pred_control.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC\n",
    "#auc = roc_auc_score(y_control, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "auc_control = roc_auc_score(y_train, y_pred_proba_control, multi_class='ovr', average='macro')\n",
    "acc = accuracy_score(y_train, y_pred_control)\n",
    "balanced_acc = balanced_accuracy_score(y_train, y_pred_control)\n",
    "report = classification_report(y_train, y_pred_control)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_train))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_train.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred_control)\n",
    "\n",
    "#print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC AUC for multiclass using 'macro' average\n",
    "#auc = roc_auc_score(y_control, y_pred_proba, multi_class='ovr', average='macro')\n",
    "\n",
    "acc = accuracy_score(y_control, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_control, y_pred)\n",
    "report = classification_report(y_control, y_pred)\n",
    "\n",
    "# For random comparison, use the number of classes instead of 2\n",
    "n_classes = len(np.unique(y_control))\n",
    "random_y_test = np.random.randint(0, n_classes, size=y_control.shape)\n",
    "random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROC AUC: {auc}\")\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "print(f\"Random Balanced Accuracy: {random_balanced_acc}\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
