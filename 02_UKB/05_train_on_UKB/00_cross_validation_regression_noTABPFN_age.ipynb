{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "import lightgbm as lgb\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mlp_model(input_shape):\n",
    "    model = Sequential([\n",
    "        layers.Dense(1024, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation=\"linear\")  # regression output\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    return model\n",
    "\n",
    "def create_cnn_model(input_shape):\n",
    "    # input_shape should be (n_features, 1)\n",
    "    model = Sequential([\n",
    "        layers.Conv1D(128, kernel_size=3, activation='relu', input_shape=(input_shape[0], 1)),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='linear')  # regression output\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_cuda(model):\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    print(\"CUDA memory cleared and model deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_best_corr_with_target(X, X_val, X_control, y, threshold=0.6, df_columns=None, number_of_features=40):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.Series(y)\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    correlation_matrix = X.corrwith(y).abs()\n",
    "    to_keep = correlation_matrix.sort_values(ascending=False).head(number_of_features).index\n",
    "    X = X[to_keep]\n",
    "    X_val = X_val[to_keep]\n",
    "    X_control = X_control[to_keep]\n",
    "    return X.to_numpy().copy(), X_val.to_numpy().copy(), X_control.to_numpy().copy()\n",
    "\n",
    "def feature_extraction_with_Pearson(X, X_val, X_control, y, threshold=0.6, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    correlation_matrix = X.corr().abs()\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X = X.drop(columns=to_drop)\n",
    "    X_val = X_val.drop(columns=to_drop)\n",
    "    X_control = X_control.drop(columns=to_drop)\n",
    "    return X.to_numpy().copy(), X_val.to_numpy().copy(), X_control.to_numpy().copy()\n",
    "\n",
    "def feature_extration_with_PCA(X, X_val, X_control, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X), pca.transform(X_val), pca.transform(X_control)\n",
    "\n",
    "def feature_extration_with_BE(X, X_val, X_control, y, significance_level=0.05, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    X = sm.add_constant(X)\n",
    "    while True:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            print(f\"Removing {feature_to_remove} with p-value {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "            X_val = X_val.drop(columns=[feature_to_remove])\n",
    "            X_control = X_control.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "        print(\"Final Feature length: \", len(X.columns))\n",
    "    X_ret = X.drop(columns=['const']).to_numpy().copy()\n",
    "    return X_ret, X_val.to_numpy().copy(), X_control.to_numpy().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation_coefficient(y_true, y_pred):\n",
    "    if len(y_true) <= 1 or len(y_pred) <= 1:\n",
    "        raise ValueError(\"Pearson correlation requires at least two points in each array.\")\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"y_true and y_pred must have the same length.\")\n",
    "\n",
    "    # Convert input to pandas series (if not already)\n",
    "    y_true = pd.Series(y_true).astype(int)\n",
    "    y_pred = pd.Series(y_pred).astype(int)\n",
    "\n",
    "    # Check for NaNs or infinite values\n",
    "    if y_true.isna().any() or y_pred.isna().any():\n",
    "        raise ValueError(\"Input contains NaN values.\")\n",
    "    if not np.isfinite(y_true).all() or not np.isfinite(y_pred).all():\n",
    "        raise ValueError(\"Input contains infinite values.\")\n",
    "\n",
    "    # Compute and return the correlation\n",
    "    result = y_true.corr(y_pred)\n",
    "    if np.isnan(result):\n",
    "        return 0.0\n",
    "    return result\n",
    "\n",
    "def evaluate_regression_performance(y_true, y_pred, title=\"\"):\n",
    "    y_pred = np.round(y_pred).astype(int)\n",
    "    #round y_true and make it an array\n",
    "    y_true = np.round(np.array(y_true)).astype(int)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    pearson = pearson_correlation_coefficient(y_true, y_pred)\n",
    "    results = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'pearson': pearson\n",
    "    }\n",
    "    print(f\"\\n {title} Regressor Performance:\")\n",
    "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, Pearson: {pearson:.4f}\")\n",
    "    return results\n",
    "\n",
    "def aggregate_cv_metrics_and_print(all_results, model_name, tag=\"Validation\"):\n",
    "    aggregated = {'mse': [], 'mae': [], 'r2': [], 'pearson': []}\n",
    "    for result in all_results:\n",
    "        aggregated['mse'].append(result['mse'])\n",
    "        aggregated['mae'].append(result['mae'])\n",
    "        aggregated['r2'].append(result['r2'])\n",
    "        aggregated['pearson'].append(result['pearson'])\n",
    "    summary = {\n",
    "        'mean_mse': np.mean(aggregated['mse']),\n",
    "        'std_mse': np.std(aggregated['mse']),\n",
    "        'mean_mae': np.mean(aggregated['mae']),\n",
    "        'std_mae': np.std(aggregated['mae']),\n",
    "        'mean_r2': np.mean(aggregated['r2']),\n",
    "        'std_r2': np.std(aggregated['r2']),\n",
    "        'mean_pearson': np.mean(aggregated['pearson']),\n",
    "    }\n",
    "    print(f\"\\n {model_name} Regressor Performance {tag}:\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_age_group\n",
      "7.0    1482\n",
      "8.0    1471\n",
      "6.0    1360\n",
      "5.0    1257\n",
      "4.0    1083\n",
      "9.0    1052\n",
      "3.0     959\n",
      "2.0     812\n",
      "1.0     356\n",
      "0.0     168\n",
      "Name: count, dtype: int64\n",
      "Total samples: 10000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_col= \"label_Age\"\n",
    "straticify_col = \"label_age_group\"\n",
    "\n",
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/age_label\", exist_ok=True)\n",
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age\", exist_ok=True)\n",
    "mri_table = \"aseg.volume_aparc.volume_aparc.thickness.csv\"\n",
    "\"\"\" # Load the age data\n",
    "command = \"dx download file-GyGfBQ8J34gPK8XXxbjYGbg4 --output /opt/notebooks/TABPFN/02_UKB/00_data/age_label/all_ages_all_ids_healthy.csv --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "#load mri data\n",
    "command = f\"dx download file-GyGf9vjJ34g2g9QbJQ7P1qZG --output '/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age/{mri_table}' --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True) \"\"\"\n",
    "\n",
    "# Load the age data middle\n",
    "command = \"dx download file-GyJp51jJ34g246Y7bZ6j7yK4 --output /opt/notebooks/TABPFN/02_UKB/00_data/age_label/all_ages_all_ids_healthy.csv --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "#load mri data cleand and renamed but age\n",
    "command = f\"dx download file-GyJp6B0J34g8xpf6Q6jz12xJ --output '/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age/{mri_table}' --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "df = pd.read_csv(f\"../00_data/deconfounded_but_age/{mri_table}\")\n",
    "label_df = pd.read_csv(\"../00_data/age_label/all_ages_all_ids_healthy.csv\")\n",
    "n_splits = 5\n",
    "label_df = label_df[['ID', label_col, straticify_col]]\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "label_counts = merged_df[straticify_col].value_counts()\n",
    "\n",
    "# Include all rows for groups with fewer samples than the target threshold\n",
    "threshold = 1000  # You can adjust this threshold as needed\n",
    "small_groups = label_counts[label_counts <= threshold].index\n",
    "small_groups_df = merged_df[merged_df[straticify_col].isin(small_groups)]\n",
    "\n",
    "# Calculate how many more samples are needed to reach 10,000\n",
    "remaining_needed = 10000 - len(small_groups_df)\n",
    "\n",
    "# Sample proportionally from the larger groups\n",
    "large_groups = label_counts[label_counts > threshold].index\n",
    "large_groups_df = merged_df[merged_df[straticify_col].isin(large_groups)]\n",
    "\n",
    "# Stratified sampling from the remaining data\n",
    "proportional_sampled_df, _ = train_test_split(\n",
    "    large_groups_df, \n",
    "    train_size=remaining_needed, \n",
    "    stratify=large_groups_df[straticify_col], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine the small groups and the proportional sample\n",
    "final_sampled_df = pd.concat([small_groups_df, proportional_sampled_df])\n",
    "\n",
    "# Verify the result\n",
    "print(final_sampled_df[straticify_col].value_counts())\n",
    "print(f\"Total samples: {len(final_sampled_df)}\")\n",
    "if label_col != straticify_col:\n",
    "    final_sampled_df.drop(columns=[straticify_col], inplace=True)\n",
    "final_sampled_df[label_col].hist()\n",
    "df_sampled = final_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only 250 samples available after balanced sampling.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/\", exist_ok=True)\n",
    "#load middle age control data\n",
    "command = \"dx download file-GyK09JQJ34g95zyvV9vFxQFv --output /opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/all_ages_all_ids_subset_middle_age.csv --overwrite\"\n",
    "subprocess.run(command, shell=True)\n",
    "#load mri data\n",
    "command = \"dx download file-GyK08xjJ34g95zyvV9vFxQFf --output /opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/aparc.thickness_aseg.volume_aparc.volume_deconfounded_but_age.csv --overwrite\"\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "label_df_control = pd.read_csv(\"../00_data/validation_data/00_National_Cohort/all_ages_all_ids_subset_middle_age.csv\")\n",
    "df_control = pd.read_csv(\"../00_data/validation_data/00_National_Cohort/aparc.thickness_aseg.volume_aparc.volume_deconfounded_but_age.csv\")\n",
    "\n",
    "label_df_control = label_df_control[['ID', straticify_col, label_col]]\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "#sample 400 so that from each group 25 samples if possible\n",
    "target_samples_per_group = 25\n",
    "grouped_df = merged_df_control.groupby(straticify_col)\n",
    "\n",
    "# Sample 25 from each group if possible, otherwise sample all available\n",
    "sampled_control = grouped_df.apply(lambda x: x.sample(n=min(target_samples_per_group, len(x)), random_state=42))\n",
    "\n",
    "# Reset the index after sampling\n",
    "sampled_control.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if we reached the desired total number of 400 samples\n",
    "if len(sampled_control) < 400:\n",
    "    print(f\"Only {len(sampled_control)} samples available after balanced sampling.\")\n",
    "else:\n",
    "    print(f\"Sampled {len(sampled_control)} rows with balanced distribution across groups.\")\n",
    "\n",
    "X_control_source = sampled_control.drop([\"ID\", label_col], axis=1)\n",
    "y_control_source = sampled_control[label_col]\n",
    "control_ids = sampled_control[\"ID\"]\n",
    "y_control_source.hist(bins=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_control = df_sampled.drop([label_col, \"ID\"], axis=1).columns\n",
    "X_control = X_control_source[column_control]\n",
    "y_control_max = y_control_source.max()\n",
    "y_control_min = y_control_source.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_control.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " #### TRAINING WITH 0.1 OF THE DATA ####\n",
      "Training data shape: (1000, 192), number of samples: 1000\n",
      "\n",
      "=== Deconfounding Strategy: Nothing ===\n",
      "\n",
      "Fold 1\n",
      "\n",
      " Random - Test Regressor Performance:\n",
      "MSE: 105.2050, MAE: 8.3650, R2: -1.0322, Pearson: 0.1417\n",
      "\n",
      " Random - Control Regressor Performance:\n",
      "MSE: 146.4560, MAE: 9.8640, R2: -1.0186, Pearson: -0.0383\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      " CNN - Test Regressor Performance:\n",
      "MSE: 69.5500, MAE: 6.7900, R2: -0.3434, Pearson: 0.0860\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      " CNN - Control Regressor Performance:\n",
      "MSE: 155.4840, MAE: 9.7880, R2: -1.1431, Pearson: 0.2175\n",
      "CUDA memory cleared and model deleted.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\n",
      " MLP - Test Regressor Performance:\n",
      "MSE: 92.4650, MAE: 7.6550, R2: -0.7861, Pearson: 0.3814\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " MLP - Control Regressor Performance:\n",
      "MSE: 137.8400, MAE: 8.7680, R2: -0.8999, Pearson: 0.3822\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " LGBM - Test Regressor Performance:\n",
      "MSE: 30.5450, MAE: 4.4350, R2: 0.4100, Pearson: 0.6424\n",
      "\n",
      " LGBM - Control Regressor Performance:\n",
      "MSE: 52.8600, MAE: 5.9720, R2: 0.2714, Pearson: 0.6559\n",
      "\n",
      "Fold 2\n",
      "\n",
      " Random - Test Regressor Performance:\n",
      "MSE: 135.2800, MAE: 9.6200, R2: -1.4700, Pearson: -0.1532\n",
      "\n",
      " Random - Control Regressor Performance:\n",
      "MSE: 125.6040, MAE: 9.3320, R2: -0.7312, Pearson: 0.0522\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\n",
      " CNN - Test Regressor Performance:\n",
      "MSE: 227.7700, MAE: 7.1600, R2: -3.1587, Pearson: 0.1805\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      " CNN - Control Regressor Performance:\n",
      "MSE: 220.9280, MAE: 12.0480, R2: -2.0451, Pearson: 0.3076\n",
      "CUDA memory cleared and model deleted.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\n",
      " MLP - Test Regressor Performance:\n",
      "MSE: 3188.0500, MAE: 12.7900, R2: -57.2080, Pearson: 0.1140\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
      "\n",
      " MLP - Control Regressor Performance:\n",
      "MSE: 160.8800, MAE: 9.8240, R2: -1.2175, Pearson: 0.2135\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " LGBM - Test Regressor Performance:\n",
      "MSE: 35.1350, MAE: 4.7150, R2: 0.3585, Pearson: 0.6110\n",
      "\n",
      " LGBM - Control Regressor Performance:\n",
      "MSE: 50.7600, MAE: 5.8800, R2: 0.3004, Pearson: 0.6380\n",
      "\n",
      "Fold 3\n",
      "\n",
      " Random - Test Regressor Performance:\n",
      "MSE: 104.6100, MAE: 8.4800, R2: -1.2198, Pearson: 0.0831\n",
      "\n",
      " Random - Control Regressor Performance:\n",
      "MSE: 144.8360, MAE: 9.8600, R2: -0.9963, Pearson: -0.0659\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\n",
      " CNN - Test Regressor Performance:\n",
      "MSE: 74.2450, MAE: 6.9250, R2: -0.5754, Pearson: 0.2109\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
      "\n",
      " CNN - Control Regressor Performance:\n",
      "MSE: 119.9240, MAE: 8.6200, R2: -0.6529, Pearson: 0.2338\n",
      "CUDA memory cleared and model deleted.\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "# You can adjust these percentages as needed\n",
    "percentage_of_the_data = [0.1]\n",
    "deconfounding_strategies = [\"Nothing\"]\n",
    "\n",
    "# Dictionary to store aggregated CV metrics for each percentage and deconfounding strategy\n",
    "percentage_dict = {}\n",
    "\n",
    "# Lists to record individual predictions (for test and control sets)\n",
    "test_predictions_records = []    # will include real outcomes and predictions (test set from CV)\n",
    "control_predictions_records = [] # will include real outcomes and predictions (control set)\n",
    "\n",
    "# We will also record random-baseline metrics (using random predictions drawn from uniform [0,1])\n",
    "random_results = []            # for test set performance\n",
    "random_results_eval = []       # for control set evaluation (if desired)\n",
    "\n",
    "# For each deconfounding strategy and percentage, we will also collect model metrics\n",
    "# We will collect separate lists for test-set (\"cv_results\") and control-set (\"cv_results_eval\")\n",
    "for percentage in percentage_of_the_data:\n",
    "    percentage_dict[percentage] = {}\n",
    "    \n",
    "    # Subsample the training data as needed\n",
    "    if percentage == 1:\n",
    "        df_sampled_subset = df_sampled.copy()\n",
    "    else:\n",
    "        df_sampled_subset, _ = train_test_split(\n",
    "            df_sampled,\n",
    "            train_size=percentage,\n",
    "            random_state=42\n",
    "        )\n",
    "    print(f\"\\n #### TRAINING WITH {percentage} OF THE DATA ####\")\n",
    "    # Separate IDs, outcomes, and features\n",
    "    ids = df_sampled_subset[\"ID\"]\n",
    "    y = df_sampled_subset[label_col]\n",
    "    X = df_sampled_subset.drop([\"ID\", label_col], axis=1)\n",
    "    \n",
    "    print(f\"Training data shape: {X.shape}, number of samples: {len(y)}\")\n",
    "    \n",
    "    for deconfounding_strategy in deconfounding_strategies:\n",
    "        print(f\"\\n=== Deconfounding Strategy: {deconfounding_strategy} ===\")\n",
    "        \n",
    "        # Prepare lists for storing CV metrics (for test set and for control set)\n",
    "        mlp_results = []\n",
    "        cnn_results = []\n",
    "        lgb_results = []\n",
    "        random_results_model = []  # for test-set random baseline\n",
    "        \n",
    "        mlp_results_eval = []\n",
    "        cnn_results_eval = []\n",
    "        lgb_results_eval = []\n",
    "        random_results_eval_model = []  # for control-set random baseline (if desired)\n",
    "        \n",
    "        # Create a KFold object (using KFold for regression)\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold_counter = 0\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            fold_counter += 1\n",
    "            print(f\"\\nFold {fold_counter}\")\n",
    "            X_train, X_test = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "            y_train, y_test = y.iloc[train_index].copy(), y.iloc[val_index].copy()\n",
    "            test_ids = ids.iloc[val_index].copy()\n",
    "            \n",
    "            # Use the entire control set (IDs are stored in control_ids)\n",
    "            X_control = X_control_source.copy()\n",
    "            y_control = y_control_source.copy()\n",
    "            try:\n",
    "                X_control = X_control[X_train.columns]\n",
    "            except Exception as e:\n",
    "                print(\"Columns mismatch between training and control:\", e)\n",
    "            \n",
    "            # Scale the data\n",
    "            df_columns = X_train.columns\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_control_scaled = scaler.transform(X_control)\n",
    "            \n",
    "            # Apply deconfounding / feature extraction strategy\n",
    "            if deconfounding_strategy == \"BE\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extration_with_BE(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"PCA\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extration_with_PCA(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, n_components=50)\n",
    "            elif deconfounding_strategy == \"Correlation_in_Feature\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extraction_with_Pearson(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, threshold=0.6, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"Correlation_with_target\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extraction_best_corr_with_target(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, threshold=0.6, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"Nothing\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = X_train_scaled, X_test_scaled, X_control_scaled\n",
    "            \n",
    "            #############################\n",
    "            # RANDOM BASELINE\n",
    "            #############################\n",
    "            n_samples_test = len(y_test)\n",
    "            # Random predcition between min and max\n",
    "            random_pred = np.random.uniform(y_test.min(), y_test.max(), n_samples_test)\n",
    "            random_pred = np.round(random_pred)\n",
    "            random_metrics = evaluate_regression_performance(y_test, random_pred, title=\"Random - Test\")\n",
    "            random_results_model.append(random_metrics)\n",
    "            \n",
    "            # For control set, random predictions as well:\n",
    "            n_samples_control = len(y_control)\n",
    "            random_control_pred = np.random.uniform(y_test.min(), y_test.max(), n_samples_control)\n",
    "            random_metrics_eval = evaluate_regression_performance(y_control, random_control_pred, title=\"Random - Control\")\n",
    "            random_results_eval_model.append(random_metrics_eval)\n",
    "            \n",
    "            # Record random predictions in the prediction logs (for test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, random_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'Random',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # And for control set\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, random_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'Random',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            \n",
    "            #############################\n",
    "            # CNN Regressor\n",
    "            #############################\n",
    "            # Reshape for CNN: (samples, n_features, 1)\n",
    "            X_train_cnn = X_train_proc.reshape(X_train_proc.shape[0], X_train_proc.shape[1], 1)\n",
    "            X_test_cnn  = X_test_proc.reshape(X_test_proc.shape[0], X_test_proc.shape[1], 1)\n",
    "            X_control_cnn = X_control_proc.reshape(X_control_proc.shape[0], X_control_proc.shape[1], 1)\n",
    "            \n",
    "            cnn_model = create_cnn_model(input_shape=(X_train_proc.shape[1], 1))\n",
    "            cnn_model.fit(X_train_cnn, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "            cnn_pred = cnn_model.predict(X_test_cnn).flatten()\n",
    "            cnn_metrics = evaluate_regression_performance(y_test, cnn_pred, title=\"CNN - Test\")\n",
    "            cnn_results.append(cnn_metrics)\n",
    "            \n",
    "            # Record CNN predictions (test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, cnn_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'CNN',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # Evaluate on control set\n",
    "            cnn_control_pred = cnn_model.predict(X_control_cnn).flatten()\n",
    "            cnn_control_metrics = evaluate_regression_performance(y_control, cnn_control_pred, title=\"CNN - Control\")\n",
    "            cnn_results_eval.append(cnn_control_metrics)\n",
    "            # Record control predictions for CNN\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, cnn_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'CNN',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            clean_up_cuda(cnn_model)\n",
    "            \n",
    "            #############################\n",
    "            # MLP Regressor\n",
    "            #############################\n",
    "            mlp_model = create_mlp_model(input_shape=X_train_proc.shape[1])\n",
    "            mlp_model.fit(X_train_proc, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "            mlp_pred = mlp_model.predict(X_test_proc).flatten()\n",
    "            mlp_metrics = evaluate_regression_performance(y_test, mlp_pred, title=\"MLP - Test\")\n",
    "            mlp_results.append(mlp_metrics)\n",
    "            # Record predictions for MLP (test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, mlp_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'MLP',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # Evaluate on control set\n",
    "            mlp_control_pred = mlp_model.predict(X_control_proc).flatten()\n",
    "            mlp_control_metrics = evaluate_regression_performance(y_control, mlp_control_pred, title=\"MLP - Control\")\n",
    "            mlp_results_eval.append(mlp_control_metrics)\n",
    "            # Record control predictions for MLP\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, mlp_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'MLP',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            clean_up_cuda(mlp_model)\n",
    "            \n",
    "            #############################\n",
    "            # LightGBM Regressor\n",
    "            #############################\n",
    "            lgb_train = lgb.Dataset(X_train_proc, label=y_train)\n",
    "            params = {\n",
    "                'objective': 'regression',\n",
    "                'metric': 'rmse',\n",
    "                'learning_rate': 0.05,\n",
    "                'seed': 42,\n",
    "                'verbose': -1\n",
    "            }\n",
    "            lgb_model = lgb.train(params, lgb_train, num_boost_round=100)\n",
    "            lgb_pred = lgb_model.predict(X_test_proc)\n",
    "            lgb_metrics = evaluate_regression_performance(y_test, lgb_pred, title=\"LGBM - Test\")\n",
    "            lgb_results.append(lgb_metrics)\n",
    "            # Record predictions for LGBM (test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, lgb_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'LGBM',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # Evaluate on control set\n",
    "            lgb_control_pred = lgb_model.predict(X_control_proc)\n",
    "            lgb_control_metrics = evaluate_regression_performance(y_control, lgb_control_pred, title=\"LGBM - Control\")\n",
    "            lgb_results_eval.append(lgb_control_metrics)\n",
    "            # Record control predictions for LGBM\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, lgb_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'LGBM',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # LightGBM does not require GPU clean-up\n",
    "            \n",
    "        # End of CV folds for this deconfounding strategy\n",
    "        \n",
    "        # Aggregate and print performance for each model (test set)\n",
    "        random_summary = aggregate_cv_metrics_and_print(random_results_model, \"Random\")\n",
    "        cnn_summary = aggregate_cv_metrics_and_print(cnn_results, \"CNN\")\n",
    "        mlp_summary = aggregate_cv_metrics_and_print(mlp_results, \"MLP\")\n",
    "        lgb_summary = aggregate_cv_metrics_and_print(lgb_results, \"LGBM\")\n",
    "        \n",
    "        # Aggregate for control set evaluations\n",
    "        random_eval_summary = aggregate_cv_metrics_and_print(random_results_eval_model, \"Random\", tag=\"Control\")\n",
    "        cnn_eval_summary = aggregate_cv_metrics_and_print(cnn_results_eval, \"CNN\", tag=\"Control\")\n",
    "        mlp_eval_summary = aggregate_cv_metrics_and_print(mlp_results_eval, \"MLP\", tag=\"Control\")\n",
    "        lgb_eval_summary = aggregate_cv_metrics_and_print(lgb_results_eval, \"LGBM\", tag=\"Control\")\n",
    "        \n",
    "        # Save results in the dictionary\n",
    "        percentage_dict[percentage][deconfounding_strategy] = {\n",
    "            \"Random\": {\n",
    "                \"results\": random_summary,\n",
    "                \"results_eval\": random_eval_summary,\n",
    "                \"cv_results\": random_results_model,\n",
    "                \"cv_results_eval\": random_results_eval_model\n",
    "            },\n",
    "            \"MLP\": {\n",
    "                \"results\": mlp_summary,\n",
    "                \"results_eval\": mlp_eval_summary,\n",
    "                \"cv_results\": mlp_results,\n",
    "                \"cv_results_eval\": mlp_results_eval\n",
    "            },\n",
    "            \"CNN\": {\n",
    "                \"results\": cnn_summary,\n",
    "                \"results_eval\": cnn_eval_summary,\n",
    "                \"cv_results\": cnn_results,\n",
    "                \"cv_results_eval\": cnn_results_eval\n",
    "            },\n",
    "            \"LGBM\": {\n",
    "                \"results\": lgb_summary,\n",
    "                \"results_eval\": lgb_eval_summary,\n",
    "                \"cv_results\": lgb_results,\n",
    "                \"cv_results_eval\": lgb_results_eval\n",
    "            }\n",
    "        }\n",
    "\n",
    "    # Set these flags as desired\n",
    "    Feature_extraction_applied = False\n",
    "    Pretraining_applied = False\n",
    "    # You can set these flags based on the deconfounding strategy if needed.\n",
    "\n",
    "    all_rows = []\n",
    "    log_file = \"/opt/notebooks/results_regression.csv\"\n",
    "    # Iterate over percentages and their associated models\n",
    "    for percentage, models in percentage_dict.items():\n",
    "        for feat_ext, feature_summary_dict in models.items():\n",
    "            for model_name, summary_dict in feature_summary_dict.items():\n",
    "                # Each summary_dict contains aggregated metrics as well as CV lists.\n",
    "                # Iterate over the number of folds (using the cv_results list)\n",
    "                for i, (cv_result, cv_result_eval) in enumerate(zip(summary_dict[\"cv_results\"], summary_dict[\"cv_results_eval\"])):\n",
    "                    # Prepare training (test set) row\n",
    "                    row_train = {\n",
    "                        \"label_col\": label_col,\n",
    "                        \"mri_table\": mri_table,\n",
    "                        \"test_set_size\": f\"{(1 - percentage):.2%} (approx. of data left for test)\",\n",
    "                        \"Feature_extraction_applied\": Feature_extraction_applied,\n",
    "                        \"Pretraining_applied\": Pretraining_applied,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"mse\": cv_result.get(\"mse\", None),\n",
    "                        \"mae\": cv_result.get(\"mae\", None),\n",
    "                        \"r2\": cv_result.get(\"r2\", None),\n",
    "                        \"pearson\": cv_result.get(\"pearson\", None),\n",
    "                        \"number_of_cross_validations\": n_splits,\n",
    "                        \"cross_validation_count\": i,\n",
    "                        \"search_term\": f\"{percentage}_{feat_ext}_{model_name}_train\",\n",
    "                        \"percentage_of_data\": percentage,\n",
    "                        \"eval_or_train\": \"train\"\n",
    "                    }\n",
    "                    # Prepare evaluation (control set) row\n",
    "                    row_eval = {\n",
    "                        \"label_col\": label_col,\n",
    "                        \"mri_table\": mri_table,\n",
    "                        \"test_set_size\": f\"{(1 - percentage):.2%} (approx. of data left for test)\",\n",
    "                        \"Feature_extraction_applied\": Feature_extraction_applied,\n",
    "                        \"Pretraining_applied\": Pretraining_applied,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"mse\": cv_result_eval.get(\"mse\", None),\n",
    "                        \"mae\": cv_result_eval.get(\"mae\", None),\n",
    "                        \"r2\": cv_result_eval.get(\"r2\", None),\n",
    "                        \"pearson\": cv_result_eval.get(\"pearson\", None),\n",
    "                        \"number_of_cross_validations\": n_splits,\n",
    "                        \"cross_validation_count\": i,\n",
    "                        \"search_term\": f\"{percentage}_{feat_ext}_{model_name}_eval\",\n",
    "                        \"percentage_of_data\": percentage,\n",
    "                        \"eval_or_train\": \"eval\"\n",
    "                    }\n",
    "                    all_rows.append(row_train)\n",
    "                    all_rows.append(row_eval)\n",
    "\n",
    "    # Convert to DataFrame and save CSV\n",
    "    df_results = pd.DataFrame(all_rows)\n",
    "    df_results.to_csv(log_file, index=False)\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_results = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_results.to_csv(log_file, index=False)\n",
    "    logs_path = \"project-GqzxkVQJ34g6ygFJ4ZbvqBYF:/Esra/00_CLIP/01_training_logs/\"\n",
    "    label = os.environ.get(\"DX_JOB_ID\") \n",
    "    logs_path_label = os.path.join(logs_path, label)\n",
    "    dx_mkdir_command = f\"dx mkdir '{logs_path_label}'\"\n",
    "    subprocess.run(dx_mkdir_command, shell=True)\n",
    "    time_tag = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    command_csv = f\"dx upload '{log_file}' --path '{logs_path_label}/{time_tag}_result_tabpfn.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n",
    "\n",
    "    df_test_predictions = pd.DataFrame(test_predictions_records)\n",
    "    df_control_predictions = pd.DataFrame(control_predictions_records)\n",
    "\n",
    "    test_csv_path = \"/opt/notebooks/regression_test_predictions.csv\"\n",
    "    control_csv_path = \"/opt/notebooks/regression_control_predictions.csv\"\n",
    "\n",
    "    df_test_predictions.to_csv(test_csv_path)\n",
    "    df_control_predictions.to_csv(control_csv_path)\n",
    "\n",
    "    print(f\"Saved test predictions to {test_csv_path}\")\n",
    "    print(f\"Saved control predictions to {control_csv_path}\")\n",
    "    command_csv = f\"dx upload '{test_csv_path}' --path '{logs_path_label}/{time_tag}_test_predictions.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n",
    "    command_csv = f\"dx upload '{control_csv_path}' --path '{logs_path_label}/{time_tag}_control_predictions.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
