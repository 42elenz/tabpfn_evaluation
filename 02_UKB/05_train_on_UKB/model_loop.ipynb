{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\")\n",
    "label_df = label_df[['ID', 'label_age_group']]\n",
    "\n",
    "# Merge dataframes\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "# Stratified sampling to maintain label distribution\n",
    "df_sampled, _ = train_test_split(merged_df, train_size=10000, stratify=merged_df[\"label_age_group\"], random_state=42)\n",
    "\n",
    "# Drop specific label\n",
    "df_sampled = df_sampled[df_sampled.label_age_group != 10]\n",
    "\n",
    "# Prepare features and target\n",
    "y = df_sampled[\"label_age_group\"]\n",
    "X = df_sampled.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify=y, random_state=42)\n",
    "\n",
    "# Initialize classifiers\n",
    "models = {\n",
    "    \"TabPFN\": TabPFNClassifier(),\n",
    "    \"LightGBM\": lgb.LGBMClassifier(objective='multiclass', num_class=len(y.unique()), num_leaves=31, learning_rate=0.05, feature_fraction=0.9, random_state=42),\n",
    "    \"MLP\": MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', solver='adam', max_iter=200, random_state=42)\n",
    "}\n",
    "\n",
    "# Training and evaluation\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Handle different class attributes (LightGBM does not have `classes_`)\n",
    "    model_classes = model.classes_ if hasattr(model, 'classes_') else np.unique(y_train)\n",
    "\n",
    "    # Calculate ROC AUC if model supports probability prediction\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        y_test_bin = label_binarize(y_test, classes=model_classes)\n",
    "        auc = roc_auc_score(y_test_bin, y_pred_proba[:, :len(model_classes)], multi_class='ovr', average='macro')\n",
    "    else:\n",
    "        auc = \"N/A (no probability predictions available)\"\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"{name} Results:\")\n",
    "    print(f\"ROC AUC: {auc}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc}\")\n",
    "    print(report)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation on control dataset\n",
    "print(\"\\nValidating models on control dataset...\")\n",
    "df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/deconfounded_but_age/aseg.volume_aparc.thickness_aparc.volume.csv\")\n",
    "label_df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/age_label/all_ages.csv\")\n",
    "\n",
    "label_df_control = label_df_control[['ID', 'label_age_group']]\n",
    "df_control = df_control[df.columns]  # Ensure same features\n",
    "\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X_control = merged_df_control.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "y_control = merged_df_control[\"label_age_group\"]\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nValidating {name}...\")\n",
    "\n",
    "    y_pred_control = model.predict(X_control)\n",
    "\n",
    "    # Handle different class attributes (LightGBM does not have `classes_`)\n",
    "    model_classes = model.classes_ if hasattr(model, 'classes_') else np.unique(y_control)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba_control = model.predict_proba(X_control)\n",
    "\n",
    "        # Ensure probability predictions align with actual classes in control set\n",
    "        present_classes = np.unique(y_control)\n",
    "        class_indices = [np.where(model_classes == cls)[0][0] for cls in present_classes]\n",
    "        y_pred_proba_filtered = y_pred_proba_control[:, class_indices]\n",
    "\n",
    "        # Binarize y_control using the present classes\n",
    "        y_control_bin = label_binarize(y_control, classes=present_classes)\n",
    "\n",
    "        auc_control = roc_auc_score(y_control_bin, y_pred_proba_filtered, multi_class='ovr', average='macro')\n",
    "    else:\n",
    "        auc_control = \"N/A (no probability predictions available)\"\n",
    "\n",
    "    acc_control = accuracy_score(y_control, y_pred_control)\n",
    "    balanced_acc_control = balanced_accuracy_score(y_control, y_pred_control)\n",
    "    report_control = classification_report(y_control, y_pred_control)\n",
    "\n",
    "    print(f\"{name} Control Results:\")\n",
    "    print(f\"ROC AUC: {auc_control}\")\n",
    "    print(f\"Accuracy: {acc_control}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc_control}\")\n",
    "    print(report_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, balanced_accuracy_score, classification_report, make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabpfn import TabPFNClassifier\n",
    "import os\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mlp_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(1024, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "#make scorer for balanced accuracy\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'balanced_accuracy': 'balanced_accuracy',\n",
    "    'roc_auc_ovr': make_scorer(roc_auc_score, multi_class='ovr', average='macro')\n",
    "}\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\")\n",
    "label_df = label_df[['ID', 'label_age_group']]\n",
    "\n",
    "# Merge dataframes\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "# Stratified sampling to maintain label distribution\n",
    "df_sampled, _ = train_test_split(merged_df, train_size=10000, stratify=merged_df[\"label_age_group\"], random_state=42)\n",
    "\n",
    "# Drop specific label\n",
    "df_sampled = df_sampled[df_sampled.label_age_group != 10]\n",
    "\n",
    "y = df_sampled[\"label_age_group\"]\n",
    "X = df_sampled.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "\n",
    "num_classes = len(y.unique())\n",
    "input_shape = X.shape[1]\n",
    "\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"Number of features: {input_shape}\")\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "num_classes = len(y_train.unique()) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# Create pipelines for each model that include normalization\n",
    "def create_keras_mlp_wrapper(input_shape, num_classes):\n",
    "    def wrapper_model():\n",
    "        return create_mlp_model(input_shape, num_classes)\n",
    "    return wrapper_model\n",
    "pipelines = {\n",
    "    \"LightGBM\": Pipeline([('scaler', StandardScaler()), ('model', lgb.LGBMClassifier(objective='multiclass', num_class=len(y.unique()), num_leaves=31, learning_rate=0.05, feature_fraction=0.9, random_state=42))]),\n",
    "    \"TabPFN\": Pipeline([('scaler', StandardScaler()), ('model', TabPFNClassifier())]),\n",
    "    \n",
    "  \n",
    "}\n",
    "\n",
    "# Set up cross-validation\n",
    "cv = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "y_onehot = to_categorical(y)\n",
    "# Training and evaluation with cross-validation\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\nTraining and evaluating {name} with cross-validation...\")\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_validate(pipeline, X, y, cv=cv, scoring=scoring)\n",
    "    \n",
    "    print(f\"{name} Cross-validation Results:\")\n",
    "    for metric in scoring.keys():\n",
    "        mean_score = cv_scores[f'test_{metric}'].mean()\n",
    "        std_score = cv_scores[f'test_{metric}'].std()\n",
    "        print(f\"Mean {metric}: {mean_score:.4f} (+/- {std_score * 2:.4f})\")\n",
    "\n",
    "    # Fit the model on the entire dataset for later use\n",
    "    pipeline.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Validation on control dataset\n",
    "print(\"\\nValidating models on control dataset...\")\n",
    "X_control = merged_df_control.drop([\"ID\", \"label_age_group\"], axis=1)\n",
    "y_control = merged_df_control[\"label_age_group\"]\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    print(f\"\\nValidating {name}...\")\n",
    "\n",
    "    y_pred_control = pipeline.predict(X_control)\n",
    "    \n",
    "    # Get the trained model from the pipeline\n",
    "    model = pipeline.named_steps['model']\n",
    "\n",
    "    # Handle different class attributes\n",
    "    model_classes = model.classes_ if hasattr(model, 'classes_') else np.unique(y)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_pred_proba_control = pipeline.predict_proba(X_control)\n",
    "\n",
    "        # Ensure probability predictions align with actual classes in control set\n",
    "        present_classes = np.unique(y_control)\n",
    "        class_indices = [np.where(model_classes == cls)[0][0] for cls in present_classes]\n",
    "        y_pred_proba_filtered = y_pred_proba_control[:, class_indices]\n",
    "\n",
    "        # Binarize y_control using the present classes\n",
    "        y_control_bin = label_binarize(y_control, classes=present_classes)\n",
    "\n",
    "        auc_control = roc_auc_score(y_control_bin, y_pred_proba_filtered, multi_class='ovr', average='macro')\n",
    "    else:\n",
    "        auc_control = \"N/A (no probability predictions available)\"\n",
    "\n",
    "    acc_control = accuracy_score(y_control, y_pred_control)\n",
    "    balanced_acc_control = balanced_accuracy_score(y_control, y_pred_control)\n",
    "    report_control = classification_report(y_control, y_pred_control)\n",
    "\n",
    "    print(f\"{name} Control Results:\")\n",
    "    print(f\"ROC AUC: {auc_control}\")\n",
    "    print(f\"Accuracy: {acc_control}\")\n",
    "    print(f\"Balanced Accuracy: {balanced_acc_control}\")\n",
    "    print(report_control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
