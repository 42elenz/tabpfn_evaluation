{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import subprocess\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from tabpfn import TabPFNRegressor\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_cuda(model):\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    print(\"CUDA memory cleared and model deleted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_best_corr_with_target(X, X_val, X_control, y, threshold=0.6, df_columns=None, number_of_features=40):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.Series(y)\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    correlation_matrix = X.corrwith(y).abs()\n",
    "    to_keep = correlation_matrix.sort_values(ascending=False).head(number_of_features).index\n",
    "    X = X[to_keep]\n",
    "    X_val = X_val[to_keep]\n",
    "    X_control = X_control[to_keep]\n",
    "    return X.to_numpy().copy(), X_val.to_numpy().copy(), X_control.to_numpy().copy()\n",
    "\n",
    "def feature_extraction_with_Pearson(X, X_val, X_control, y, threshold=0.6, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    correlation_matrix = X.corr().abs()\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X = X.drop(columns=to_drop)\n",
    "    X_val = X_val.drop(columns=to_drop)\n",
    "    X_control = X_control.drop(columns=to_drop)\n",
    "    return X.to_numpy().copy(), X_val.to_numpy().copy(), X_control.to_numpy().copy()\n",
    "\n",
    "def feature_extration_with_PCA(X, X_val, X_control, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X), pca.transform(X_val), pca.transform(X_control)\n",
    "\n",
    "def feature_extration_with_BE(X, X_val, X_control, y, significance_level=0.05, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    X = sm.add_constant(X)\n",
    "    while True:\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        p_values = model.pvalues\n",
    "        max_p_value = p_values.max()\n",
    "        if max_p_value > significance_level:\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            print(f\"Removing {feature_to_remove} with p-value {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "            X_val = X_val.drop(columns=[feature_to_remove])\n",
    "            X_control = X_control.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "        print(\"Final Feature length: \", len(X.columns))\n",
    "    X_ret = X.drop(columns=['const']).to_numpy().copy()\n",
    "    return X_ret, X_val.to_numpy().copy(), X_control.to_numpy().copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_correlation_coefficient(y_true, y_pred):\n",
    "    if len(y_true) <= 1 or len(y_pred) <= 1:\n",
    "        raise ValueError(\"Pearson correlation requires at least two points in each array.\")\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"y_true and y_pred must have the same length.\")\n",
    "\n",
    "    # Convert input to pandas series (if not already)\n",
    "    y_true = pd.Series(y_true).astype(int)\n",
    "    y_pred = pd.Series(y_pred).astype(int)\n",
    "\n",
    "    # Check for NaNs or infinite values\n",
    "    if y_true.isna().any() or y_pred.isna().any():\n",
    "        raise ValueError(\"Input contains NaN values.\")\n",
    "    if not np.isfinite(y_true).all() or not np.isfinite(y_pred).all():\n",
    "        raise ValueError(\"Input contains infinite values.\")\n",
    "\n",
    "    # Compute and return the correlation\n",
    "    result = y_true.corr(y_pred)\n",
    "    if np.isnan(result):\n",
    "        return 0.0\n",
    "    return result\n",
    "\n",
    "def evaluate_regression_performance(y_true, y_pred, title=\"\", round_predictions=True):\n",
    "    if round_predictions:\n",
    "        y_pred = np.round(y_pred).astype(int)\n",
    "        y_true = np.round(np.array(y_true)).astype(int)\n",
    "    else:\n",
    "        y_pred = np.array(y_pred).astype(float)\n",
    "        y_true = np.array(y_true).astype(float)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2  = r2_score(y_true, y_pred)\n",
    "    pearson = pearson_correlation_coefficient(y_true, y_pred)\n",
    "    results = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'pearson': pearson\n",
    "    }\n",
    "    print(f\"\\n {title} Regressor Performance:\")\n",
    "    print(f\"MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}, Pearson: {pearson:.4f}\")\n",
    "    return results\n",
    "\n",
    "def aggregate_cv_metrics_and_print(all_results, model_name, tag=\"Validation\"):\n",
    "    aggregated = {'mse': [], 'mae': [], 'r2': [], 'pearson': []}\n",
    "    for result in all_results:\n",
    "        aggregated['mse'].append(result['mse'])\n",
    "        aggregated['mae'].append(result['mae'])\n",
    "        aggregated['r2'].append(result['r2'])\n",
    "        aggregated['pearson'].append(result['pearson'])\n",
    "    summary = {\n",
    "        'mean_mse': np.mean(aggregated['mse']),\n",
    "        'std_mse': np.std(aggregated['mse']),\n",
    "        'mean_mae': np.mean(aggregated['mae']),\n",
    "        'std_mae': np.std(aggregated['mae']),\n",
    "        'mean_r2': np.mean(aggregated['r2']),\n",
    "        'std_r2': np.std(aggregated['r2']),\n",
    "        'mean_pearson': np.mean(aggregated['pearson']),\n",
    "    }\n",
    "    print(f\"\\n {model_name} Regressor Performance {tag}:\")\n",
    "    for k, v in summary.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_col= \"label_Age\"\n",
    "straticify_col = \"label_age_group\"\n",
    "\n",
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/age_label\", exist_ok=True)\n",
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age\", exist_ok=True)\n",
    "mri_table = \"aseg.volume_aparc.volume_aparc.thickness.csv\"\n",
    "\"\"\" # Load the age data\n",
    "command = \"dx download file-GyGfBQ8J34gPK8XXxbjYGbg4 --output /opt/notebooks/TABPFN/02_UKB/00_data/age_label/all_ages_all_ids_healthy.csv --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "#load mri data\n",
    "command = f\"dx download file-GyGf9vjJ34g2g9QbJQ7P1qZG --output '/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age/{mri_table}' --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True) \"\"\"\n",
    "\n",
    "# Load the age data middle\n",
    "command = \"dx download file-GyJp51jJ34g246Y7bZ6j7yK4 --output /opt/notebooks/TABPFN/02_UKB/00_data/age_label/all_ages_all_ids_healthy.csv --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "#load mri data cleand and renamed but age\n",
    "command = f\"dx download file-GyJp6B0J34g8xpf6Q6jz12xJ --output '/opt/notebooks/TABPFN/02_UKB/00_data/deconfounded_but_age/{mri_table}' --overwrite\"\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "df = pd.read_csv(f\"../00_data/deconfounded_but_age/{mri_table}\")\n",
    "label_df = pd.read_csv(\"../00_data/age_label/all_ages_all_ids_healthy.csv\")\n",
    "n_splits = 5\n",
    "label_df = label_df[['ID', label_col, straticify_col]]\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "\n",
    "label_counts = merged_df[straticify_col].value_counts()\n",
    "\n",
    "# Include all rows for groups with fewer samples than the target threshold\n",
    "threshold = 1000  # You can adjust this threshold as needed\n",
    "small_groups = label_counts[label_counts <= threshold].index\n",
    "small_groups_df = merged_df[merged_df[straticify_col].isin(small_groups)]\n",
    "\n",
    "# Calculate how many more samples are needed to reach 10,000\n",
    "remaining_needed = 10000 - len(small_groups_df)\n",
    "\n",
    "# Sample proportionally from the larger groups\n",
    "large_groups = label_counts[label_counts > threshold].index\n",
    "large_groups_df = merged_df[merged_df[straticify_col].isin(large_groups)]\n",
    "\n",
    "# Stratified sampling from the remaining data\n",
    "proportional_sampled_df, _ = train_test_split(\n",
    "    large_groups_df, \n",
    "    train_size=remaining_needed, \n",
    "    stratify=large_groups_df[straticify_col], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combine the small groups and the proportional sample\n",
    "final_sampled_df = pd.concat([small_groups_df, proportional_sampled_df])\n",
    "\n",
    "# Verify the result\n",
    "print(final_sampled_df[straticify_col].value_counts())\n",
    "print(f\"Total samples: {len(final_sampled_df)}\")\n",
    "if label_col != straticify_col:\n",
    "    final_sampled_df.drop(columns=[straticify_col], inplace=True)\n",
    "final_sampled_df[label_col].hist()\n",
    "df_sampled = final_sampled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"/opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/\", exist_ok=True)\n",
    "#load middle age control data\n",
    "command = \"dx download file-GyK09JQJ34g95zyvV9vFxQFv --output /opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/all_ages_all_ids_subset_middle_age.csv --overwrite\"\n",
    "subprocess.run(command, shell=True)\n",
    "#load mri data\n",
    "command = \"dx download file-GyK08xjJ34g95zyvV9vFxQFf --output /opt/notebooks/TABPFN/02_UKB/00_data/validation_data/00_National_Cohort/aparc.thickness_aseg.volume_aparc.volume_deconfounded_but_age.csv --overwrite\"\n",
    "subprocess.run(command, shell=True)\n",
    "\n",
    "label_df_control = pd.read_csv(\"../00_data/validation_data/00_National_Cohort/all_ages_all_ids_subset_middle_age.csv\")\n",
    "df_control = pd.read_csv(\"../00_data/validation_data/00_National_Cohort/aparc.thickness_aseg.volume_aparc.volume_deconfounded_but_age.csv\")\n",
    "\n",
    "label_df_control = label_df_control[['ID', straticify_col, label_col]]\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "#sample 400 so that from each group 25 samples if possible\n",
    "target_samples_per_group = 25\n",
    "grouped_df = merged_df_control.groupby(straticify_col)\n",
    "\n",
    "# Sample 25 from each group if possible, otherwise sample all available\n",
    "sampled_control = grouped_df.apply(lambda x: x.sample(n=min(target_samples_per_group, len(x)), random_state=42))\n",
    "\n",
    "# Reset the index after sampling\n",
    "sampled_control.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Check if we reached the desired total number of 400 samples\n",
    "if len(sampled_control) < 400:\n",
    "    print(f\"Only {len(sampled_control)} samples available after balanced sampling.\")\n",
    "else:\n",
    "    print(f\"Sampled {len(sampled_control)} rows with balanced distribution across groups.\")\n",
    "\n",
    "X_control_source = sampled_control.drop([\"ID\", label_col], axis=1)\n",
    "y_control_source = sampled_control[label_col]\n",
    "control_ids = sampled_control[\"ID\"]\n",
    "y_control_source.hist(bins=29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_control = df_sampled.drop([label_col, \"ID\"], axis=1).columns\n",
    "X_control = X_control_source[column_control]\n",
    "y_control_max = y_control_source.max()\n",
    "y_control_min = y_control_source.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_control.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "# You can adjust these percentages as needed\n",
    "#percentage_of_the_data = [1.0, 0.8, 0.6, 0.5, 0.2, 0.05]\n",
    "percentage_of_the_data = [0.05, 0.2, 0.5, 0.6, 0.8, 1.0]\n",
    "deconfounding_strategies = [\"Nothing\"]\n",
    "\n",
    "# Dictionary to store aggregated CV metrics for each percentage and deconfounding strategy\n",
    "percentage_dict = {}\n",
    "\n",
    "# Lists to record individual predictions (for test and control sets)\n",
    "test_predictions_records = []    # will include real outcomes and predictions (test set from CV)\n",
    "control_predictions_records = [] # will include real outcomes and predictions (control set)\n",
    "\n",
    "# We will also record random-baseline metrics (using random predictions drawn from uniform [0,1])\n",
    "random_results = []            # for test set performance\n",
    "random_results_eval = []       # for control set evaluation (if desired)\n",
    "\n",
    "# For each deconfounding strategy and percentage, we will also collect model metrics\n",
    "# We will collect separate lists for test-set (\"cv_results\") and control-set (\"cv_results_eval\")\n",
    "for percentage in percentage_of_the_data:\n",
    "    percentage_dict[percentage] = {}\n",
    "    \n",
    "    # Subsample the training data as needed\n",
    "    if percentage == 1:\n",
    "        df_sampled_subset = df_sampled.copy()\n",
    "    else:\n",
    "        df_sampled_subset, _ = train_test_split(\n",
    "            df_sampled,\n",
    "            train_size=percentage,\n",
    "            random_state=42\n",
    "        )\n",
    "    print(f\"\\n #### TRAINING WITH {percentage} OF THE DATA ####\")\n",
    "    # Separate IDs, outcomes, and features\n",
    "    ids = df_sampled_subset[\"ID\"]\n",
    "    y = df_sampled_subset[label_col]\n",
    "    X = df_sampled_subset.drop([\"ID\", label_col], axis=1)\n",
    "    \n",
    "    print(f\"Training data shape: {X.shape}, number of samples: {len(y)}\")\n",
    "    \n",
    "    for deconfounding_strategy in deconfounding_strategies:\n",
    "        print(f\"\\n=== Deconfounding Strategy: {deconfounding_strategy} ===\")\n",
    "        \n",
    "        # Prepare lists for storing CV metrics (for test set and for control set)\n",
    "        mlp_results = []\n",
    "        tabpfn_results = []\n",
    "        lgb_results = []\n",
    "        random_results_model = []  # for test-set random baseline\n",
    "        \n",
    "        mlp_results_eval = []\n",
    "        tabpfn_results_eval = []\n",
    "        lgb_results_eval = []\n",
    "        random_results_eval_model = []  # for control-set random baseline (if desired)\n",
    "        \n",
    "        # Create a KFold object (using KFold for regression)\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "        fold_counter = 0\n",
    "        for train_index, val_index in kf.split(X):\n",
    "            fold_counter += 1\n",
    "            print(f\"\\nFold {fold_counter}\")\n",
    "            X_train, X_test = X.iloc[train_index].copy(), X.iloc[val_index].copy()\n",
    "            y_train, y_test = y.iloc[train_index].copy(), y.iloc[val_index].copy()\n",
    "            test_ids = ids.iloc[val_index].copy()\n",
    "            \n",
    "            # Use the entire control set (IDs are stored in control_ids)\n",
    "            X_control = X_control_source.copy()\n",
    "            y_control = y_control_source.copy()\n",
    "            try:\n",
    "                X_control = X_control[X_train.columns]\n",
    "            except Exception as e:\n",
    "                print(\"Columns mismatch between training and control:\", e)\n",
    "            \n",
    "            # Scale the data\n",
    "            df_columns = X_train.columns\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            X_control_scaled = scaler.transform(X_control)\n",
    "            \n",
    "            # Apply deconfounding / feature extraction strategy\n",
    "            if deconfounding_strategy == \"BE\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extration_with_BE(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"PCA\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extration_with_PCA(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, n_components=50)\n",
    "            elif deconfounding_strategy == \"Correlation_in_Feature\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extraction_with_Pearson(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, threshold=0.6, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"Correlation_with_target\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = feature_extraction_best_corr_with_target(\n",
    "                    X_train_scaled, X_test_scaled, X_control_scaled, y_train, threshold=0.6, df_columns=df_columns)\n",
    "            elif deconfounding_strategy == \"Nothing\":\n",
    "                X_train_proc, X_test_proc, X_control_proc = X_train_scaled, X_test_scaled, X_control_scaled\n",
    "            \n",
    "            #############################\n",
    "            # RANDOM BASELINE\n",
    "            #############################\n",
    "            n_samples_test = len(y_test)\n",
    "            # Random predcition between min and max\n",
    "            random_pred = np.random.uniform(y_test.min(), y_test.max(), n_samples_test)\n",
    "            random_pred = np.round(random_pred)\n",
    "            random_metrics = evaluate_regression_performance(y_test, random_pred, title=\"Random - Test\")\n",
    "            random_results_model.append(random_metrics)\n",
    "            \n",
    "            # For control set, random predictions as well:\n",
    "            n_samples_control = len(y_control)\n",
    "            random_control_pred = np.random.uniform(y_test.min(), y_test.max(), n_samples_control)\n",
    "            random_metrics_eval = evaluate_regression_performance(y_control, random_control_pred, title=\"Random - Control\")\n",
    "            random_results_eval_model.append(random_metrics_eval)\n",
    "            \n",
    "            # Record random predictions in the prediction logs (for test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, random_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'Random',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # And for control set\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, random_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'Random',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            \n",
    "            \n",
    "            #############################\n",
    "            # TABPFN Regressor\n",
    "            #############################\n",
    "            tabpfn_model = TabPFNRegressor()\n",
    "            tabpfn_model.fit(X_train_proc, y_train)\n",
    "            tabpfn_pred = tabpfn_model.predict(X_test_proc)\n",
    "            tabpfn_metrics = evaluate_regression_performance(y_test, tabpfn_pred, title=\"tabpfn - Test\")\n",
    "            tabpfn_results.append(tabpfn_metrics)\n",
    "            \n",
    "            # Record tabpfn predictions (test set)\n",
    "            for idx, true_val, pred_val in zip(test_ids, y_test, tabpfn_pred):\n",
    "                test_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'tabpfn',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            # Evaluate on control set\n",
    "            tabpfn_control_pred = tabpfn_model.predict(X_control_proc).flatten()\n",
    "            tabpfn_control_metrics = evaluate_regression_performance(y_control, tabpfn_control_pred, title=\"tabpfn - Control\")\n",
    "            tabpfn_results_eval.append(tabpfn_control_metrics)\n",
    "            # Record control predictions for tabpfn\n",
    "            for idx, true_val, pred_val in zip(control_ids, y_control, tabpfn_control_pred):\n",
    "                control_predictions_records.append({\n",
    "                    'ID': idx,\n",
    "                    'fold': fold_counter,\n",
    "                    'model': 'tabpfn',\n",
    "                    'real_outcome': true_val,\n",
    "                    'predicted_outcome': pred_val,\n",
    "                    'percentage': percentage,\n",
    "                    'deconfounding': deconfounding_strategy\n",
    "                })\n",
    "            clean_up_cuda(tabpfn_model)\n",
    "            \n",
    "        # End of CV folds for this deconfounding strategy\n",
    "        \n",
    "        # Aggregate and print performance for each model (test set)\n",
    "        random_summary = aggregate_cv_metrics_and_print(random_results_model, \"Random\")\n",
    "        tabpfn_summary = aggregate_cv_metrics_and_print(tabpfn_results, \"tabpfn\")\n",
    "        mlp_summary = aggregate_cv_metrics_and_print(mlp_results, \"MLP\")\n",
    "        lgb_summary = aggregate_cv_metrics_and_print(lgb_results, \"LGBM\")\n",
    "        \n",
    "        # Aggregate for control set evaluations\n",
    "        random_eval_summary = aggregate_cv_metrics_and_print(random_results_eval_model, \"Random\", tag=\"Control\")\n",
    "        tabpfn_eval_summary = aggregate_cv_metrics_and_print(tabpfn_results_eval, \"tabpfn\", tag=\"Control\")\n",
    "        mlp_eval_summary = aggregate_cv_metrics_and_print(mlp_results_eval, \"MLP\", tag=\"Control\")\n",
    "        lgb_eval_summary = aggregate_cv_metrics_and_print(lgb_results_eval, \"LGBM\", tag=\"Control\")\n",
    "        \n",
    "        # Save results in the dictionary\n",
    "        percentage_dict[percentage][deconfounding_strategy] = {\n",
    "            \"Random\": {\n",
    "                \"results\": random_summary,\n",
    "                \"results_eval\": random_eval_summary,\n",
    "                \"cv_results\": random_results_model,\n",
    "                \"cv_results_eval\": random_results_eval_model\n",
    "            },\n",
    "            \"tabpfn\": {\n",
    "                \"results\": tabpfn_summary,\n",
    "                \"results_eval\": tabpfn_eval_summary,\n",
    "                \"cv_results\": tabpfn_results,\n",
    "                \"cv_results_eval\": tabpfn_results_eval\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # Set these flags as desired\n",
    "    Feature_extraction_applied = False\n",
    "    Pretraining_applied = False\n",
    "    # You can set these flags based on the deconfounding strategy if needed.\n",
    "\n",
    "    all_rows = []\n",
    "    log_file = \"/opt/notebooks/results_regression.csv\"\n",
    "    # Iterate over percentages and their associated models\n",
    "    for percentage, models in percentage_dict.items():\n",
    "        for feat_ext, feature_summary_dict in models.items():\n",
    "            for model_name, summary_dict in feature_summary_dict.items():\n",
    "                # Each summary_dict contains aggregated metrics as well as CV lists.\n",
    "                # Iterate over the number of folds (using the cv_results list)\n",
    "                for i, (cv_result, cv_result_eval) in enumerate(zip(summary_dict[\"cv_results\"], summary_dict[\"cv_results_eval\"])):\n",
    "                    # Prepare training (test set) row\n",
    "                    row_train = {\n",
    "                        \"label_col\": label_col,\n",
    "                        \"mri_table\": mri_table,\n",
    "                        \"test_set_size\": f\"{(1 - percentage):.2%} (approx. of data left for test)\",\n",
    "                        \"Feature_extraction_applied\": Feature_extraction_applied,\n",
    "                        \"Pretraining_applied\": Pretraining_applied,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"mse\": cv_result.get(\"mse\", None),\n",
    "                        \"mae\": cv_result.get(\"mae\", None),\n",
    "                        \"r2\": cv_result.get(\"r2\", None),\n",
    "                        \"pearson\": cv_result.get(\"pearson\", None),\n",
    "                        \"number_of_cross_validations\": n_splits,\n",
    "                        \"cross_validation_count\": i,\n",
    "                        \"search_term\": f\"{percentage}_{feat_ext}_{model_name}_train\",\n",
    "                        \"percentage_of_data\": percentage,\n",
    "                        \"eval_or_train\": \"train\"\n",
    "                    }\n",
    "                    # Prepare evaluation (control set) row\n",
    "                    row_eval = {\n",
    "                        \"label_col\": label_col,\n",
    "                        \"mri_table\": mri_table,\n",
    "                        \"test_set_size\": f\"{(1 - percentage):.2%} (approx. of data left for test)\",\n",
    "                        \"Feature_extraction_applied\": Feature_extraction_applied,\n",
    "                        \"Pretraining_applied\": Pretraining_applied,\n",
    "                        \"model_type\": model_name,\n",
    "                        \"mse\": cv_result_eval.get(\"mse\", None),\n",
    "                        \"mae\": cv_result_eval.get(\"mae\", None),\n",
    "                        \"r2\": cv_result_eval.get(\"r2\", None),\n",
    "                        \"pearson\": cv_result_eval.get(\"pearson\", None),\n",
    "                        \"number_of_cross_validations\": n_splits,\n",
    "                        \"cross_validation_count\": i,\n",
    "                        \"search_term\": f\"{percentage}_{feat_ext}_{model_name}_eval\",\n",
    "                        \"percentage_of_data\": percentage,\n",
    "                        \"eval_or_train\": \"eval\"\n",
    "                    }\n",
    "                    all_rows.append(row_train)\n",
    "                    all_rows.append(row_eval)\n",
    "\n",
    "    # Convert to DataFrame and save CSV\n",
    "    df_results = pd.DataFrame(all_rows)\n",
    "    df_results.to_csv(log_file, index=False)\n",
    "    # Convert the list of dictionaries to a DataFrame\n",
    "    df_results = pd.DataFrame(all_rows)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df_results.to_csv(log_file, index=False)\n",
    "    logs_path = \"project-GqzxkVQJ34g6ygFJ4ZbvqBYF:/Esra/00_CLIP/01_training_logs/\"\n",
    "    label = os.environ.get(\"DX_JOB_ID\") \n",
    "    logs_path_label = os.path.join(logs_path, label)\n",
    "    dx_mkdir_command = f\"dx mkdir '{logs_path_label}'\"\n",
    "    subprocess.run(dx_mkdir_command, shell=True)\n",
    "    time_tag = pd.Timestamp.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    command_csv = f\"dx upload '{log_file}' --path '{logs_path_label}/{time_tag}_result_tabpfn.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n",
    "\n",
    "    df_test_predictions = pd.DataFrame(test_predictions_records)\n",
    "    df_control_predictions = pd.DataFrame(control_predictions_records)\n",
    "\n",
    "    test_csv_path = \"/opt/notebooks/regression_test_predictions.csv\"\n",
    "    control_csv_path = \"/opt/notebooks/regression_control_predictions.csv\"\n",
    "\n",
    "    df_test_predictions.to_csv(test_csv_path)\n",
    "    df_control_predictions.to_csv(control_csv_path)\n",
    "\n",
    "    print(f\"Saved test predictions to {test_csv_path}\")\n",
    "    print(f\"Saved control predictions to {control_csv_path}\")\n",
    "    command_csv = f\"dx upload '{test_csv_path}' --path '{logs_path_label}/{time_tag}_test_predictions_tabpfn.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n",
    "    command_csv = f\"dx upload '{control_csv_path}' --path '{logs_path_label}/{time_tag}_control_predictions_tabpfn.csv'\"\n",
    "    subprocess.run(command_csv, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
