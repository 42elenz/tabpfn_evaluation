{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pip install scikit-learn numpy scipy tensorflow imblearn # if needed you can install these onse, depend to the environment \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from scipy.stats import pointbiserialr, chi2_contingency\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tabpfn import TabPFNClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, balanced_accuracy_score, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import wandb\n",
    "from time import sleep\n",
    "import random\n",
    "# Suppress TensorFlow warnings\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='keras')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='absl')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import subprocess\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "tf.random.set_seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "random.seed(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"../99_logs/logging/training_log.csv\"\n",
    "subprocess.run([\"rm\", \"-rf\", \"../99_logs/log_ml_loop.txt\"], check=True)\n",
    "subprocess.run([\"rm\", \"-rf\", log_file], check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###THIS IS FOR LOGGING TO CSV\n",
    "columns = [\n",
    "    \"label_col\", \"mri_table\", \"number_of_pos\", \"number_of_neg\",\"test_set_size\",\"y_label_ratio\", \"sex_label_ratio\",\n",
    "    \"Feature_extraction_applied\", \"Pretraining_applied\", \n",
    "    \"model_type\", \"Accuracy\", \"AUC\", \"Balanced_ACC\", \"Permutation_Balanced_ACC\", \"number_of_cross_validations\", \"cross_validation_count\", \"search_term\"\n",
    "]\n",
    "log_df = pd.DataFrame(columns=columns)\n",
    "log_file = \"../99_logs/training_log.csv\"\n",
    "log_df.to_csv(log_file, index=False)\n",
    "\n",
    "def write_to_csv(label_col,\n",
    "                 mri_table,\n",
    "                 number_of_pos,\n",
    "                 number_of_neg,\n",
    "                 test_set_size,\n",
    "                 y_label_ratio,\n",
    "                 sex_label_ratio,\n",
    "                 Feature_extraction_applied,\n",
    "                 Pretraining_applied,\n",
    "                 model_type,\n",
    "                 Accuracy,\n",
    "                 AUC,\n",
    "                 Balanced_ACC,\n",
    "                 Permutation_Balanced_ACC,\n",
    "                 number_of_cross_validations,\n",
    "                 cross_validation_count,\n",
    "                 file=\"../99_logs/training_log.csv\"):\n",
    "    log_df = pd.read_csv(file)\n",
    "    new_row = pd.DataFrame([{\n",
    "        \"label_col\": label_col,\n",
    "        \"mri_table\": mri_table,\n",
    "        \"number_of_pos\": number_of_pos,\n",
    "        \"number_of_neg\": number_of_neg,\n",
    "        \"test_set_size\": test_set_size,\n",
    "        \"y_label_ratio\": y_label_ratio,\n",
    "        \"sex_label_ratio\": sex_label_ratio,\n",
    "        \"Feature_extraction_applied\": Feature_extraction_applied,\n",
    "        \"Pretraining_applied\": Pretraining_applied,\n",
    "        \"model_type\": model_type,\n",
    "        \"Accuracy\": Accuracy,\n",
    "        \"AUC\": AUC,\n",
    "        \"Balanced_ACC\": Balanced_ACC,\n",
    "        \"Permutation_Balanced_ACC\": Permutation_Balanced_ACC,\n",
    "        \"number_of_cross_validations\": number_of_cross_validations,\n",
    "        \"cross_validation_count\": cross_validation_count,\n",
    "        \"search_term\": label_col + \"_\" + mri_table\n",
    "    }])\n",
    "    log_df = pd.concat([log_df, new_row], ignore_index=True)\n",
    "    log_df.to_csv(file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote_balancing(dataset, features, id_col, label_col, gender_col):\n",
    "    # Create a combined label for stratification\n",
    "    dataset['combined_label'] = dataset[label_col].astype(str) + '_' + dataset[gender_col].astype(str)\n",
    "    \n",
    "    # Apply SMOTE to balance the combined labels\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X, y = smote.fit_resample(dataset[features], dataset['combined_label'])\n",
    "    \n",
    "    # Identify synthetic samples\n",
    "    is_synthetic = pd.Series(X.index).isin(dataset.index) == False\n",
    "\n",
    "    # Assign IDs: keep original IDs for real data, assign new IDs for synthetic data\n",
    "    synthetic_id_start = 999999\n",
    "    synthetic_ids = list(range(synthetic_id_start, synthetic_id_start - is_synthetic.sum(), -1))\n",
    "    new_ids = []\n",
    "\n",
    "    for idx, is_syn in zip(X.index, is_synthetic):\n",
    "        if is_syn:\n",
    "            new_ids.append(synthetic_ids.pop(0))\n",
    "        else:\n",
    "            new_ids.append(dataset.at[idx, id_col])\n",
    "\n",
    "    # Split the combined labels back into original columns\n",
    "    new_labels = y.str.split('_', expand=True)\n",
    "    y_balanced = new_labels[0].astype(float).astype(int)  # Original label\n",
    "    gender_balanced = new_labels[1]                      # Original gender\n",
    "    \n",
    "    # Combine the balanced features with the separated labels and gender\n",
    "    balanced_data = pd.concat([pd.DataFrame(X, columns=features),\n",
    "                               pd.DataFrame({id_col: new_ids, label_col: y_balanced, gender_col: gender_balanced})], axis=1)\n",
    "    \n",
    "    return balanced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# you can also change reading data to avoid merging them if you plan to use more labels for future research, or you can write me to change them\n",
    "def prepare_dataset(brain_csv_path, labels_csv_path, id_col, label_col, additional_cols=None, smote_upsampling_for_sex=True, sex_col = \"sex\"):\n",
    "    \"\"\"\n",
    "    Prepares the dataset for training by merging brain features and binary labels.\n",
    "\n",
    "    Args:\n",
    "    - brain_csv_path (str): Path to the CSV file containing brain info (features).\n",
    "    - labels_csv_path (str): Path to the CSV file containing labels.\n",
    "    - id_col (str): Column name representing unique IDs in both files.\n",
    "    - label_col (str): Label to filter by (binary).\n",
    "    - additional_cols (list, optional): Additional columns to include in the merged dataset.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Merged and cleaned dataset.\n",
    "    \"\"\"\n",
    "    additional_cols = additional_cols or []  # Default to empty list\n",
    "    brain_data = pd.read_csv(brain_csv_path)\n",
    "    label_data = pd.read_csv(labels_csv_path)\n",
    "\n",
    "    brain_data[id_col] = brain_data[id_col].astype(str)\n",
    "    label_data[id_col] = label_data[id_col].astype(str)\n",
    "    if \"sub-\" in label_data[id_col].iloc[0]:\n",
    "        label_data[id_col] = label_data[id_col].str.replace(\"sub-\", \"\")\n",
    "    if \"sub-\" in brain_data[id_col].iloc[0]:\n",
    "        brain_data[id_col] = brain_data[id_col].str.replace(\"sub-\", \"\")\n",
    "\n",
    "    # Filter labels to keep only rows where label is binary (0 or 1)\n",
    "    label_data = label_data[label_data[label_col].isin([0, 1])]\n",
    "\n",
    "    if smote_upsampling_for_sex != None:\n",
    "        # Merge datasets\n",
    "        merged_data = pd.merge(\n",
    "            brain_data,\n",
    "            label_data[[id_col, label_col, sex_col] + additional_cols],\n",
    "            on=id_col,\n",
    "            how='inner'\n",
    "        )\n",
    "    else:\n",
    "        # Merge datasets\n",
    "        merged_data = pd.merge(\n",
    "            brain_data,\n",
    "            label_data[[id_col, label_col] + additional_cols],\n",
    "            on=id_col,\n",
    "            how='inner'\n",
    "        )\n",
    "    # Drop rows with missing values\n",
    "    merged_data.dropna(inplace=True)\n",
    "    return merged_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(input, output_file=\"../99_logs/log_ml_loop.txt\", dict=False, print_inplace=True):\n",
    "    with open(output_file, 'a') as f:\n",
    "        f.write(input)\n",
    "    if print_inplace:\n",
    "        print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# i could not find a good baseline for dropping non correlated features, i got this idea from chatGPT and you are welcome to change or modify them based what you need \n",
    "def calculate_max_features(sample_size, min_features=5, scaling_factor=10):\n",
    "    \"\"\"\n",
    "    Dynamically calculate the maximum number of features based on the sample size.\n",
    "\n",
    "    Args:\n",
    "        sample_size (int): The number of samples in the dataset.\n",
    "        min_features (int): The minimum number of features to retain.\n",
    "        scaling_factor (int): Scaling factor for feature-to-sample ratio (e.g., 10).\n",
    "\n",
    "    Returns:\n",
    "        int: Recommended maximum number of features.\n",
    "    \"\"\"\n",
    "    # Rule-based calculations\n",
    "    max_features_by_ratio = sample_size // scaling_factor\n",
    "    max_features_by_log = scaling_factor * np.log(sample_size)\n",
    "    \n",
    "    # Choose the most restrictive limit, but ensure at least min_features\n",
    "    return int(max(min_features, min(max_features_by_ratio, max_features_by_log)))\n",
    "\n",
    "def validate_labels(data, label_col):\n",
    "    \"\"\"\n",
    "    Validates the label column and ensures it exists in the dataset.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The dataset.\n",
    "        label_col (str): The label column to validate.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The validated label column.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: If the label column is not found in the dataset.\n",
    "        ValueError: If the label column contains invalid data types or unexpected values.\n",
    "    \"\"\"\n",
    "    if label_col not in data.columns:\n",
    "        raise KeyError(f\"The label column `{label_col}` is not found in the dataset.\")\n",
    "    \n",
    "    y = data[label_col]  # Extract the label column\n",
    "    if not isinstance(y, pd.Series):\n",
    "        raise ValueError(f\"The label column `{label_col}` must be a single column, but a different type was provided.\")\n",
    "    \n",
    "    return y\n",
    "\n",
    "\n",
    "def feature_extraction(data, features, label_col, excluded_labels=None, p_value_threshold=0.05, min_features=5, scaling_factor=10, use_feature_extraction=True):\n",
    "    \"\"\"\n",
    "    Extracts features based on their correlation with the label.\n",
    "\n",
    "    Args:\n",
    "    - data (pd.DataFrame): Dataset containing features and labels.\n",
    "    - features (list): List of feature columns to evaluate.\n",
    "    - label_col (str): Name of the binary label column.\n",
    "    - excluded_labels (list): List of additional columns to exclude during feature evaluation.\n",
    "    - p_value_threshold (float): Threshold for selecting features based on p-value.\n",
    "    - min_features (int): Minimum number of features to retain.\n",
    "    - scaling_factor (int): Scaling factor for feature-to-sample ratio.\n",
    "    - use_feature_extraction (bool): Whether to perform feature extraction.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Dataset with filtered features and all excluded labels retained.\n",
    "    - pd.DataFrame: DataFrame of correlation results for all features.\n",
    "    \"\"\"\n",
    "    if not use_feature_extraction:\n",
    "        print(\"Feature extraction is disabled. Returning the original dataset.\")\n",
    "        return data[features + [label_col]], None\n",
    "    # Ensure excluded_labels is a list\n",
    "    excluded_labels = excluded_labels or []\n",
    "    if not isinstance(excluded_labels, list):\n",
    "        raise ValueError(\"excluded_labels must be a list or None.\")\n",
    "    #if there is a None value in the list, drop it\n",
    "    excluded_labels = [label for label in excluded_labels if label is not None]\n",
    "\n",
    "    # Exclude labels only during p-value computation\n",
    "    excluded_features = set(excluded_labels + [label_col])\n",
    "    feature_subset = [f for f in features if f not in excluded_features]\n",
    "    \n",
    "    y = data[label_col].astype(int)  # Ensure binary label is numeric (0/1)\n",
    "    X = data[feature_subset]  # Extract relevant feature columns\n",
    "    write_to_file(f\"Number of columns before feature extraction: {len(feature_subset)}\")\n",
    "\n",
    "    # Store correlation results\n",
    "    correlation_results = {}\n",
    "    for column in X.columns:\n",
    "        if X[column].nunique() <= 1:\n",
    "            continue  # Skip constant features\n",
    "        \n",
    "        if np.issubdtype(X[column].dtype, np.number):  # Numerical features\n",
    "            try:\n",
    "                _, p_value = pointbiserialr(X[column], y)\n",
    "            except ValueError:  # Handle constant input issues\n",
    "                continue\n",
    "        else:  # Categorical features\n",
    "            try:\n",
    "                contingency_table = pd.crosstab(X[column], y)\n",
    "                _, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        correlation_results[column] = {'P-value': p_value}\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    correlation_df = pd.DataFrame(correlation_results).T\n",
    "\n",
    "    # Dynamically calculate max_features based on sample size\n",
    "    sample_size = len(data)\n",
    "    max_features = calculate_max_features(sample_size, min_features=min_features, scaling_factor=scaling_factor)\n",
    "\n",
    "    # Filter features based on p-value threshold\n",
    "    filtered_features = correlation_df[correlation_df['P-value'] < p_value_threshold].index.tolist()\n",
    "\n",
    "    if len(filtered_features) < max_features:\n",
    "        # Not enough features, select the top `max_features` ranked by p-value\n",
    "        filtered_features = correlation_df.nsmallest(max_features, 'P-value').index.tolist()\n",
    "\n",
    "    # Print the 5 most significant features and their p-values\n",
    "    most_significant = correlation_df.nsmallest(5, 'P-value')\n",
    "    write_to_file(f\"Top 5 most significant features and their p-values:\\n{most_significant}\\nNumber of columns after feature extraction: {len(filtered_features)}\")\n",
    "    \n",
    "    # Retain excluded labels in the returned dataset\n",
    "    return data[filtered_features + excluded_labels + [label_col]], correlation_df\n",
    "\n",
    "# i faced milions of errors while was trying to uise the same function for binary and multiclass label as we needed for pretraining, i seprated them, so you can also choose other categorical features to make pretrain model\n",
    "# if you plan to use binary features for pretraining you can also use binary function for preprocessing data before runing models \n",
    "# in addition, most of the calsses or labels are kind of balanced, i did not look at hem deeply but apparently, over and under sampling may not be so helpful, but it is your choice your Grace :) \n",
    "def preprocess_binary_data(data, features, label_col, test_size=0.2, normalize=True, sampling='over', random_state=42):\n",
    "    \"\"\"\n",
    "    Preprocesses data for binary classification tasks.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data.\n",
    "        features (list): Features to use.\n",
    "        label_col (str): Binary label column.\n",
    "        test_size (float): Test set size.\n",
    "        normalize (bool): Whether to normalize features.\n",
    "        sampling (str): Sampling method ('over', 'under', or None).\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: Train, validation, and test splits for features and labels.\n",
    "    \"\"\"\n",
    "    # Validate the label column\n",
    "    y = data[label_col]\n",
    "    if not set(y.unique()).issubset({0, 1}):\n",
    "        raise ValueError(f\"The label column `{label_col}` must contain only binary values (0 and 1).\")\n",
    "\n",
    "    X = data[features]\n",
    "\n",
    "    # Split the data\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=test_size, random_state=random_state, stratify=y_train_val\n",
    "    )\n",
    "\n",
    "\n",
    "    write_to_file(f\"Real sample shape (before sampling):\\nX_train: {X_train.shape}, y_train distribution:\\n{y_train.value_counts()}\")\n",
    "\n",
    "    # Apply sampling if specified\n",
    "    if sampling == 'over':\n",
    "        smote = SMOTE(random_state=random_state)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "        print(\"After oversampling (SMOTE):\")\n",
    "        print(f\"X_train: {X_train.shape}, y_train distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "    elif sampling == 'under':\n",
    "        undersampler = RandomUnderSampler(random_state=random_state)\n",
    "        X_train, y_train = undersampler.fit_resample(X_train, y_train)\n",
    "        print(\"After undersampling:\")\n",
    "        print(f\"X_train: {X_train.shape}, y_train distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "        write_to_file(f\"After undersampling:\\nX_train: {X_train.shape}, y_train distribution:\\n{pd.Series(y_train).value_counts()}\")\n",
    "# i thinks we can also use more normalization mathods to compare the result, but would be the next steps \n",
    "\n",
    "    # Normalize features\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=features)\n",
    "        X_val = pd.DataFrame(scaler.transform(X_val), columns=features)\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns=features)\n",
    "        print(\"After normalization:\")\n",
    "        print(f\"X_train: {X_train.shape}, X_val: {X_val.shape}, X_test: {X_test.shape}\")\n",
    "    #labe ratio as float\n",
    "    y_label_ratio = y_test.mean()\n",
    "    return {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_val\": X_val,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_train\": y_train,\n",
    "        \"y_val\": y_val,\n",
    "        \"y_test\": y_test,\n",
    "        \"y_label_ratio\": y_label_ratio,\n",
    "        \"sex_label_ratio\": -99\n",
    "    }\n",
    "\n",
    "\n",
    "# Preprocess Multi-Class Data, I did not use sampling fot this part, but if you want i can add sampling as well \n",
    "# i did not used age classes( i mean i used the whole ages without using age range, that is why i had to drop stratify in train test split, so if you use age ranges you can add stratify in traintest split\n",
    "# we should not have single class to use stratify, all classes should have more than one sample if yoy want use stratify spliting \n",
    "def preprocess_multiclass_data(data, features, label_col, test_size=0.2, normalize=True, random_state=42):\n",
    "    y = validate_labels(data, label_col)\n",
    "    X = data[features]\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "        X_val = pd.DataFrame(scaler.transform(X_val), columns=X_val.columns)\n",
    "        X_test = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "        print(y_train.shape)\n",
    "        print(y_val.shape)\n",
    "    return {\"X_train\": X_train, \"X_val\": X_val, \"X_test\": X_test, \"y_train\": y_train, \"y_val\": y_val, \"y_test\": y_test}\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balanced_sub_set_cross_validation(data, group_column='combined', test_size=0.2, random_state=None, set_type=\"TEST\"):\n",
    "    cross_validation_data = []\n",
    "    group_sizes = data.groupby(group_column).size()\n",
    "    smallest_group_size = group_sizes.min()\n",
    "    n_splits = smallest_group_size // 6\n",
    "    n_splits = min(n_splits, 5)\n",
    "    if n_splits < 2:\n",
    "        write_to_file(f\"Skipping cross-validation for {set_type} set because there is not enough data.\")\n",
    "        print(f\"Group sizes: {group_sizes}\")\n",
    "        remaining_data, test_set = create_balanced_sub_set(data, group_column=group_column, test_size=test_size, random_state=random_state, set_type=set_type)\n",
    "        cross_validation_data.append((remaining_data, test_set, n_splits))\n",
    "        return cross_validation_data\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    for train_index, test_index in skf.split(data, data[group_column]):\n",
    "        write_to_file(f\"Example of test_index: {test_index[:5]} for split\")\n",
    "        #make test_index to df like data\n",
    "        test_index_df = data.iloc[test_index]\n",
    "        # Determine the smallest group size\n",
    "        group_sizes = test_index_df.groupby(group_column).size()\n",
    "        smallest_group_size = group_sizes.min()\n",
    "        # Calculate the number of samples to take per group for the test set\n",
    "        n_samples = int(smallest_group_size)\n",
    "        if n_samples < 1:\n",
    "            raise ValueError(f\"The {set_type} set size is too small. Please reduce the test_size parameter.\")\n",
    "        if n_samples < 6:\n",
    "            n_samples = 6\n",
    "            write_to_file(f\"Sampling {n_samples} samples per group for the {set_type} set because there is so less data.\")\n",
    "        print(f\"Sampling {n_samples} samples per group for the {set_type} set.\")\n",
    "        print(f\"{set_type} set size: {n_samples * len(group_sizes)} samples.\")\n",
    "    \n",
    "        # Sample test set\n",
    "        test_set = pd.DataFrame()\n",
    "        remaining_data = data.copy()\n",
    "    \n",
    "        for group, group_data in test_index_df.groupby(group_column):\n",
    "            # Sample for test set\n",
    "            group_test = group_data.sample(n=n_samples, random_state=random_state)\n",
    "            test_set = pd.concat([test_set, group_test])\n",
    "            # Remove test samples from remaining data\n",
    "            remaining_data = remaining_data.drop(group_test.index)\n",
    "        \n",
    "        cross_validation_data.append((remaining_data, test_set, n_splits))\n",
    "    return cross_validation_data\n",
    "\n",
    "def create_balanced_sub_set(data, group_column='combined', test_size=0.2, random_state=None, set_type=\"TEST\"):\n",
    "    # Determine the smallest group size\n",
    "    group_sizes = data.groupby(group_column).size()\n",
    "    smallest_group_size = group_sizes.min()\n",
    "    # Calculate the number of samples to take per group for the test set\n",
    "    n_samples = int(smallest_group_size * test_size)\n",
    "    if n_samples < 1:\n",
    "        raise ValueError(f\"The {set_type} set size is too small. for n_samplies * 0.2 {n_samples} Please reduce the test_size parameter.\")\n",
    "    if n_samples < 6:\n",
    "        n_samples = 6\n",
    "        write_to_file(f\"Sampling {n_samples} samples per group for the {set_type} set because there is so less data.\")\n",
    "    print(f\"Sampling {n_samples} samples per group for the {set_type} set.\")\n",
    "    print(f\"{set_type} set size: {n_samples * len(group_sizes)} samples.\")\n",
    "    \n",
    "    # Sample test set\n",
    "    test_set = pd.DataFrame()\n",
    "    remaining_data = data.copy()\n",
    "    \n",
    "    for group, group_data in data.groupby(group_column):\n",
    "        # Sample for test set\n",
    "        group_test = group_data.sample(n=n_samples, random_state=random_state)\n",
    "        test_set = pd.concat([test_set, group_test])\n",
    "        \n",
    "        # Remove test samples from remaining data\n",
    "        remaining_data = remaining_data.drop(group_test.index)\n",
    "    \n",
    "    return test_set, remaining_data\n",
    "\n",
    "def preprocess_balanced_binary_data(data, features, label_col, gender_col, test_size=0.2, normalize=True, random_state=42, smote_upsampling=False, standard_cross_validation=True, outer_folds=5):\n",
    "    \"\"\"\n",
    "    Preprocesses data for binary classification tasks with equal representation of combined labels in the test set.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): Input data.\n",
    "        features (list): Features to use.\n",
    "        label_col (str): Binary label column.\n",
    "        gender_col (str): Binary gender column (0: Male, 1: Female).\n",
    "        test_size (float): Test set size.\n",
    "        normalize (bool): Whether to normalize features.\n",
    "        random_state (int): Random seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        dict: Train, validation, and test splits for features and labels.\n",
    "    \"\"\"\n",
    "    # Validate the label column\n",
    "    if not set(data[label_col].unique()).issubset({0, 1}):\n",
    "        raise ValueError(f\"The label column `{label_col}` must contain only binary values (0 and 1).\")\n",
    "    # Create combined column for gender and label\n",
    "    data['combined'] = data[gender_col].astype(str) + \"_\" + data[label_col].astype(str)\n",
    "    list_of_data_splits = []\n",
    "\n",
    "    if standard_cross_validation:\n",
    "        cross_validation_data = []\n",
    "        outer_cv = StratifiedKFold(n_splits=outer_folds, shuffle=True, random_state=random_state)\n",
    "        for train_val_index, test_index in outer_cv.split(data, data['combined']):\n",
    "            train_val_set = data.iloc[train_val_index]\n",
    "            test_set = data.iloc[test_index]\n",
    "            number_of_cross_validations = outer_folds\n",
    "            # Sample validation set so that in the y_val are at least 6 of the minority class\n",
    "            cross_validation_data.append((train_val_set, test_set, number_of_cross_validations))\n",
    "\n",
    "    cross_validation_data = create_balanced_sub_set_cross_validation(data, group_column='combined', test_size=test_size, random_state=random_state, set_type=\"TEST\")\n",
    "    for train_val_set, test_set, number_of_cross_validations in cross_validation_data:\n",
    "        X_test = test_set[features]\n",
    "        y_test = test_set[label_col]\n",
    "        \n",
    "        print(\"Test set distribution by combined label:\")\n",
    "        print(test_set['combined'].value_counts())\n",
    "\n",
    "        # Sample validation set so that in the y_val are at least 6 of the minority class\n",
    "        if standard_cross_validation:\n",
    "                validation_set, train_set = train_test_split(\n",
    "                train_val_set, test_size=test_size, stratify=train_val_set['combined'], random_state=random_state\n",
    "                 )\n",
    "        else:\n",
    "            validation_set, train_set = create_balanced_sub_set(train_val_set, group_column='combined', test_size=test_size, random_state=random_state, set_type=\"VALIDATION\")\n",
    "        X_train = train_set[features]\n",
    "        y_train = train_set[\"combined\"]\n",
    "        X_val = validation_set[features]\n",
    "        y_val = validation_set[\"combined\"]\n",
    "        if smote_upsampling:\n",
    "            # Apply SMOTE to the training set only\n",
    "            smote = SMOTE(random_state=random_state)\n",
    "            X_train_resampled, y_train_resampled_comb = smote.fit_resample(X_train, y_train)\n",
    "            \n",
    "            write_to_file(\"\\nTraining set distribution after SMOTE:\\n\")\n",
    "            write_to_file(pd.Series(y_train_resampled_comb).value_counts().to_string())\n",
    "            \n",
    "            # Aplly SMOTE to the validation set only\n",
    "            X_val_resampled, y_val_resampled_comb = smote.fit_resample(X_val, y_val)\n",
    "\n",
    "            write_to_file(\"\\nValidation set distribution after SMOTE:\\n\")\n",
    "            write_to_file(pd.Series(y_val_resampled_comb).value_counts().to_string())\n",
    "        else:\n",
    "            X_train_resampled, y_train_resampled_comb = X_train, y_train\n",
    "            X_val_resampled, y_val_resampled_comb = X_val, y_val\n",
    "        #split back\n",
    "        y_train_resampled = pd.DataFrame(\n",
    "            y_train_resampled_comb.str.split(\"_\").tolist(), columns=[gender_col, label_col]\n",
    "        ).astype(float)\n",
    "        y_val_resampled = pd.DataFrame(\n",
    "            y_val_resampled_comb.str.split(\"_\").tolist(), columns=[gender_col, label_col]\n",
    "        ).astype(float)\n",
    "\n",
    "        y_train_resampled = y_train_resampled[label_col]\n",
    "        y_val_resampled = y_val_resampled[label_col]\n",
    "        write_to_file(\"\\nTraining set distribution after SMOTE:\\n\")\n",
    "        write_to_file(y_train_resampled.value_counts().to_string())\n",
    "        write_to_file(\"\\n+++++FINISHED SMOTING AND PREPRCESSING+++++\\n\")\n",
    "        # Normalize features if specified\n",
    "        if normalize:\n",
    "            scaler = StandardScaler()\n",
    "            X_train_resampled = pd.DataFrame(scaler.fit_transform(X_train_resampled), columns=features)\n",
    "            X_val_resampled = pd.DataFrame(scaler.transform(X_val_resampled), columns=features)\n",
    "            X_test = pd.DataFrame(scaler.transform(X_test), columns=features)\n",
    "        \n",
    "        #calculate how many samples where added to the training and test set\n",
    "        added_samples = len(X_train_resampled) - len(X_train)\n",
    "        added_samples_test = len(X_test) - len(test_set)\n",
    "        write_to_file(f\"Added {added_samples} samples to the training set and {added_samples_test} samples to the test set.\")\n",
    "\n",
    "        #get the ratio of posivte to negative and of sex in the test as one float\n",
    "        ratio_pos_neg = y_test.sum() / len(y_test)\n",
    "        sex_ratio = test_set[\"sex\"].sum() / len(test_set)\n",
    "\n",
    "        list_of_data_splits.append(\n",
    "            {\n",
    "                \"X_train\": X_train_resampled,\n",
    "                \"X_val\": X_val_resampled,\n",
    "                \"X_test\": X_test,\n",
    "                \"y_train\": y_train_resampled,\n",
    "                \"y_val\": y_val_resampled,\n",
    "                \"y_test\": y_test,\n",
    "                \"y_label_ratio\": ratio_pos_neg,\n",
    "                \"sex_label_ratio\": sex_ratio,\n",
    "                \"number_of_cross_validations\": number_of_cross_validations\n",
    "            }\n",
    "            )\n",
    "    return list_of_data_splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Early stopping,  you can increse number of epochs, and change 'patience' if you find the model is improving somehow\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=30, restore_best_weights=True, verbose=1\n",
    "    )\n",
    "# Pretrain Models\n",
    "def build_pretraining_model(input_shape, output_units, model_type=\"mlp\"):\n",
    "    \"\"\"\n",
    "    Builds a pretraining model for a categorical task.\n",
    "\n",
    "    Args:\n",
    "    - input_shape (tuple): Shape of the input data (features).\n",
    "    - output_units (int): Number of output classes.\n",
    "    - model_type (str): Type of model to build ('mlp' or 'cnn').\n",
    "\n",
    "    Returns:\n",
    "    - tf.keras.Model: Compiled model ready for training.\n",
    "    \"\"\"\n",
    "    if model_type == \"mlp\":\n",
    "        model = models.Sequential([\n",
    "            layers.Dense(256, activation='relu', input_shape=input_shape),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(64, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(output_units, activation='softmax')  # Multiclass output\n",
    "        ])\n",
    "    elif model_type == \"cnn\":\n",
    "        model = models.Sequential([\n",
    "            layers.Conv1D(128, kernel_size=3, activation='relu', input_shape=(input_shape[0], 1)),\n",
    "            layers.MaxPooling1D(pool_size=2),\n",
    "            layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "            layers.MaxPooling1D(pool_size=2),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dropout(0.3),\n",
    "            layers.Dense(output_units, activation='softmax')  # Multiclass output\n",
    "        ])\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model type. Choose 'mlp' or 'cnn'.\")\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pretraining Workflow, I dropped y and x val and used split during training because some tasks have inconsistency for input and output, does not affect the performance\n",
    "# beause of some inconsistency of numpy and tensorflow as well as scipy, i have to change and convert the data several times for different models\n",
    "# if you see some parts that you think is not neccasary when they are converting data and changing dim during runing, it is because of the python version of UKB_RAP, it may not be the same in different PC or Clouds\n",
    "\n",
    "def pretrain_models(X_train, y_train, X_val, y_val, save_path_mlp, save_path_cnn, input_shape, num_classes, epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Pretrains MLP and CNN models for a categorical task.\n",
    "\n",
    "    Args:\n",
    "    - X_train, y_train: Training data and labels.\n",
    "    - X_val, y_val: Validation data and labels.\n",
    "    - save_path_mlp, save_path_cnn: Paths to save the pretrained models.\n",
    "    - input_shape: Shape of the input data.\n",
    "    - num_classes: Number of output classes.\n",
    "    - epochs, batch_size: Training hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of trained MLP and CNN models.\n",
    "    \"\"\"\n",
    "    # Dynamically determine the number of classes\n",
    "    print(f\"Number of classes (num_classes): {num_classes}\")\n",
    "\n",
    "    print(\"Pretraining MLP...\")\n",
    "    mlp_model = build_pretraining_model(input_shape, num_classes, model_type=\"mlp\")\n",
    "    mlp_model.fit(X_train, y_train, validation_split = 0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "    mlp_model.save(save_path_mlp)\n",
    "    print(f\"MLP pretrained model saved to: {save_path_mlp}\")\n",
    "\n",
    "    print(\"Pretraining CNN...\")\n",
    "    # Adjust input shape for CNN\n",
    "    X_train_cnn = X_train.to_numpy()[..., np.newaxis]  # Convert to NumPy array and add channel dimension\n",
    "    X_val_cnn = X_val.to_numpy()[..., np.newaxis]  # Convert to NumPy array and add channel dimension\n",
    "\n",
    "    cnn_model = build_pretraining_model((input_shape[0], 1), num_classes, model_type=\"cnn\")\n",
    "    cnn_model.fit(X_train_cnn, y_train, validation_split = 0.2, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "    cnn_model.save(save_path_cnn)\n",
    "    print(f\"CNN pretrained model saved to: {save_path_cnn}\")\n",
    "\n",
    "    return mlp_model, cnn_model\n",
    "\n",
    "\n",
    "def fine_tune_both_models(mlp_path, cnn_path, X_train, y_train, X_val, y_val, X_test, y_test, output_units, epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Fine-tunes both MLP and CNN pretrained models.\n",
    "\n",
    "    Args:\n",
    "    - mlp_path, cnn_path: Paths to the pretrained models.\n",
    "    - X_train, y_train, X_val, y_val, X_test, y_test: Training, validation, and test data.\n",
    "    - output_units: Number of output units for binary classification.\n",
    "    - epochs, batch_size: Training hyperparameters.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Results for MLP and CNN fine-tuning.\n",
    "    \"\"\"\n",
    "    print(\"Fine-tuning MLP...\")\n",
    "    mlp_results = fine_tune_model(mlp_path, X_train, y_train, X_val, y_val, X_test, y_test, output_units, model_type=\"mlp\", epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    print(\"Fine-tuning CNN...\")\n",
    "    cnn_results = fine_tune_model(cnn_path, X_train, y_train, X_val, y_val, X_test, y_test, output_units, model_type=\"cnn\", epochs=epochs, batch_size=batch_size)\n",
    "    \n",
    "    return {\"MLP\": mlp_results, \"CNN\": cnn_results}\n",
    "# Fine-Tuning Pretrained Models\n",
    "def fine_tune_model(pretrained_path, X_train, y_train, X_val, y_val, X_test, y_test, output_units, model_type=\"mlp\", epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Fine-tunes a pretrained model for binary classification.\n",
    "\n",
    "    Args:\n",
    "    - pretrained_path: Path to the pretrained model.\n",
    "    - X_train, y_train, X_val, y_val, X_test, y_test: Training, validation, and test data.\n",
    "    - output_units: Number of output units (e.g., 1 for binary classification).\n",
    "    - model_type: \"mlp\" or \"cnn\".\n",
    "    - epochs: Number of epochs for training.\n",
    "    - batch_size: Batch size for training.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Evaluation metrics (ACC, AUC, Classification Report).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    print(f\"Loading pretrained model from {pretrained_path} for fine-tuning...\")\n",
    "    model = load_model(pretrained_path)\n",
    "    # i did not change anything for input as you said we need to pretrain for reduced features, so if you need to train only on full data and try finetuning in reduced data, we can add an input layer to make it a little flexible\n",
    "    \n",
    "    # Modify the final layer for fine-tuning\n",
    "    if hasattr(model, 'pop'):  # Some Keras models support pop()\n",
    "        model.pop()\n",
    "    else:  # Recreate the model without the last layer\n",
    "        model = tf.keras.Model(inputs=model.input, outputs=model.layers[-2].output)\n",
    "\n",
    "    model.add(Dense(output_units, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    # Adjust input shape for CNN\n",
    "    if model_type == \"cnn\":\n",
    "        if isinstance(X_train, pd.DataFrame):\n",
    "            X_train = X_train.values\n",
    "            X_val = X_val.values\n",
    "            X_test = X_test.values\n",
    "        X_train = X_train[..., np.newaxis]  # Add channel dimension\n",
    "        X_val = X_val[..., np.newaxis]      # Add channel dimension\n",
    "        X_test = X_test[..., np.newaxis]    # Add channel dimension\n",
    "\n",
    "    # Debugging input shapes\n",
    "    print(f\"Fine-tuning {model_type.upper()} - X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "\n",
    "    # Train the model\n",
    "    print(f\"Starting fine-tuning for {model_type.upper()}...\")\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "    print(f\"Fine-tuning for {model_type.upper()} complete!\")\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, np.round(y_pred))\n",
    "    balanced_acc = balanced_accuracy_score(y_test, np.round(y_pred))\n",
    "    report = classification_report(y_test, np.round(y_pred))\n",
    "\n",
    "    #Evaluat against random permutation\n",
    "    random_y_test = np.random.randint(0, 2, size=y_test.shape)\n",
    "    random_balanced_acc = balanced_accuracy_score(random_y_test, np.round(y_pred))\n",
    "    return {\"ACC\": acc, \"AUC\": auc, \"Balanced ACC\": balanced_acc, \"Random Balanced ACC\" : random_balanced_acc, \"Classification Report\": report}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Debugging Preprocessing Steps\n",
    "def debug_preprocessing(data, sampling, use_feature_extraction, label_col):\n",
    "    print(\"\\n--- Initial Data ---\")\n",
    "    print(data.head())\n",
    "\n",
    "    if sampling:\n",
    "        print(\"\\n--- After Sampling ---\")\n",
    "        print(data.head())\n",
    "\n",
    "    if use_feature_extraction:\n",
    "        print(\"\\n--- After Feature Extraction ---\")\n",
    "        print(data[label_col].head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Build CNN model\n",
    "def build_cnn_model(input_shape, output_units):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv1D(256, kernel_size=3, activation='relu', input_shape=(input_shape[0], 1)),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Conv1D(128, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(output_units, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Build MLP model\n",
    "def build_mlp_model(input_shape, output_units):\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=input_shape),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(output_units, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Train and evaluate ML models\n",
    "def train_ml_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    #Evaluat against random permutation\n",
    "    random_y_test = np.random.randint(0, 2, size=y_test.shape)\n",
    "    random_balanced_acc = balanced_accuracy_score(random_y_test, y_pred)\n",
    "    return {\"AUC\": auc, \"ACC\": acc, \"Balanced ACC\": balanced_acc, \"Random Balanced ACC\" : random_balanced_acc, \"Classification Report\": report}\n",
    "\n",
    "# Train and evaluate DL models\n",
    "# Train and evaluate DL models\n",
    "def train_dl_model(model, X_train, y_train, X_val, y_val, X_test, y_test, model_type=\"mlp\", epochs=100, batch_size=32):\n",
    "    \"\"\"\n",
    "    Trains and evaluates a deep learning model.\n",
    "\n",
    "    Args:\n",
    "    - model: Keras model to train.\n",
    "    - X_train, X_val, X_test: Training, validation, and test features (DataFrames or NumPy arrays).\n",
    "    - y_train, y_val, y_test: Training, validation, and test labels.\n",
    "    - model_type: \"mlp\" or \"cnn\".\n",
    "    - epochs: Number of epochs for training.\n",
    "    - batch_size: Batch size.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Evaluation metrics (ACC, AUC, Balanced ACC, Classification Report).\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Convert DataFrames to NumPy arrays if necessary\n",
    "    if isinstance(X_train, pd.DataFrame):\n",
    "        X_train = X_train.values\n",
    "        X_val = X_val.values\n",
    "        X_test = X_test.values\n",
    "\n",
    "    # Add channel dimension for CNN input\n",
    "    if model_type == \"cnn\":\n",
    "        X_train = X_train[..., np.newaxis]\n",
    "        X_val = X_val[..., np.newaxis]\n",
    "        X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=epochs, batch_size=batch_size, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test).flatten()\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, np.round(y_pred))\n",
    "    balanced_acc = balanced_accuracy_score(y_test, np.round(y_pred))\n",
    "    report = classification_report(y_test, np.round(y_pred))\n",
    "\n",
    "    random_y_test = np.random.randint(0, 2, size=y_test.shape)\n",
    "    random_balanced_acc = balanced_accuracy_score(random_y_test, np.round(y_pred))\n",
    "    return {\"AUC\": auc, \"ACC\": acc, \"Balanced ACC\": balanced_acc, \"Random Balanced ACC\" : random_balanced_acc, \"Classification Report\": report}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(data, excluded_labels=None, p_value_threshold=0.05, min_features=5, scaling_factor=10, use_feature_extraction=True):\n",
    "    if not use_feature_extraction:\n",
    "        print(\"Feature extraction is disabled. Returning the original dataset.\")\n",
    "        return data, None\n",
    "    # Ensure excluded_labels is a list\n",
    "    excluded_labels = excluded_labels or []\n",
    "    if not isinstance(excluded_labels, list):\n",
    "        raise ValueError(\"excluded_labels must be a list or None.\")\n",
    "    #if there is a None value in the list, drop it\n",
    "    excluded_labels = [label for label in excluded_labels if label is not None]\n",
    "    excluded_features = set(excluded_labels)\n",
    "    \n",
    "\n",
    "    y = data[\"y_train\"].astype(int)  # Ensure binary label is numeric (0/1)\n",
    "    X = data[\"X_train\"]  # Extract relevant feature columns\n",
    "    write_to_file(f\"Number of columns before feature extraction: {len(X.columns)}\")\n",
    "\n",
    "    # Store correlation results\n",
    "    correlation_results = {}\n",
    "    for column in X.columns:\n",
    "        if X[column].nunique() <= 1:\n",
    "            continue  # Skip constant features\n",
    "        \n",
    "        if np.issubdtype(X[column].dtype, np.number):  # Numerical features\n",
    "            try:\n",
    "                _, p_value = pointbiserialr(X[column], y)\n",
    "            except ValueError:  # Handle constant input issues\n",
    "                continue\n",
    "        else:  # Categorical features\n",
    "            try:\n",
    "                contingency_table = pd.crosstab(X[column], y)\n",
    "                _, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        correlation_results[column] = {'P-value': p_value}\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    correlation_df = pd.DataFrame(correlation_results).T\n",
    "\n",
    "    # Dynamically calculate max_features based on sample size\n",
    "    sample_size = len(X)\n",
    "    max_features = calculate_max_features(sample_size, min_features=min_features, scaling_factor=scaling_factor)\n",
    "\n",
    "    # Filter features based on p-value threshold\n",
    "    filtered_features = correlation_df[correlation_df['P-value'] < p_value_threshold].index.tolist()\n",
    "\n",
    "    if len(filtered_features) < max_features:\n",
    "        # Not enough features, select the top `max_features` ranked by p-value\n",
    "        filtered_features = correlation_df.nsmallest(max_features, 'P-value').index.tolist()\n",
    "\n",
    "    # Print the 5 most significant features and their p-values\n",
    "    most_significant = correlation_df.nsmallest(5, 'P-value')\n",
    "    write_to_file(f\"Top 5 most significant features and their p-values:\\n{most_significant}\\nNumber of columns after feature extraction: {len(filtered_features)}\")\n",
    "    data[\"X_train\"] = data[\"X_train\"][filtered_features]\n",
    "    data[\"X_val\"] = data[\"X_val\"][filtered_features]\n",
    "    data[\"X_test\"] = data[\"X_test\"][filtered_features]\n",
    "\n",
    "    # Retain excluded labels in the returned dataset\n",
    "    return data, correlation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(perform_pretraining, use_feature_extraction, brain_csv_path, labels_csv_paths, label_col, age_col=None, id_col=\"ID\", sex_col=\"sex\"):\n",
    "    try:\n",
    "        number_of_positive= -99\n",
    "        number_of_negative= -99\n",
    "        number_of_cross_validation = -99\n",
    "        mri_table_type = brain_csv_path.split('/')[-1]\n",
    "        merged_data = prepare_dataset(\n",
    "            brain_csv_path=brain_csv_path,\n",
    "            labels_csv_path=labels_csv_paths,\n",
    "            id_col=id_col,\n",
    "            label_col=label_col,\n",
    "            additional_cols=[age_col],\n",
    "            smote_upsampling_for_sex=sex_col is not None,\n",
    "            sex_col=sex_col\n",
    "        )\n",
    "\n",
    "        if len(merged_data) < 59:\n",
    "            write_to_file(f\"Dataset size for label {label_col} and {brain_csv_path.split('/')[-1]} is too small for training {len(merged_data)}\")\n",
    "        number_of_positive = len(merged_data[merged_data[label_col] == 1])\n",
    "        number_of_negative = len(merged_data[merged_data[label_col] == 0])\n",
    "        number_of_male = len(merged_data[merged_data[sex_col] == 1])\n",
    "        number_of_female = len(merged_data[merged_data[sex_col] == 0])\n",
    "        write_to_file(f\"Number of positive, before sampling: {number_of_positive}\")\n",
    "        write_to_file(f\"Number of negative, before sampling: {number_of_negative}\")\n",
    "        write_to_file(f\"Number of male, before sampling {number_of_male}\")\n",
    "        write_to_file(f\"Number of female, before sampling {number_of_female}\")\n",
    "        # Optional Feature Extraction True or False\n",
    "\n",
    "        if sex_col is not None:\n",
    "            processed_data_test_sampled = preprocess_balanced_binary_data(\n",
    "                data=merged_data.copy(deep=True),\n",
    "                features=[col for col in merged_data.columns if col not in [id_col, label_col, age_col, sex_col]],\n",
    "                label_col=label_col,\n",
    "                gender_col=sex_col,\n",
    "            )\n",
    "        \n",
    "        for cross_val_count, processed_data in enumerate(processed_data_test_sampled):\n",
    "            y_label_ratio = processed_data['y_label_ratio']\n",
    "            sex_label_ratio = processed_data[\"sex_label_ratio\"]\n",
    "            number_of_cross_validation = processed_data[\"number_of_cross_validations\"]\n",
    "    \n",
    "            if use_feature_extraction:\n",
    "                print(\"Performing feature extraction...\")\n",
    "                processed_data, correlation_results = feature_extraction(\n",
    "                    data = processed_data,\n",
    "                    excluded_labels=None,\n",
    "                    p_value_threshold=0.05\n",
    "                )\n",
    "            # Step 4: Pretraining and Fine-Tuning (Optional)\n",
    "            # of cource you may say why it is always using and defining data in different sections, but in fact using CNN beside all one dimention models would be sometimes challenging and brings a lot of error, that is why i used and defined data in every section\n",
    "            # we may make them better but it need a little more time to make codes optimal\n",
    "            # in someway, you may think why we are always training to make ptetrain model, we can just save then always use finetuning. the reason is that in every table we may have different shape and different results for feature extraction.\n",
    "            # the age then will  be pretrained on new data and new dimentions \n",
    "\n",
    "            if perform_pretraining:\n",
    "                print(\"\\nPerforming pretraining and fine-tuning not implemented yet with cross vladiation\")\n",
    "            # Step 3: Preprocessing for Age (Multi-Class), i did not make age in different ranges, i am using them as classes, and they are more than 80 class, if you get less accuray that is the reason, you can use the range \n",
    "                processed_data_age = preprocess_multiclass_data(\n",
    "                data=merged_data,\n",
    "                features=[col for col in merged_data.columns if col not in [id_col, label_col, age_col,sex_col]], # to make sure taht your model works fine you can also include the label during the training and see overfitting and learning process if you want \n",
    "                label_col=age_col,\n",
    "                test_size=0.2,\n",
    "                normalize=True,\n",
    "                random_state=42\n",
    "            )\n",
    "                # Pretrain MLP and CNN with Age\n",
    "                # Call the Pretraining Function\n",
    "                mlp_model, cnn_model = pretrain_models(\n",
    "                X_train=processed_data_age['X_train'],\n",
    "                y_train=tf.keras.utils.to_categorical(processed_data_age['y_train']),\n",
    "                X_val=processed_data_age['X_val'],\n",
    "                y_val=tf.keras.utils.to_categorical(processed_data_age['y_val']),\n",
    "                save_path_mlp=\"pretrained_mlp_age.h5\",\n",
    "                save_path_cnn=\"pretrained_cnn_age.h5\",\n",
    "                input_shape=(processed_data_age['X_train'].shape[1],),\n",
    "                num_classes=tf.keras.utils.to_categorical(processed_data_age['y_train']).shape[1],  # Dynamically set output units\n",
    "                epochs=100,\n",
    "                batch_size=32\n",
    "            )\n",
    "\n",
    "                # Fine-Tune Models\n",
    "                fine_tune_results = fine_tune_both_models(\n",
    "                    mlp_path=\"pretrained_mlp_age.h5\",\n",
    "                    cnn_path=\"pretrained_cnn_age.h5\",\n",
    "                    X_train=processed_data['X_train'],\n",
    "                    y_train=processed_data['y_train'],\n",
    "                    X_val=processed_data['X_val'],\n",
    "                    y_val=processed_data['y_val'],\n",
    "                    X_test=processed_data['X_test'],\n",
    "                    y_test=processed_data['y_test'],\n",
    "                    output_units=1,\n",
    "                    epochs=100,\n",
    "                    batch_size=32\n",
    "                )\n",
    "\n",
    "                # Display Fine-Tuning Results\n",
    "                for model_type, result in fine_tune_results.items():\n",
    "                    print(f\"\\n--- {model_type} Fine-Tuning Results ---\")\n",
    "                    print(f\"AUC: {result['AUC']:.4f}\")\n",
    "                    print(f\"Balanced ACC: {result['Balanced ACC']:.4f}\")\n",
    "                    print(f\"ACC: {result['ACC']:.4f}\")\n",
    "                    print(\"Classification Report:\")\n",
    "                    print(result[\"Classification Report\"])\n",
    "                    write_to_file(f\"\\n--- {model_type} Fine-Tuning Results ---\\nAUC: {result['AUC']:.4f}\\n Balanced ACC: {result['Balanced ACC']:.4f}\\nACC: {result['ACC']:.4f}\\nClassification Report:\\n{result['Classification Report']}\", print_inplace=False)\n",
    "                    write_to_csv(   label_col=label_col,\n",
    "                                    mri_table=mri_table_type,\n",
    "                                    number_of_pos=number_of_positive,\n",
    "                                    number_of_neg=number_of_negative,\n",
    "                                    test_set_size=len(processed_data['y_test']),\n",
    "                                    y_label_ratio= y_label_ratio,\n",
    "                                    sex_label_ratio=sex_label_ratio,\n",
    "                                    Feature_extraction_applied=use_feature_extraction,\n",
    "                                    Pretraining_applied=True,\n",
    "                                    model_type=model_type,\n",
    "                                    Accuracy=result['ACC'],\n",
    "                                    AUC=result['AUC'],\n",
    "                                    Balanced_ACC=result['Balanced ACC'],\n",
    "                                    Permutation_Balanced_ACC=result['Random Balanced ACC'],\n",
    "                                    number_of_cross_validations=number_of_cross_validation,\n",
    "                                    cross_validation_count=cross_val_count)\n",
    "                                \n",
    "            else:\n",
    "                print(\"\\nSkipping pretraining and fine-tuning as per user setting.\\n\")\n",
    "\n",
    "            # Step 5: Training ML Models (Logistic Regression and Random Forest)\n",
    "            # I just used RF and LR, i guess using more ML methods would not help us, as we only focus on deep side, we can also add more but i guess does not make sence, these two would be enough as baseline \n",
    "            ml_results = {}\n",
    "            print('................................................................................................')\n",
    "            print('ML is running... please wait :)')\n",
    "            # Logistic Regression\n",
    "            lr_model = LogisticRegression(random_state=42)\n",
    "            ml_results['Logistic Regression'] = train_ml_model(\n",
    "                model=lr_model,\n",
    "                X_train=processed_data['X_train'],\n",
    "                y_train=processed_data['y_train'],\n",
    "                X_test=processed_data['X_test'],\n",
    "                y_test=processed_data['y_test']\n",
    "            )\n",
    "\n",
    "            # Random Forest\n",
    "            rf_model = RandomForestClassifier(random_state=42)\n",
    "            ml_results['Random Forest'] = train_ml_model(\n",
    "                model=rf_model,\n",
    "                X_train=processed_data['X_train'],\n",
    "                y_train=processed_data['y_train'],\n",
    "                X_test=processed_data['X_test'],\n",
    "                y_test=processed_data['y_test']\n",
    "            )\n",
    "\n",
    "            xgb_model = XGBClassifier(random_state=42)\n",
    "            ml_results['XGBoost'] = train_ml_model(\n",
    "                model=xgb_model,\n",
    "                X_train=processed_data['X_train'],\n",
    "                y_train=processed_data['y_train'],\n",
    "                X_test=processed_data['X_test'],\n",
    "                y_test=processed_data['y_test']\n",
    "            )\n",
    "            \n",
    "\n",
    "            tabpf_model = TabPFNClassifier()\n",
    "            ml_results['TabPFN'] = train_ml_model(\n",
    "                model=tabpf_model,\n",
    "                X_train=processed_data['X_train'],\n",
    "                y_train=processed_data['y_train'],\n",
    "                X_test=processed_data['X_test'],\n",
    "                y_test=processed_data['y_test']\n",
    "            )\n",
    "            # Display ML Results\n",
    "            for model_name, result in ml_results.items():\n",
    "                print(f\"\\n--- {model_name} Results ---\")\n",
    "                print(f\"AUC: {result['AUC']:.4f}\")\n",
    "                print(f\"Balanced ACC: {result['Balanced ACC']:.4f}\")\n",
    "                print(f\"ACC: {result['ACC']:.4f}\")\n",
    "                print(f\"Permutation Balanced ACC: {result['Random Balanced ACC']:.4f}\")\n",
    "                print(\"Classification Report:\")\n",
    "                print(result[\"Classification Report\"])\n",
    "                write_to_file(f\"\\n--- {model_name} Results ---\\nAUC: {result['AUC']:.4f}\\nBalanced ACC: {result['Balanced ACC']:.4f}\\nACC: {result['ACC']:.4f}\\nClassification Report:\\n{result['Classification Report']}\", print_inplace=False)\n",
    "                write_to_csv(   label_col=label_col,\n",
    "                                mri_table=mri_table_type,\n",
    "                                number_of_pos=number_of_positive,\n",
    "                                number_of_neg=number_of_negative,\n",
    "                                test_set_size=len(processed_data['y_test']),\n",
    "                                y_label_ratio= y_label_ratio,\n",
    "                                sex_label_ratio=sex_label_ratio,\n",
    "                                Feature_extraction_applied=use_feature_extraction,\n",
    "                                Pretraining_applied=False,\n",
    "                                model_type=model_name,\n",
    "                                Accuracy=result['ACC'],\n",
    "                                AUC=result['AUC'],\n",
    "                                Balanced_ACC=result['Balanced ACC'],\n",
    "                                Permutation_Balanced_ACC=result['Random Balanced ACC'],\n",
    "                                number_of_cross_validations=number_of_cross_validation,\n",
    "                                cross_validation_count=cross_val_count)\n",
    "            del processed_data\n",
    "            gc.collect()\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        write_to_file(f\"Error: {e} for {label_col} and {brain_csv_path.split('/')[-1]}\", print_inplace=True)\n",
    "        write_to_csv(  label_col=label_col,\n",
    "                        mri_table=mri_table_type,\n",
    "                        number_of_pos=number_of_positive,\n",
    "                        number_of_neg=number_of_negative,\n",
    "                        test_set_size=-99,\n",
    "                        y_label_ratio= -99,\n",
    "                        sex_label_ratio=-99,\n",
    "                        Feature_extraction_applied=use_feature_extraction,\n",
    "                        Pretraining_applied=False,\n",
    "                        model_type=f'Error {e}',\n",
    "                        Accuracy=-99,\n",
    "                        AUC=-99,\n",
    "                        Balanced_ACC=-99,\n",
    "                        Permutation_Balanced_ACC=-99,\n",
    "                        number_of_cross_validations=number_of_cross_validation,\n",
    "                        cross_validation_count=-99) \n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_labels(path, label_col_types, specific_labels, cols_to_keep=['ID', 'sex'], path_to_save=\"/zi/home/esra.lenz/Documents/00_HITKIP/00_CLIP/00_NAKO/02_Validation_of_UKB/99_logs/\"):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Initialize a set to track unique columns to keep\n",
    "    unique_columns = set(cols_to_keep)\n",
    "\n",
    "    # Loop through each label column type\n",
    "    for label_col_typ in label_col_types:\n",
    "        # Filter columns that match the label column type\n",
    "        matching_columns = [col for col in df.columns if label_col_typ in col]\n",
    "        unique_columns.update(matching_columns)\n",
    "\n",
    "    # Add specific labels to the unique columns\n",
    "    unique_columns.update(specific_labels)\n",
    "\n",
    "    #sort the columns\n",
    "    unique_columns_list = sorted(list(unique_columns))\n",
    "    # Ensure only unique columns are kept in the dataframe\n",
    "    filtered_df = df[unique_columns_list]\n",
    "\n",
    "    new_name = path.split('/')[-1].split('.')[0]\n",
    "    new_path = f\"{new_name}_filtered.csv\"\n",
    "    new_path = path_to_save + new_path\n",
    "    # Save the filtered dataframe back to the same path\n",
    "    filtered_df.to_csv(f\"{new_path}\", index=False)\n",
    "\n",
    "    print(f\"Filtered dataframe saved to {path} with columns: {unique_columns_list}\")\n",
    "    write_to_file(f\"Filtered dataframe saved to {path} with columns: {unique_columns_list}\")\n",
    "    return new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mri_paths(mri_tables):\n",
    "    mri_paths = []\n",
    "    for file in os.listdir(mri_tables):\n",
    "        if file.endswith(\".csv\"):\n",
    "            mri_paths.append(os.path.join(mri_tables, file))\n",
    "    return mri_paths\n",
    "\n",
    "def get_all_labels(df, inidcator = \"label_\"):\n",
    "    labels = []\n",
    "    for col in df.columns:\n",
    "        if inidcator in col:\n",
    "            labels.append(col)\n",
    "    return labels\n",
    "\n",
    "def view_merge_details_fct(labels, all_label_df, mri_paths):\n",
    "    for label in labels:\n",
    "        filterd_df = all_label_df[[\"ID\", label]]\n",
    "        print(f\"Value count for \", filterd_df[label].value_counts())\n",
    "        for mri_path in mri_paths:\n",
    "            mri_df = pd.read_csv(mri_path)\n",
    "            mri = mri_path.split(\"/\")[-1].replace(\".csv\", \"\")\n",
    "            merged_df = filterd_df.merge(mri_df, on=\"ID\", how=\"inner\")\n",
    "            print(f\"Shape for {label} and {mri} is \\n\", merged_df.shape)\n",
    "            print(f\"Value count for {label} after merge \\n\", merged_df[label].value_counts())\n",
    "\n",
    "def get_data_mri_and_label_path(\n",
    "        all_labels_path = \"/zi/home/esra.lenz/Documents/00_HITKIP/00_CLIP/00_NAKO/02_Validation_of_UKB/00_data/depression_3.csv\", \n",
    "        mri_tables_path=\"/zi/home/esra.lenz/Documents/00_HITKIP/00_CLIP/00_NAKO/02_Validation_of_UKB/00_data/mri_table_for_loop/\",\n",
    "        view_merge_details=False):\n",
    "    mri_paths = load_mri_paths(mri_tables_path)\n",
    "    all_label_df = pd.read_csv(all_labels_path)\n",
    "    labels= get_all_labels(df=all_label_df, inidcator = \"label_\")\n",
    "    if view_merge_details:\n",
    "        view_merge_details_fct(labels, all_label_df, mri_paths)\n",
    "    return all_label_df, mri_paths, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iteration_loop(all_labels_path, mri_pathes, labels,time_tag):\n",
    "    for label in labels:\n",
    "        for mri_path in mri_pathes:\n",
    "            print(\"Now Training\")\n",
    "            write_to_file(input=f\"Label: {label}, MRI: {mri_path.split('/')[-1]}\\n\")\n",
    "            write_to_file(input=f\"search_term: {label}_{mri_path.split('/')[-1]}\\n\")\n",
    "            write_to_file(input=\"\\n##### With Feature Extraction #####\\n\") \n",
    "            succeeded = train_models(perform_pretraining=False, use_feature_extraction=True, brain_csv_path=mri_path, labels_csv_paths=all_labels_path, label_col=label)\n",
    "            if succeeded == False:\n",
    "                continue\n",
    "            write_to_file(input=\"\\n##### Without Feature Extraction #####\\n\")\n",
    "            train_models(perform_pretraining=False, use_feature_extraction=False, brain_csv_path=mri_path, labels_csv_paths=all_labels_path, label_col=label)\n",
    "            write_to_file(input=\"\\n##############################################################################################################\\n\")\n",
    "        sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels_path = choose_labels(path=\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/age_label/all_ages.csv\", label_col_types=[], specific_labels=[\"label_Age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_label_df, mri_pathes, labels = get_data_mri_and_label_path(all_labels_path=all_labels_path,\n",
    "    mri_tables_path=\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/00_NAKO/00_data/deconfounded_but_age/\")\n",
    "time_tag = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "print(mri_pathes)\n",
    "iteration_loop(all_labels_path, mri_pathes, labels,time_tag)\n",
    "write_to_file(input=\"FINISHED TERMINATING INSTANCE\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NAKO_CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
