{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 14:34:29.767545: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-31 14:34:29.782768: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-01-31 14:34:29.804955: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-01-31 14:34:29.805003: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-31 14:34:29.820047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-31 14:34:31.798505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn imports\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import  statsmodels.api as sm\n",
    "\n",
    "# Keras imports\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Scikeras wrapper for Keras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# (Hypothetical) TabPFN Regressor\n",
    "# If the TabPFN package does not provide a regressor, remove or replace this import\n",
    "from tabpfn import TabPFNRegressor  # Placeholder for a potential TabPFNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "###############################################################################\n",
    "# MLP Model Definition\n",
    "\n",
    "###############################################################################\n",
    "def create_mlp_model(input_shape):\n",
    "    \"\"\"\n",
    "    Create a simple MLP model for regression.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(1024, activation=\"relu\", input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(512, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        # Final layer for regression: linear activation, 1 output\n",
    "        Dense(1, activation=\"linear\")\n",
    "    ])\n",
    "    model.compile(optimizer='adam', \n",
    "                  loss='mean_squared_error', \n",
    "                  metrics=['mean_absolute_error'])\n",
    "    return model\n",
    "\n",
    "###############################################################################\n",
    "# CUDA / Memory Cleanup\n",
    "###############################################################################\n",
    "def clean_up_cuda(model):\n",
    "    \"\"\"\n",
    "    Free up GPU memory and clear Keras session.\n",
    "    \"\"\"\n",
    "    # Delete the Keras model\n",
    "    K.clear_session()\n",
    "    del model\n",
    "    \n",
    "    # Run garbage collection\n",
    "    gc.collect()\n",
    "    \n",
    "    # Free CUDA memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.ipc_collect()\n",
    "    \n",
    "    print(\"CUDA memory cleared and model deleted.\")\n",
    "\n",
    "###############################################################################\n",
    "# Regression Metrics & Aggregation\n",
    "###############################################################################\n",
    "def evaluate_regression_performance(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute regression metrics for predictions.\n",
    "    Returns a dictionary with MSE, MAE, and R2.\n",
    "    \"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    results = {\n",
    "        'mse': mse,\n",
    "        'mae': mae,\n",
    "        'r2': r2\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_regression_performance(results):\n",
    "    \"\"\"\n",
    "    Print regression performance metrics nicely.\n",
    "    \"\"\"\n",
    "    print(f\"MSE: {results['mse']:.4f}\")\n",
    "    print(f\"MAE: {results['mae']:.4f}\")\n",
    "    print(f\"R²:  {results['r2']:.4f}\")\n",
    "\n",
    "def aggregate_cv_metrics_and_print(all_results, model_name, tag=\"Validation\"):\n",
    "    \"\"\"\n",
    "    Aggregate cross-validation metrics (MSE, MAE, R2)\n",
    "    and return mean + std across folds.\n",
    "    \"\"\"\n",
    "    aggregated = {\n",
    "        'mse': [],\n",
    "        'mae': [],\n",
    "        'r2': []\n",
    "    }\n",
    "    \n",
    "    for result in all_results:\n",
    "        aggregated['mse'].append(result['mse'])\n",
    "        aggregated['mae'].append(result['mae'])\n",
    "        aggregated['r2'].append(result['r2'])\n",
    "        \n",
    "    summary = {\n",
    "        'mean_mse':  np.mean(aggregated['mse']),\n",
    "        'std_mse':   np.std(aggregated['mse']),\n",
    "        'mean_mae':  np.mean(aggregated['mae']),\n",
    "        'std_mae':   np.std(aggregated['mae']),\n",
    "        'mean_r2':   np.mean(aggregated['r2']),\n",
    "        'std_r2':    np.std(aggregated['r2']),\n",
    "    }\n",
    "    print(f\"\\n {model_name} Classifier Performance {tag}:\")\n",
    "    print_cv_summary(summary)\n",
    "    return summary\n",
    "\n",
    "def print_cv_summary(summary):\n",
    "    \"\"\"\n",
    "    Print the aggregated CV summary (MSE, MAE, R²).\n",
    "    \"\"\"\n",
    "    print(f\"Mean MSE:  {summary['mean_mse']:.4f} ± {summary['std_mse']:.4f}\")\n",
    "    print(f\"Mean MAE:  {summary['mean_mae']:.4f} ± {summary['std_mae']:.4f}\")\n",
    "    print(f\"Mean R²:   {summary['mean_r2']:.4f} ± {summary['std_r2']:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/zi/home/sajad.rezaei/clip/clip/02_Full_Pipeline/src/pair/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df = pd.read_csv(\"/zi/home/sajad.rezaei/clip/clip/02_Full_Pipeline/src/pair/all_ages.csv\")\n",
    "n_splits = 5\n",
    "\n",
    "merged_df = pd.merge(df, label_df, on='ID', how='inner')\n",
    "merged_df.dropna(inplace=True)\n",
    "df_sampled, _ = train_test_split(merged_df, train_size=10000, stratify=merged_df[\"label_age_group\"], random_state=42)\n",
    "s = df_sampled[\"label_Age\"].value_counts()\n",
    "\n",
    "y = df_sampled[\"label_Age\"]\n",
    "col_to_drop = [col for col in label_df.columns]\n",
    "X = df_sampled.drop(col_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_age_group\n",
      "3.0    3141\n",
      "2.0    3141\n",
      "4.0    2912\n",
      "1.0    1500\n",
      "0.0    1364\n",
      "5.0     211\n",
      "Name: count, dtype: int64\n",
      "Total samples: 12269\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Get class distribution\n",
    "class_counts = merged_df[\"label_age_group\"].value_counts()\n",
    "\n",
    "# Step 1: Retain all samples from the 3 smallest classes\n",
    "smallest_classes = class_counts.nsmallest(3).index\n",
    "df_smallest = merged_df[merged_df[\"label_age_group\"].isin(smallest_classes)]\n",
    "\n",
    "# Step 2: Calculate remaining samples needed to reach 10,000\n",
    "remaining_size = 12500- len(df_smallest)\n",
    "\n",
    "# Step 3: Select the remaining larger classes\n",
    "remaining_classes = class_counts.nlargest(len(class_counts) - 3).index\n",
    "df_remaining = merged_df[merged_df[\"label_age_group\"].isin(remaining_classes)]\n",
    "\n",
    "# Step 4: Determine the number of samples to take per remaining class proportionally\n",
    "samples_per_class = remaining_size // len(remaining_classes)\n",
    "\n",
    "# Downsample the remaining classes to fill the dataset\n",
    "balanced_majority = df_remaining.groupby(\"label_age_group\").apply(\n",
    "    lambda x: x.sample(n=min(len(x), samples_per_class), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Combine both parts to form the final balanced dataset\n",
    "balanced_df = pd.concat([df_smallest, balanced_majority])\n",
    "\n",
    "# Verify the final class distribution\n",
    "print(balanced_df[\"label_age_group\"].value_counts())\n",
    "print(\"Total samples:\", len(balanced_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID', 'sex', 'assessment_centre', 'label_Age', 'label_age_group']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_Age\n",
       "47    531\n",
       "49    529\n",
       "50    519\n",
       "48    506\n",
       "46    464\n",
       "51    453\n",
       "52    421\n",
       "53    420\n",
       "44    419\n",
       "45    400\n",
       "54    382\n",
       "43    372\n",
       "55    363\n",
       "56    349\n",
       "63    344\n",
       "65    340\n",
       "58    337\n",
       "64    330\n",
       "42    322\n",
       "61    318\n",
       "62    318\n",
       "57    314\n",
       "66    303\n",
       "60    283\n",
       "41    271\n",
       "67    268\n",
       "59    268\n",
       "40    255\n",
       "68    238\n",
       "29    218\n",
       "28    201\n",
       "30    183\n",
       "27    180\n",
       "31    172\n",
       "69    170\n",
       "32    160\n",
       "37    159\n",
       "25    159\n",
       "26    158\n",
       "39    152\n",
       "35    146\n",
       "36    137\n",
       "24    135\n",
       "38    135\n",
       "23    133\n",
       "34    129\n",
       "33    127\n",
       "70    119\n",
       "22     94\n",
       "71     69\n",
       "21     62\n",
       "20     24\n",
       "72     22\n",
       "19      4\n",
       "74      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_control = pd.read_csv(\"/zi/home/sajad.rezaei/clip/clip/02_Full_Pipeline/src/pair/aseg.volume_aparc.volume_aparc.thickness.csv\")\n",
    "label_df_control = pd.read_csv(\"/zi/home/sajad.rezaei/clip/clip/02_Full_Pipeline/src/pair/all_ages.csv\")\n",
    "\n",
    "# df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/final_folder/aparc.thickness_aparc.volume_aseg.volume.csv\")\n",
    "# label_df_control = pd.read_csv(\"/zi/home/esra.lenz/Documents/00_HITKIP/09_TABPFN/01_Validation_data_set/00_data/final_folder/aparc.thickness_aparc.volume_aseg.volume_label.csv\")\n",
    "\n",
    "label_df_control = label_df_control[['ID', 'label_Age']]\n",
    "df_control = df_control[df.columns]\n",
    "merged_df_control = pd.merge(df_control, label_df_control, on='ID', how='inner')\n",
    "merged_df_control.dropna(inplace=True)\n",
    "\n",
    "X_control = merged_df_control.drop([\"ID\", \"label_Age\"], axis=1)\n",
    "y_control = merged_df_control[\"label_Age\"]\n",
    "\n",
    "merged_df_control[\"label_Age\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n",
      "13886 13886\n",
      "192 192\n"
     ]
    }
   ],
   "source": [
    "#make sure that the order of columns is the same\n",
    "X = X[X_control.columns]\n",
    "#check len of X and y\n",
    "print(len(X), len(y))\n",
    "print(len(X_control), len(y_control))\n",
    "#columns number\n",
    "print(X.shape[1], X_control.shape[1])\n",
    "\n",
    "for col in X.columns:\n",
    "    if col not in X_control.columns:\n",
    "        print(col)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_with_Pearson(X, X_val, X_control, y, threshold=0.6, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    correlation_matrix = X.corr().abs()\n",
    "    upper = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    X = X.drop(columns=to_drop)\n",
    "    X_val = X_val.drop(columns=to_drop)\n",
    "    X_control = X_control.drop(columns=to_drop)\n",
    "    return X.to_numpy(), X_val.to_numpy(), X_control.to_numpy()\n",
    "\n",
    "def feature_extration_with_PCA(X, X_val, X_control, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    X_val_pca = pca.transform(X_val)\n",
    "    X_control_pca = pca.transform(X_control)\n",
    "    return X_pca, X_val_pca, X_control_pca\n",
    "\n",
    "def feature_extration_with_BE(X, X_val, X_control, y, significance_level=0.05, df_columns=None):\n",
    "    if isinstance(X, np.ndarray):\n",
    "        X = pd.DataFrame(X)\n",
    "        if df_columns is not None:\n",
    "            X.columns = df_columns\n",
    "    if isinstance(X_val, np.ndarray):\n",
    "        X_val = pd.DataFrame(X_val)\n",
    "        if df_columns is not None:\n",
    "            X_val.columns = df_columns\n",
    "    if isinstance(X_control, np.ndarray):\n",
    "        X_control = pd.DataFrame(X_control)\n",
    "        if df_columns is not None:\n",
    "            X_control.columns = df_columns\n",
    "    # Add constant for intercept\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    X = sm.add_constant(X)\n",
    "\n",
    "    while True:\n",
    "        # Fit the OLS model\n",
    "        model = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Get the p-values for each feature\n",
    "        p_values = model.pvalues\n",
    "        \n",
    "        # Find the feature with the highest p-value\n",
    "        max_p_value = p_values.max()\n",
    "        \n",
    "        if max_p_value > significance_level:\n",
    "            # Remove the feature with the highest p-value\n",
    "            feature_to_remove = p_values.idxmax()\n",
    "            print(f\"Removing {feature_to_remove} with p-value {max_p_value:.4f}\")\n",
    "            X = X.drop(columns=[feature_to_remove])\n",
    "            X_val = X_val.drop(columns=[feature_to_remove])\n",
    "            X_control = X_control.drop(columns=[feature_to_remove])\n",
    "        else:\n",
    "            break\n",
    "        print(\"Final Feature lengthe: \", len(X.columns))\n",
    "    # Return the final selected feature set (excluding the intercept)\n",
    "    return X.drop(columns=['const']).to_numpy(), X_val.to_numpy(), X_control.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Deconfounding Strategy: BE ===\n",
      "\n",
      "=== Fold 1 ===\n",
      "Removing lh_rostralmiddlefrontal_thickness with p-value 0.9739\n",
      "Final Feature lengthe:  192\n",
      "Removing rh_lateralorbitofrontal_thickness with p-value 0.8616\n",
      "Final Feature lengthe:  191\n",
      "Removing CC_Central with p-value 0.7767\n",
      "Final Feature lengthe:  190\n",
      "Removing lh_parstriangularis_volume with p-value 0.7600\n",
      "Final Feature lengthe:  189\n",
      "Removing lh_postcentral_thickness with p-value 0.7549\n",
      "Final Feature lengthe:  188\n",
      "Removing rh_supramarginal_thickness with p-value 0.7099\n",
      "Final Feature lengthe:  187\n",
      "Removing lh_superiorfrontal_volume with p-value 0.7056\n",
      "Final Feature lengthe:  186\n",
      "Removing rh_entorhinal_thickness with p-value 0.6858\n",
      "Final Feature lengthe:  185\n",
      "Removing lh_pericalcarine_thickness with p-value 0.6758\n",
      "Final Feature lengthe:  184\n",
      "Removing rhCerebralWhiteMatterVol with p-value 0.6387\n",
      "Final Feature lengthe:  183\n",
      "Removing CortexVol with p-value 0.6386\n",
      "Final Feature lengthe:  182\n",
      "Removing rh_bankssts_thickness with p-value 0.6085\n",
      "Final Feature lengthe:  181\n",
      "Removing lh_parahippocampal_thickness with p-value 0.6054\n",
      "Final Feature lengthe:  180\n",
      "Removing rh_caudalanteriorcingulate_thickness with p-value 0.5871\n",
      "Final Feature lengthe:  179\n",
      "Removing rh_insula_thickness with p-value 0.5041\n",
      "Final Feature lengthe:  178\n",
      "Removing rh_medialorbitofrontal_thickness with p-value 0.4826\n",
      "Final Feature lengthe:  177\n",
      "Removing lhCerebralWhiteMatterVol with p-value 0.4391\n",
      "Final Feature lengthe:  176\n",
      "Removing rh_inferiortemporal_thickness with p-value 0.4251\n",
      "Final Feature lengthe:  175\n",
      "Removing 5th-Ventricle with p-value 0.3446\n",
      "Final Feature lengthe:  174\n",
      "Removing lh_parsorbitalis_thickness with p-value 0.3184\n",
      "Final Feature lengthe:  173\n",
      "Removing lh_fusiform_volume with p-value 0.3094\n",
      "Final Feature lengthe:  172\n",
      "Removing lh_lateraloccipital_volume with p-value 0.4074\n",
      "Final Feature lengthe:  171\n",
      "Removing Right-non-WM-hypointensities with p-value 0.5048\n",
      "Final Feature lengthe:  170\n",
      "Removing lh_precuneus_volume with p-value 0.4213\n",
      "Final Feature lengthe:  169\n",
      "Removing lh_medialorbitofrontal_thickness with p-value 0.3042\n",
      "Final Feature lengthe:  168\n",
      "Removing Left-vessel with p-value 0.3061\n",
      "Final Feature lengthe:  167\n",
      "Removing lh_paracentral_volume with p-value 0.2963\n",
      "Final Feature lengthe:  166\n",
      "Removing lh_middletemporal_volume with p-value 0.2835\n",
      "Final Feature lengthe:  165\n",
      "Removing lh_caudalmiddlefrontal_volume with p-value 0.3283\n",
      "Final Feature lengthe:  164\n",
      "Removing rh_transversetemporal_volume with p-value 0.2497\n",
      "Final Feature lengthe:  163\n",
      "Removing rh_transversetemporal_thickness with p-value 0.3845\n",
      "Final Feature lengthe:  162\n",
      "Removing rh_precuneus_thickness with p-value 0.2597\n",
      "Final Feature lengthe:  161\n",
      "Removing lh_precuneus_thickness with p-value 0.3591\n",
      "Final Feature lengthe:  160\n",
      "Removing Right-Cerebellum-Cortex with p-value 0.2396\n",
      "Final Feature lengthe:  159\n",
      "Removing lh_posteriorcingulate_volume with p-value 0.2405\n",
      "Final Feature lengthe:  158\n",
      "Removing rh_postcentral_thickness with p-value 0.2489\n",
      "Final Feature lengthe:  157\n",
      "Removing rh_parsorbitalis_thickness with p-value 0.2265\n",
      "Final Feature lengthe:  156\n",
      "Removing rh_pericalcarine_thickness with p-value 0.2130\n",
      "Final Feature lengthe:  155\n",
      "Removing Right-Amygdala with p-value 0.1941\n",
      "Final Feature lengthe:  154\n",
      "Removing non-WM-hypointensities with p-value 0.1593\n",
      "Final Feature lengthe:  153\n",
      "Removing lh_bankssts_thickness with p-value 0.1423\n",
      "Final Feature lengthe:  152\n",
      "Removing lh_caudalanteriorcingulate_volume with p-value 0.1434\n",
      "Final Feature lengthe:  151\n",
      "Removing lh_rostralanteriorcingulate_volume with p-value 0.2613\n",
      "Final Feature lengthe:  150\n",
      "Removing lh_temporalpole_volume with p-value 0.1143\n",
      "Final Feature lengthe:  149\n",
      "Removing rh_rostralanteriorcingulate_thickness with p-value 0.1058\n",
      "Final Feature lengthe:  148\n",
      "Removing lh_insula_thickness with p-value 0.1184\n",
      "Final Feature lengthe:  147\n",
      "Removing rh_inferiorparietal_thickness with p-value 0.0870\n",
      "Final Feature lengthe:  146\n",
      "Removing lh_pericalcarine_volume with p-value 0.0953\n",
      "Final Feature lengthe:  145\n",
      "Removing lh_posteriorcingulate_thickness with p-value 0.0737\n",
      "Final Feature lengthe:  144\n",
      "Random Baseline Performance:\n",
      "MSE: 296.4941\n",
      "MAE: 13.8040\n",
      "R²:  -1.0401\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 58.1019\n",
      "MAE: 6.1329\n",
      "R²:  0.6002\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 50.9806\n",
      "MAE: 5.7150\n",
      "R²:  0.6622\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005356 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35700\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 140\n",
      "[LightGBM] [Info] Start training from score 48.813250\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 42.8277\n",
      "MAE: 5.2197\n",
      "R²:  0.7053\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.9204\n",
      "MAE: 2.7615\n",
      "R²:  0.8746\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  296.4941 ± 0.0000\n",
      "Mean MAE:  13.8040 ± 0.0000\n",
      "Mean R²:   -1.0401 ± 0.0000\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  42.8277 ± 0.0000\n",
      "Mean MAE:  5.2197 ± 0.0000\n",
      "Mean R²:   0.7053 ± 0.0000\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  58.1019 ± 0.0000\n",
      "Mean MAE:  6.1329 ± 0.0000\n",
      "Mean R²:   0.6002 ± 0.0000\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  18.9204 ± 0.0000\n",
      "Mean MAE:  2.7615 ± 0.0000\n",
      "Mean R²:   0.8746 ± 0.0000\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  50.9806 ± 0.0000\n",
      "Mean MAE:  5.7150 ± 0.0000\n",
      "Mean R²:   0.6622 ± 0.0000\n",
      "\n",
      "=== Fold 2 ===\n",
      "Removing Right-Amygdala with p-value 0.9651\n",
      "Final Feature lengthe:  192\n",
      "Removing rh_parsorbitalis_thickness with p-value 0.9598\n",
      "Final Feature lengthe:  191\n",
      "Removing lh_postcentral_thickness with p-value 0.9211\n",
      "Final Feature lengthe:  190\n",
      "Removing lhCerebralWhiteMatterVol with p-value 0.9141\n",
      "Final Feature lengthe:  189\n",
      "Removing rhCortexVol with p-value 0.9141\n",
      "Final Feature lengthe:  188\n",
      "Removing rh_entorhinal_thickness with p-value 0.8910\n",
      "Final Feature lengthe:  187\n",
      "Removing CC_Central with p-value 0.8756\n",
      "Final Feature lengthe:  186\n",
      "Removing lh_caudalanteriorcingulate_volume with p-value 0.8626\n",
      "Final Feature lengthe:  185\n",
      "Removing rh_supramarginal_thickness with p-value 0.8507\n",
      "Final Feature lengthe:  184\n",
      "Removing lh_precuneus_thickness with p-value 0.8390\n",
      "Final Feature lengthe:  183\n",
      "Removing rh_caudalanteriorcingulate_thickness with p-value 0.7901\n",
      "Final Feature lengthe:  182\n",
      "Removing rh_inferiortemporal_thickness with p-value 0.7688\n",
      "Final Feature lengthe:  181\n",
      "Removing rh_rostralanteriorcingulate_thickness with p-value 0.7660\n",
      "Final Feature lengthe:  180\n",
      "Removing rh_postcentral_thickness with p-value 0.7568\n",
      "Final Feature lengthe:  179\n",
      "Removing rh_lateralorbitofrontal_thickness with p-value 0.7169\n",
      "Final Feature lengthe:  178\n",
      "Removing lh_insula_thickness with p-value 0.7135\n",
      "Final Feature lengthe:  177\n",
      "Removing rh_precuneus_thickness with p-value 0.7005\n",
      "Final Feature lengthe:  176\n",
      "Removing rh_bankssts_thickness with p-value 0.6458\n",
      "Final Feature lengthe:  175\n",
      "Removing lh_parahippocampal_thickness with p-value 0.6058\n",
      "Final Feature lengthe:  174\n",
      "Removing rh_inferiorparietal_thickness with p-value 0.5625\n",
      "Final Feature lengthe:  173\n",
      "Removing lh_parahippocampal_volume with p-value 0.5385\n",
      "Final Feature lengthe:  172\n",
      "Removing lh_lateralorbitofrontal_volume with p-value 0.5917\n",
      "Final Feature lengthe:  171\n",
      "Removing rhCerebralWhiteMatterVol with p-value 0.5229\n",
      "Final Feature lengthe:  170\n",
      "Removing lh_medialorbitofrontal_thickness with p-value 0.5071\n",
      "Final Feature lengthe:  169\n",
      "Removing rh_transversetemporal_thickness with p-value 0.4389\n",
      "Final Feature lengthe:  168\n",
      "Removing rh_lingual_thickness with p-value 0.3600\n",
      "Final Feature lengthe:  167\n",
      "Removing rh_middletemporal_thickness with p-value 0.3391\n",
      "Final Feature lengthe:  166\n",
      "Removing lh_bankssts_thickness with p-value 0.3236\n",
      "Final Feature lengthe:  165\n",
      "Removing lh_parsorbitalis_volume with p-value 0.3144\n",
      "Final Feature lengthe:  164\n",
      "Removing lh_rostralmiddlefrontal_thickness with p-value 0.2975\n",
      "Final Feature lengthe:  163\n",
      "Removing Right-Cerebellum-Cortex with p-value 0.2862\n",
      "Final Feature lengthe:  162\n",
      "Removing 5th-Ventricle with p-value 0.2340\n",
      "Final Feature lengthe:  161\n",
      "Removing lh_pericalcarine_thickness with p-value 0.2298\n",
      "Final Feature lengthe:  160\n",
      "Removing Left-vessel with p-value 0.2124\n",
      "Final Feature lengthe:  159\n",
      "Removing non-WM-hypointensities with p-value 0.2360\n",
      "Final Feature lengthe:  158\n",
      "Removing CerebralWhiteMatterVol with p-value 0.2215\n",
      "Final Feature lengthe:  157\n",
      "Removing rh_transversetemporal_volume with p-value 0.2005\n",
      "Final Feature lengthe:  156\n",
      "Removing rh_medialorbitofrontal_thickness with p-value 0.1698\n",
      "Final Feature lengthe:  155\n",
      "Removing Right-WM-hypointensities with p-value 0.5810\n",
      "Final Feature lengthe:  154\n",
      "Removing rh_parsorbitalis_volume with p-value 0.1594\n",
      "Final Feature lengthe:  153\n",
      "Removing rh_frontalpole_volume with p-value 0.0965\n",
      "Final Feature lengthe:  152\n",
      "Removing lh_posteriorcingulate_thickness with p-value 0.0839\n",
      "Final Feature lengthe:  151\n",
      "Removing rh_cuneus_thickness with p-value 0.0513\n",
      "Final Feature lengthe:  150\n",
      "Removing rh_cuneus_volume with p-value 0.0860\n",
      "Final Feature lengthe:  149\n",
      "Removing lhCortexVol with p-value 0.2560\n",
      "Final Feature lengthe:  148\n",
      "Removing rh_parsopercularis_volume with p-value 0.1269\n",
      "Final Feature lengthe:  147\n",
      "Removing rh_medialorbitofrontal_volume with p-value 0.1133\n",
      "Final Feature lengthe:  146\n",
      "Removing rh_rostralanteriorcingulate_volume with p-value 0.1527\n",
      "Final Feature lengthe:  145\n",
      "Random Baseline Performance:\n",
      "MSE: 293.4790\n",
      "MAE: 13.7948\n",
      "R²:  -0.9941\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 59.3601\n",
      "MAE: 5.9610\n",
      "R²:  0.5967\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 47.1445\n",
      "MAE: 5.3713\n",
      "R²:  0.6876\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016379 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 35955\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 141\n",
      "[LightGBM] [Info] Start training from score 48.838500\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 45.5891\n",
      "MAE: 5.3467\n",
      "R²:  0.6902\n",
      "LightGBM Performance on Control:\n",
      "MSE: 19.4122\n",
      "MAE: 2.7925\n",
      "R²:  0.8714\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  294.9865 ± 1.5075\n",
      "Mean MAE:  13.7994 ± 0.0046\n",
      "Mean R²:   -1.0171 ± 0.0230\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  44.2084 ± 1.3807\n",
      "Mean MAE:  5.2832 ± 0.0635\n",
      "Mean R²:   0.6978 ± 0.0075\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  58.7310 ± 0.6291\n",
      "Mean MAE:  6.0469 ± 0.0860\n",
      "Mean R²:   0.5984 ± 0.0018\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  19.1663 ± 0.2459\n",
      "Mean MAE:  2.7770 ± 0.0155\n",
      "Mean R²:   0.8730 ± 0.0016\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  49.0626 ± 1.9180\n",
      "Mean MAE:  5.5431 ± 0.1718\n",
      "Mean R²:   0.6749 ± 0.0127\n",
      "\n",
      "=== Fold 3 ===\n",
      "Removing rh_pericalcarine_thickness with p-value 0.9442\n",
      "Final Feature lengthe:  192\n",
      "Removing rh_parsorbitalis_thickness with p-value 0.9400\n",
      "Final Feature lengthe:  191\n",
      "Removing rh_supramarginal_thickness with p-value 0.9343\n",
      "Final Feature lengthe:  190\n",
      "Removing lh_parahippocampal_volume with p-value 0.9232\n",
      "Final Feature lengthe:  189\n",
      "Removing lh_postcentral_thickness with p-value 0.9077\n",
      "Final Feature lengthe:  188\n",
      "Removing lh_parahippocampal_thickness with p-value 0.8951\n",
      "Final Feature lengthe:  187\n",
      "Removing rh_medialorbitofrontal_thickness with p-value 0.8901\n",
      "Final Feature lengthe:  186\n",
      "Removing lh_lateralorbitofrontal_volume with p-value 0.8702\n",
      "Final Feature lengthe:  185\n",
      "Removing lh_caudalanteriorcingulate_volume with p-value 0.8919\n",
      "Final Feature lengthe:  184\n",
      "Removing rh_entorhinal_thickness with p-value 0.8473\n",
      "Final Feature lengthe:  183\n",
      "Removing lh_parsorbitalis_thickness with p-value 0.8028\n",
      "Final Feature lengthe:  182\n",
      "Removing lh_insula_thickness with p-value 0.7722\n",
      "Final Feature lengthe:  181\n",
      "Removing rh_precuneus_thickness with p-value 0.6297\n",
      "Final Feature lengthe:  180\n",
      "Removing rh_caudalanteriorcingulate_thickness with p-value 0.5942\n",
      "Final Feature lengthe:  179\n",
      "Removing lh_rostralmiddlefrontal_thickness with p-value 0.5888\n",
      "Final Feature lengthe:  178\n",
      "Removing lhCerebralWhiteMatterVol with p-value 0.4643\n",
      "Final Feature lengthe:  177\n",
      "Removing rhCerebralWhiteMatterVol with p-value 0.9917\n",
      "Final Feature lengthe:  176\n",
      "Removing rhCortexVol with p-value 0.4643\n",
      "Final Feature lengthe:  175\n",
      "Removing Right-Amygdala with p-value 0.4654\n",
      "Final Feature lengthe:  174\n",
      "Removing rh_lateralorbitofrontal_thickness with p-value 0.4292\n",
      "Final Feature lengthe:  173\n",
      "Removing non-WM-hypointensities with p-value 0.3822\n",
      "Final Feature lengthe:  172\n",
      "Removing rh_rostralanteriorcingulate_thickness with p-value 0.3697\n",
      "Final Feature lengthe:  171\n",
      "Removing rh_postcentral_thickness with p-value 0.3580\n",
      "Final Feature lengthe:  170\n",
      "Removing rh_lingual_thickness with p-value 0.3448\n",
      "Final Feature lengthe:  169\n",
      "Removing Left-non-WM-hypointensities with p-value 0.6327\n",
      "Final Feature lengthe:  168\n",
      "Removing CC_Central with p-value 0.2957\n",
      "Final Feature lengthe:  167\n",
      "Removing lh_posteriorcingulate_thickness with p-value 0.3067\n",
      "Final Feature lengthe:  166\n",
      "Removing rh_inferiortemporal_thickness with p-value 0.2290\n",
      "Final Feature lengthe:  165\n",
      "Removing lh_precuneus_thickness with p-value 0.2261\n",
      "Final Feature lengthe:  164\n",
      "Removing 5th-Ventricle with p-value 0.2082\n",
      "Final Feature lengthe:  163\n",
      "Removing rh_bankssts_thickness with p-value 0.2082\n",
      "Final Feature lengthe:  162\n",
      "Removing lh_parstriangularis_volume with p-value 0.1855\n",
      "Final Feature lengthe:  161\n",
      "Removing rh_inferiorparietal_thickness with p-value 0.1836\n",
      "Final Feature lengthe:  160\n",
      "Removing rh_transversetemporal_volume with p-value 0.1425\n",
      "Final Feature lengthe:  159\n",
      "Removing rh_transversetemporal_thickness with p-value 0.2734\n",
      "Final Feature lengthe:  158\n",
      "Removing lh_cuneus_thickness with p-value 0.1331\n",
      "Final Feature lengthe:  157\n",
      "Removing lh_cuneus_volume with p-value 0.2423\n",
      "Final Feature lengthe:  156\n",
      "Removing Right-Cerebellum-Cortex with p-value 0.1040\n",
      "Final Feature lengthe:  155\n",
      "Removing lh_medialorbitofrontal_thickness with p-value 0.0868\n",
      "Final Feature lengthe:  154\n",
      "Removing rh_frontalpole_volume with p-value 0.0676\n",
      "Final Feature lengthe:  153\n",
      "Removing rh_parsorbitalis_volume with p-value 0.1793\n",
      "Final Feature lengthe:  152\n",
      "Removing lh_bankssts_thickness with p-value 0.0563\n",
      "Final Feature lengthe:  151\n",
      "Random Baseline Performance:\n",
      "MSE: 306.6509\n",
      "MAE: 14.1016\n",
      "R²:  -0.9458\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 62.9765\n",
      "MAE: 6.1206\n",
      "R²:  0.6004\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 46.7817\n",
      "MAE: 5.3748\n",
      "R²:  0.6900\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 37485\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 147\n",
      "[LightGBM] [Info] Start training from score 49.012125\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 44.5530\n",
      "MAE: 5.2180\n",
      "R²:  0.7173\n",
      "LightGBM Performance on Control:\n",
      "MSE: 19.1986\n",
      "MAE: 2.7900\n",
      "R²:  0.8728\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  298.8747 ± 5.6347\n",
      "Mean MAE:  13.9002 ± 0.1425\n",
      "Mean R²:   -0.9933 ± 0.0385\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  44.3233 ± 1.1390\n",
      "Mean MAE:  5.2615 ± 0.0603\n",
      "Mean R²:   0.7043 ± 0.0111\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  60.1462 ± 2.0662\n",
      "Mean MAE:  6.0715 ± 0.0783\n",
      "Mean R²:   0.5991 ± 0.0017\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  19.1771 ± 0.2014\n",
      "Mean MAE:  2.7813 ± 0.0141\n",
      "Mean R²:   0.8729 ± 0.0013\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  48.3023 ± 1.8996\n",
      "Mean MAE:  5.4870 ± 0.1612\n",
      "Mean R²:   0.6799 ± 0.0126\n",
      "\n",
      "=== Fold 4 ===\n",
      "Removing 5th-Ventricle with p-value 0.9658\n",
      "Final Feature lengthe:  192\n",
      "Removing Right-Cerebellum-Cortex with p-value 0.9488\n",
      "Final Feature lengthe:  191\n",
      "Removing lh_precuneus_thickness with p-value 0.9066\n",
      "Final Feature lengthe:  190\n",
      "Removing rh_precuneus_thickness with p-value 0.9172\n",
      "Final Feature lengthe:  189\n",
      "Removing rh_postcentral_thickness with p-value 0.9009\n",
      "Final Feature lengthe:  188\n",
      "Removing CC_Central with p-value 0.8683\n",
      "Final Feature lengthe:  187\n",
      "Removing lh_superiorfrontal_volume with p-value 0.8187\n",
      "Final Feature lengthe:  186\n",
      "Removing lh_parstriangularis_volume with p-value 0.8084\n",
      "Final Feature lengthe:  185\n",
      "Removing lh_posteriorcingulate_thickness with p-value 0.8019\n",
      "Final Feature lengthe:  184\n",
      "Removing rh_entorhinal_thickness with p-value 0.7248\n",
      "Final Feature lengthe:  183\n",
      "Removing lh_postcentral_thickness with p-value 0.7105\n",
      "Final Feature lengthe:  182\n",
      "Removing rh_caudalanteriorcingulate_thickness with p-value 0.6982\n",
      "Final Feature lengthe:  181\n",
      "Removing lh_insula_thickness with p-value 0.6443\n",
      "Final Feature lengthe:  180\n",
      "Removing lh_parsorbitalis_thickness with p-value 0.6291\n",
      "Final Feature lengthe:  179\n",
      "Removing rh_medialorbitofrontal_thickness with p-value 0.6262\n",
      "Final Feature lengthe:  178\n",
      "Removing lh_middletemporal_volume with p-value 0.5746\n",
      "Final Feature lengthe:  177\n",
      "Removing lh_caudalmiddlefrontal_volume with p-value 0.6401\n",
      "Final Feature lengthe:  176\n",
      "Removing lh_cuneus_volume with p-value 0.5998\n",
      "Final Feature lengthe:  175\n",
      "Removing lh_paracentral_volume with p-value 0.5827\n",
      "Final Feature lengthe:  174\n",
      "Removing lh_lateraloccipital_volume with p-value 0.5940\n",
      "Final Feature lengthe:  173\n",
      "Removing lh_precuneus_volume with p-value 0.6065\n",
      "Final Feature lengthe:  172\n",
      "Removing lh_posteriorcingulate_volume with p-value 0.5839\n",
      "Final Feature lengthe:  171\n",
      "Removing lh_cuneus_thickness with p-value 0.4993\n",
      "Final Feature lengthe:  170\n",
      "Removing Right-Amygdala with p-value 0.4901\n",
      "Final Feature lengthe:  169\n",
      "Removing lh_parahippocampal_thickness with p-value 0.4678\n",
      "Final Feature lengthe:  168\n",
      "Removing rh_bankssts_thickness with p-value 0.3991\n",
      "Final Feature lengthe:  167\n",
      "Removing CerebralWhiteMatterVol with p-value 0.3437\n",
      "Final Feature lengthe:  166\n",
      "Removing rhCerebralWhiteMatterVol with p-value 0.7145\n",
      "Final Feature lengthe:  165\n",
      "Removing rhCortexVol with p-value 0.3451\n",
      "Final Feature lengthe:  164\n",
      "Removing rh_supramarginal_thickness with p-value 0.3334\n",
      "Final Feature lengthe:  163\n",
      "Removing lh_fusiform_volume with p-value 0.3375\n",
      "Final Feature lengthe:  162\n",
      "Removing rh_inferiortemporal_thickness with p-value 0.3389\n",
      "Final Feature lengthe:  161\n",
      "Removing lh_rostralmiddlefrontal_thickness with p-value 0.3302\n",
      "Final Feature lengthe:  160\n",
      "Removing rh_lateralorbitofrontal_thickness with p-value 0.2892\n",
      "Final Feature lengthe:  159\n",
      "Removing rh_parsorbitalis_thickness with p-value 0.3746\n",
      "Final Feature lengthe:  158\n",
      "Removing lh_medialorbitofrontal_thickness with p-value 0.3004\n",
      "Final Feature lengthe:  157\n",
      "Removing lh_bankssts_volume with p-value 0.2838\n",
      "Final Feature lengthe:  156\n",
      "Removing lh_pericalcarine_thickness with p-value 0.2822\n",
      "Final Feature lengthe:  155\n",
      "Removing rh_transversetemporal_thickness with p-value 0.2019\n",
      "Final Feature lengthe:  154\n",
      "Removing rh_rostralanteriorcingulate_thickness with p-value 0.2036\n",
      "Final Feature lengthe:  153\n",
      "Removing Left-vessel with p-value 0.1929\n",
      "Final Feature lengthe:  152\n",
      "Removing rh_transversetemporal_volume with p-value 0.1704\n",
      "Final Feature lengthe:  151\n",
      "Removing lh_caudalanteriorcingulate_volume with p-value 0.1642\n",
      "Final Feature lengthe:  150\n",
      "Removing lh_rostralanteriorcingulate_volume with p-value 0.2542\n",
      "Final Feature lengthe:  149\n",
      "Removing rh_frontalpole_volume with p-value 0.1462\n",
      "Final Feature lengthe:  148\n",
      "Removing lh_pericalcarine_volume with p-value 0.0871\n",
      "Final Feature lengthe:  147\n",
      "Removing rh_inferiorparietal_thickness with p-value 0.0734\n",
      "Final Feature lengthe:  146\n",
      "Removing rh_parsorbitalis_volume with p-value 0.0747\n",
      "Final Feature lengthe:  145\n",
      "Removing rh_cuneus_thickness with p-value 0.0590\n",
      "Final Feature lengthe:  144\n",
      "Removing non-WM-hypointensities with p-value 0.0584\n",
      "Final Feature lengthe:  143\n",
      "Removing lh_temporalpole_volume with p-value 0.0544\n",
      "Final Feature lengthe:  142\n",
      "Removing lh_superiorparietal_volume with p-value 0.0549\n",
      "Final Feature lengthe:  141\n",
      "Removing lh_precentral_thickness with p-value 0.0559\n",
      "Final Feature lengthe:  140\n",
      "Removing lh_supramarginal_volume with p-value 0.0530\n",
      "Final Feature lengthe:  139\n",
      "Random Baseline Performance:\n",
      "MSE: 322.4236\n",
      "MAE: 14.3482\n",
      "R²:  -1.0344\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 73.8112\n",
      "MAE: 6.9751\n",
      "R²:  0.5343\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 67.4450\n",
      "MAE: 6.6947\n",
      "R²:  0.5531\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013205 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 34170\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 134\n",
      "[LightGBM] [Info] Start training from score 48.960625\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 43.2977\n",
      "MAE: 5.1901\n",
      "R²:  0.7268\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.8231\n",
      "MAE: 2.7436\n",
      "R²:  0.8753\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  304.7619 ± 11.3045\n",
      "Mean MAE:  14.0122 ± 0.2299\n",
      "Mean R²:   -1.0036 ± 0.0378\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  44.0669 ± 1.0817\n",
      "Mean MAE:  5.2436 ± 0.0606\n",
      "Mean R²:   0.7099 ± 0.0137\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  63.5624 ± 6.1818\n",
      "Mean MAE:  6.2974 ± 0.3971\n",
      "Mean R²:   0.5829 ± 0.0281\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  19.0886 ± 0.2322\n",
      "Mean MAE:  2.7719 ± 0.0204\n",
      "Mean R²:   0.8735 ± 0.0015\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  53.0879 ± 8.4507\n",
      "Mean MAE:  5.7889 ± 0.5412\n",
      "Mean R²:   0.6482 ± 0.0560\n",
      "\n",
      "=== Fold 5 ===\n",
      "Removing lh_lateralorbitofrontal_volume with p-value 0.9684\n",
      "Final Feature lengthe:  192\n",
      "Removing rh_caudalanteriorcingulate_thickness with p-value 0.9585\n",
      "Final Feature lengthe:  191\n",
      "Removing CC_Central with p-value 0.8279\n",
      "Final Feature lengthe:  190\n",
      "Removing lh_insula_thickness with p-value 0.8140\n",
      "Final Feature lengthe:  189\n",
      "Removing rh_lateralorbitofrontal_thickness with p-value 0.7972\n",
      "Final Feature lengthe:  188\n",
      "Removing lh_parahippocampal_volume with p-value 0.7774\n",
      "Final Feature lengthe:  187\n",
      "Removing rh_medialorbitofrontal_thickness with p-value 0.7614\n",
      "Final Feature lengthe:  186\n",
      "Removing lhCerebralWhiteMatterVol with p-value 0.7612\n",
      "Final Feature lengthe:  185\n",
      "Removing rhCerebralWhiteMatterVol with p-value 0.9195\n",
      "Final Feature lengthe:  184\n",
      "Removing rhCortexVol with p-value 0.7613\n",
      "Final Feature lengthe:  183\n",
      "Removing lh_rostralmiddlefrontal_thickness with p-value 0.7456\n",
      "Final Feature lengthe:  182\n",
      "Removing lh_parsorbitalis_thickness with p-value 0.7256\n",
      "Final Feature lengthe:  181\n",
      "Removing lh_pericalcarine_thickness with p-value 0.7074\n",
      "Final Feature lengthe:  180\n",
      "Removing lh_posteriorcingulate_thickness with p-value 0.7027\n",
      "Final Feature lengthe:  179\n",
      "Removing rh_supramarginal_thickness with p-value 0.6356\n",
      "Final Feature lengthe:  178\n",
      "Removing lh_medialorbitofrontal_thickness with p-value 0.6156\n",
      "Final Feature lengthe:  177\n",
      "Removing lh_caudalanteriorcingulate_volume with p-value 0.5452\n",
      "Final Feature lengthe:  176\n",
      "Removing lh_parahippocampal_thickness with p-value 0.5913\n",
      "Final Feature lengthe:  175\n",
      "Removing rh_entorhinal_thickness with p-value 0.5249\n",
      "Final Feature lengthe:  174\n",
      "Removing lh_precuneus_thickness with p-value 0.4418\n",
      "Final Feature lengthe:  173\n",
      "Removing rh_transversetemporal_volume with p-value 0.4063\n",
      "Final Feature lengthe:  172\n",
      "Removing rh_cuneus_thickness with p-value 0.3918\n",
      "Final Feature lengthe:  171\n",
      "Removing rh_rostralanteriorcingulate_thickness with p-value 0.3854\n",
      "Final Feature lengthe:  170\n",
      "Removing Left-vessel with p-value 0.3954\n",
      "Final Feature lengthe:  169\n",
      "Removing non-WM-hypointensities with p-value 0.3969\n",
      "Final Feature lengthe:  168\n",
      "Removing lh_postcentral_thickness with p-value 0.3799\n",
      "Final Feature lengthe:  167\n",
      "Removing rh_postcentral_thickness with p-value 0.4717\n",
      "Final Feature lengthe:  166\n",
      "Removing rh_parsorbitalis_thickness with p-value 0.3548\n",
      "Final Feature lengthe:  165\n",
      "Removing Right-Amygdala with p-value 0.3447\n",
      "Final Feature lengthe:  164\n",
      "Removing rh_transversetemporal_thickness with p-value 0.3437\n",
      "Final Feature lengthe:  163\n",
      "Removing rh_bankssts_thickness with p-value 0.3262\n",
      "Final Feature lengthe:  162\n",
      "Removing Right-Cerebellum-Cortex with p-value 0.2823\n",
      "Final Feature lengthe:  161\n",
      "Removing rh_inferiortemporal_thickness with p-value 0.2794\n",
      "Final Feature lengthe:  160\n",
      "Removing rh_precuneus_thickness with p-value 0.2828\n",
      "Final Feature lengthe:  159\n",
      "Removing rh_middletemporal_thickness with p-value 0.1365\n",
      "Final Feature lengthe:  158\n",
      "Removing rh_lingual_thickness with p-value 0.0994\n",
      "Final Feature lengthe:  157\n",
      "Removing rh_insula_thickness with p-value 0.0928\n",
      "Final Feature lengthe:  156\n",
      "Removing 5th-Ventricle with p-value 0.0870\n",
      "Final Feature lengthe:  155\n",
      "Removing rh_frontalpole_volume with p-value 0.0759\n",
      "Final Feature lengthe:  154\n",
      "Removing rh_parsorbitalis_volume with p-value 0.2126\n",
      "Final Feature lengthe:  153\n",
      "Removing rh_cuneus_volume with p-value 0.1086\n",
      "Final Feature lengthe:  152\n",
      "Removing lhCortexVol with p-value 0.1948\n",
      "Final Feature lengthe:  151\n",
      "Removing rh_medialorbitofrontal_volume with p-value 0.1373\n",
      "Final Feature lengthe:  150\n",
      "Removing Right-WM-hypointensities with p-value 0.4363\n",
      "Final Feature lengthe:  149\n",
      "Removing rh_rostralanteriorcingulate_volume with p-value 0.1283\n",
      "Final Feature lengthe:  148\n",
      "Removing rh_parsopercularis_volume with p-value 0.1338\n",
      "Final Feature lengthe:  147\n",
      "Random Baseline Performance:\n",
      "MSE: 302.5923\n",
      "MAE: 13.9615\n",
      "R²:  -1.0723\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 64.2163\n",
      "MAE: 6.3495\n",
      "R²:  0.5602\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 59.1426\n",
      "MAE: 6.0824\n",
      "R²:  0.6081\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004856 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 36465\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 48.778000\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 41.9825\n",
      "MAE: 5.0866\n",
      "R²:  0.7125\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.6899\n",
      "MAE: 2.7603\n",
      "R²:  0.8761\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  304.3280 ± 10.1482\n",
      "Mean MAE:  14.0020 ± 0.2067\n",
      "Mean R²:   -1.0173 ± 0.0435\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  43.6500 ± 1.2772\n",
      "Mean MAE:  5.2122 ± 0.0830\n",
      "Mean R²:   0.7104 ± 0.0123\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  63.6932 ± 5.5353\n",
      "Mean MAE:  6.3078 ± 0.3558\n",
      "Mean R²:   0.5784 ± 0.0267\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  19.0088 ± 0.2618\n",
      "Mean MAE:  2.7696 ± 0.0188\n",
      "Mean R²:   0.8740 ± 0.0017\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  54.2989 ± 7.9371\n",
      "Mean MAE:  5.8476 ± 0.4981\n",
      "Mean R²:   0.6402 ± 0.0526\n",
      "\n",
      "=== Deconfounding Strategy: Correlation ===\n",
      "\n",
      "=== Fold 1 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 297.6961\n",
      "MAE: 13.9773\n",
      "R²:  -1.0484\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 64.8084\n",
      "MAE: 6.3158\n",
      "R²:  0.5541\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 55.5982\n",
      "MAE: 5.8762\n",
      "R²:  0.6316\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17652\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 48.813250\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 52.8949\n",
      "MAE: 5.7700\n",
      "R²:  0.6360\n",
      "LightGBM Performance on Control:\n",
      "MSE: 24.2009\n",
      "MAE: 3.2364\n",
      "R²:  0.8396\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  303.2227 ± 9.5880\n",
      "Mean MAE:  13.9979 ± 0.1889\n",
      "Mean R²:   -1.0225 ± 0.0414\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  45.1908 ± 3.6373\n",
      "Mean MAE:  5.3052 ± 0.2212\n",
      "Mean R²:   0.6980 ± 0.0299\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  63.8791 ± 5.0701\n",
      "Mean MAE:  6.3091 ± 0.3248\n",
      "Mean R²:   0.5743 ± 0.0260\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  19.8742 ± 1.9497\n",
      "Mean MAE:  2.8474 ± 0.1748\n",
      "Mean R²:   0.8683 ± 0.0129\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  54.5154 ± 7.2617\n",
      "Mean MAE:  5.8524 ± 0.4549\n",
      "Mean R²:   0.6387 ± 0.0481\n",
      "\n",
      "=== Fold 2 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 307.2927\n",
      "MAE: 14.1437\n",
      "R²:  -1.0880\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 77.9698\n",
      "MAE: 6.9857\n",
      "R²:  0.4702\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 65.2038\n",
      "MAE: 6.4048\n",
      "R²:  0.5679\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17903\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 72\n",
      "[LightGBM] [Info] Start training from score 48.838500\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 54.0940\n",
      "MAE: 5.8483\n",
      "R²:  0.6324\n",
      "LightGBM Performance on Control:\n",
      "MSE: 24.2302\n",
      "MAE: 3.2195\n",
      "R²:  0.8394\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  303.8041 ± 8.9903\n",
      "Mean MAE:  14.0187 ± 0.1822\n",
      "Mean R²:   -1.0319 ± 0.0447\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  46.4627 ± 4.5876\n",
      "Mean MAE:  5.3828 ± 0.2794\n",
      "Mean R²:   0.6887 ± 0.0360\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  65.8920 ± 6.8078\n",
      "Mean MAE:  6.4058 ± 0.3827\n",
      "Mean R²:   0.5594 ± 0.0437\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  20.4965 ± 2.3626\n",
      "Mean MAE:  2.9005 ± 0.2077\n",
      "Mean R²:   0.8642 ± 0.0157\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  56.0423 ± 7.6934\n",
      "Mean MAE:  5.9313 ± 0.4634\n",
      "Mean R²:   0.6286 ± 0.0510\n",
      "\n",
      "=== Fold 3 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 303.5848\n",
      "MAE: 14.0933\n",
      "R²:  -0.9264\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 81.9320\n",
      "MAE: 6.9941\n",
      "R²:  0.4801\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 62.3899\n",
      "MAE: 6.1805\n",
      "R²:  0.5866\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17650\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 71\n",
      "[LightGBM] [Info] Start training from score 49.012125\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 55.6555\n",
      "MAE: 5.8210\n",
      "R²:  0.6468\n",
      "LightGBM Performance on Control:\n",
      "MSE: 25.2852\n",
      "MAE: 3.3078\n",
      "R²:  0.8324\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  303.7767 ± 8.4100\n",
      "Mean MAE:  14.0281 ± 0.1722\n",
      "Mean R²:   -1.0187 ± 0.0544\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  47.6118 ± 5.2591\n",
      "Mean MAE:  5.4376 ± 0.2989\n",
      "Mean R²:   0.6834 ± 0.0364\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  67.8970 ± 8.2881\n",
      "Mean MAE:  6.4793 ± 0.4075\n",
      "Mean R²:   0.5495 ± 0.0485\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.0951 ± 2.7188\n",
      "Mean MAE:  2.9515 ± 0.2364\n",
      "Mean R²:   0.8602 ± 0.0180\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  56.8358 ± 7.4964\n",
      "Mean MAE:  5.9624 ± 0.4412\n",
      "Mean R²:   0.6234 ± 0.0497\n",
      "\n",
      "=== Fold 4 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 314.5977\n",
      "MAE: 14.2411\n",
      "R²:  -0.9851\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 71.6776\n",
      "MAE: 6.6295\n",
      "R²:  0.5477\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 58.6081\n",
      "MAE: 6.0324\n",
      "R²:  0.6116\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003138 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17392\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 70\n",
      "[LightGBM] [Info] Start training from score 48.960625\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 56.2037\n",
      "MAE: 5.9166\n",
      "R²:  0.6454\n",
      "LightGBM Performance on Control:\n",
      "MSE: 24.8741\n",
      "MAE: 3.2744\n",
      "R²:  0.8352\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  304.9790 ± 8.6275\n",
      "Mean MAE:  14.0517 ± 0.1756\n",
      "Mean R²:   -1.0149 ± 0.0524\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  48.5665 ± 5.6459\n",
      "Mean MAE:  5.4908 ± 0.3195\n",
      "Mean R²:   0.6792 ± 0.0363\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  68.3171 ± 7.9039\n",
      "Mean MAE:  6.4960 ± 0.3871\n",
      "Mean R²:   0.5493 ± 0.0458\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.5150 ± 2.8251\n",
      "Mean MAE:  2.9873 ± 0.2449\n",
      "Mean R²:   0.8574 ± 0.0187\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  57.0327 ± 7.0896\n",
      "Mean MAE:  5.9702 ± 0.4165\n",
      "Mean R²:   0.6221 ± 0.0470\n",
      "\n",
      "=== Fold 5 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 290.8856\n",
      "MAE: 13.8013\n",
      "R²:  -0.9921\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 72.8032\n",
      "MAE: 6.7770\n",
      "R²:  0.5014\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 63.6773\n",
      "MAE: 6.3189\n",
      "R²:  0.5780\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 17139\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 69\n",
      "[LightGBM] [Info] Start training from score 48.778000\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 52.9687\n",
      "MAE: 5.7659\n",
      "R²:  0.6373\n",
      "LightGBM Performance on Control:\n",
      "MSE: 24.9637\n",
      "MAE: 3.3168\n",
      "R²:  0.8346\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  303.5697 ± 9.2123\n",
      "Mean MAE:  14.0267 ± 0.1827\n",
      "Mean R²:   -1.0127 ± 0.0502\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  49.0067 ± 5.5166\n",
      "Mean MAE:  5.5183 ± 0.3141\n",
      "Mean R²:   0.6750 ± 0.0367\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  68.7657 ± 7.6181\n",
      "Mean MAE:  6.5241 ± 0.3767\n",
      "Mean R²:   0.5445 ± 0.0457\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.8598 ± 2.8729\n",
      "Mean MAE:  3.0203 ± 0.2525\n",
      "Mean R²:   0.8551 ± 0.0190\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  57.6972 ± 7.0150\n",
      "Mean MAE:  6.0051 ± 0.4088\n",
      "Mean R²:   0.6177 ± 0.0465\n",
      "\n",
      "=== Deconfounding Strategy: PCANothing ===\n",
      "\n",
      "=== Fold 1 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 298.9749\n",
      "MAE: 13.8608\n",
      "R²:  -1.0572\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 66.0390\n",
      "MAE: 6.5792\n",
      "R²:  0.5456\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 58.3367\n",
      "MAE: 6.1636\n",
      "R²:  0.6134\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47487\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 48.813250\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 43.2892\n",
      "MAE: 5.2325\n",
      "R²:  0.7021\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.8552\n",
      "MAE: 2.7211\n",
      "R²:  0.8751\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  303.1520 ± 8.8824\n",
      "Mean MAE:  14.0116 ± 0.1806\n",
      "Mean R²:   -1.0167 ± 0.0495\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  48.4869 ± 5.5107\n",
      "Mean MAE:  5.4923 ± 0.3106\n",
      "Mean R²:   0.6775 ± 0.0358\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  68.5178 ± 7.3058\n",
      "Mean MAE:  6.5291 ± 0.3596\n",
      "Mean R²:   0.5446 ± 0.0436\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.5867 ± 2.8722\n",
      "Mean MAE:  2.9931 ± 0.2557\n",
      "Mean R²:   0.8570 ± 0.0190\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  57.7553 ± 6.6910\n",
      "Mean MAE:  6.0195 ± 0.3924\n",
      "Mean R²:   0.6173 ± 0.0443\n",
      "\n",
      "=== Fold 2 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 299.5764\n",
      "MAE: 13.9562\n",
      "R²:  -1.0355\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 59.8999\n",
      "MAE: 6.0955\n",
      "R²:  0.5930\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 47.0515\n",
      "MAE: 5.3935\n",
      "R²:  0.6882\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47483\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 48.838500\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 44.3869\n",
      "MAE: 5.2893\n",
      "R²:  0.6984\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.8847\n",
      "MAE: 2.7264\n",
      "R²:  0.8749\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  302.8540 ± 8.5614\n",
      "Mean MAE:  14.0070 ± 0.1736\n",
      "Mean R²:   -1.0183 ± 0.0477\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  48.1452 ± 5.3964\n",
      "Mean MAE:  5.4754 ± 0.3026\n",
      "Mean R²:   0.6792 ± 0.0348\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  67.7997 ± 7.3892\n",
      "Mean MAE:  6.4930 ± 0.3645\n",
      "Mean R²:   0.5487 ± 0.0438\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.3615 ± 2.8495\n",
      "Mean MAE:  2.9709 ± 0.2556\n",
      "Mean R²:   0.8584 ± 0.0189\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  56.8633 ± 7.0563\n",
      "Mean MAE:  5.9673 ± 0.4136\n",
      "Mean R²:   0.6232 ± 0.0468\n",
      "\n",
      "=== Fold 3 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 301.9457\n",
      "MAE: 14.0236\n",
      "R²:  -0.9160\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 79.8747\n",
      "MAE: 7.0558\n",
      "R²:  0.4932\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 62.8397\n",
      "MAE: 6.3980\n",
      "R²:  0.5836\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023658 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47485\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 49.012125\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 44.9957\n",
      "MAE: 5.2538\n",
      "R²:  0.7145\n",
      "LightGBM Performance on Control:\n",
      "MSE: 19.0118\n",
      "MAE: 2.7393\n",
      "R²:  0.8740\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  302.7841 ± 8.2291\n",
      "Mean MAE:  14.0083 ± 0.1669\n",
      "Mean R²:   -1.0104 ± 0.0533\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  47.9030 ± 5.2522\n",
      "Mean MAE:  5.4584 ± 0.2967\n",
      "Mean R²:   0.6819 ± 0.0347\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  68.7285 ± 7.7944\n",
      "Mean MAE:  6.5363 ± 0.3810\n",
      "Mean R²:   0.5444 ± 0.0446\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.1808 ± 2.8084\n",
      "Mean MAE:  2.9531 ± 0.2532\n",
      "Mean R²:   0.8596 ± 0.0186\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  57.3230 ± 6.9640\n",
      "Mean MAE:  6.0005 ± 0.4136\n",
      "Mean R²:   0.6201 ± 0.0461\n",
      "\n",
      "=== Fold 4 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 302.9589\n",
      "MAE: 13.8534\n",
      "R²:  -0.9116\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 89.4946\n",
      "MAE: 7.6609\n",
      "R²:  0.4353\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 79.3612\n",
      "MAE: 7.2322\n",
      "R²:  0.4741\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024751 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 47482\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 48.960625\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 43.0982\n",
      "MAE: 5.1734\n",
      "R²:  0.7281\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.6500\n",
      "MAE: 2.6942\n",
      "R²:  0.8764\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  302.7966 ± 7.9299\n",
      "Mean MAE:  13.9972 ± 0.1657\n",
      "Mean R²:   -1.0033 ± 0.0573\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  47.5598 ± 5.2102\n",
      "Mean MAE:  5.4380 ± 0.2951\n",
      "Mean R²:   0.6852 ± 0.0355\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  70.2118 ± 9.2204\n",
      "Mean MAE:  6.6166 ± 0.4676\n",
      "Mean R²:   0.5366 ± 0.0514\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  21.0000 ± 2.7836\n",
      "Mean MAE:  2.9346 ± 0.2530\n",
      "Mean R²:   0.8608 ± 0.0184\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  58.8972 ± 8.7890\n",
      "Mean MAE:  6.0884 ± 0.5094\n",
      "Mean R²:   0.6097 ± 0.0582\n",
      "\n",
      "=== Fold 5 ===\n",
      "Random Baseline Performance:\n",
      "MSE: 305.7808\n",
      "MAE: 13.9542\n",
      "R²:  -1.0941\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "MLP Performance on Validation:\n",
      "MSE: 73.1299\n",
      "MAE: 6.8987\n",
      "R²:  0.4992\n",
      "\u001b[1m434/434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "MLP Performance on Control:\n",
      "MSE: 65.7693\n",
      "MAE: 6.5616\n",
      "R²:  0.5642\n",
      "CUDA memory cleared and model deleted.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.027938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 47484\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score 48.778000\n",
      "\n",
      "LightGBM Performance on Validation:\n",
      "MSE: 41.7407\n",
      "MAE: 5.1034\n",
      "R²:  0.7141\n",
      "LightGBM Performance on Control:\n",
      "MSE: 18.4915\n",
      "MAE: 2.7096\n",
      "R²:  0.8775\n",
      "CUDA memory cleared and model deleted.\n",
      "\n",
      " Random Classifier Performance Validation:\n",
      "Mean MSE:  302.9956 ± 7.6971\n",
      "Mean MAE:  13.9943 ± 0.1604\n",
      "Mean R²:   -1.0094 ± 0.0598\n",
      "\n",
      " LGBM Classifier Performance Validation:\n",
      "Mean MSE:  47.1718 ± 5.2386\n",
      "Mean MAE:  5.4157 ± 0.2971\n",
      "Mean R²:   0.6872 ± 0.0351\n",
      "\n",
      " MLP Classifier Performance Validation:\n",
      "Mean MSE:  70.4063 ± 8.9374\n",
      "Mean MAE:  6.6354 ± 0.4572\n",
      "Mean R²:   0.5341 ± 0.0505\n",
      "\n",
      " LGBM Classifier Performance Control:\n",
      "Mean MSE:  20.8328 ± 2.7611\n",
      "Mean MAE:  2.9196 ± 0.2507\n",
      "Mean R²:   0.8619 ± 0.0183\n",
      "\n",
      " MLP Classifier Performance Control:\n",
      "Mean MSE:  59.3553 ± 8.6623\n",
      "Mean MAE:  6.1200 ± 0.5061\n",
      "Mean R²:   0.6067 ± 0.0574\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# K-Fold Cross-Validation Setup\n",
    "###############################################################################\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "###############################################################################\n",
    "# Training & Evaluation\n",
    "###############################################################################\n",
    "mlp_results = []\n",
    "lgb_results = []\n",
    "# tabpfn_results = []\n",
    "random_results = []\n",
    "\n",
    "mlp_results_eval = []\n",
    "lgb_results_eval = []\n",
    "# tabpfn_results_eval = []\n",
    "result_dict = {}\n",
    "\n",
    "model_dict = {}\n",
    "best_mse_mlp = float('inf')\n",
    "best_mse_lgb = float('inf')\n",
    "# best_mse_tab = float('inf')\n",
    "deconfounding_strategies = [\"BE\", \"Correlation\", \"PCA\" \"Nothing\"]\n",
    "for deconfounding_strategy in deconfounding_strategies:\n",
    "    print(f\"\\n=== Deconfounding Strategy: {deconfounding_strategy} ===\")\n",
    "    for fold, (train_index, val_index) in enumerate(kf.split(X), 1):\n",
    "        print(f\"\\n=== Fold {fold} ===\")\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "        # Scale features\n",
    "        df_columns = X.columns\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled   = scaler.transform(X_val)\n",
    "        X_control_scaled = scaler.fit_transform(X_control)\n",
    "\n",
    "        if deconfounding_strategy == \"BE\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled = feature_extration_with_BE(X_train_scaled, X_val_scaled, X_control_scaled, y_train, df_columns=df_columns)\n",
    "        elif deconfounding_strategy == \"PCA\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled= feature_extration_with_PCA(X_train_scaled, X_val_scaled, X_control_scaled,  n_components=50)\n",
    "        elif deconfounding_strategy == \"Correlation\":\n",
    "            X_train_scaled, X_val_scaled, X_control_scaled = feature_extraction_with_Pearson(X_train_scaled, X_val_scaled, X_control_scaled, y_train, threshold=0.6, df_columns=df_columns)\n",
    "\n",
    "        # -------------------------------\n",
    "        # Random Baseline\n",
    "        # -------------------------------\n",
    "        # We'll generate random predictions from a normal distribution \n",
    "        # matching the train target's mean and std\n",
    "        random_predictions = np.random.normal(loc=y_train.mean(), scale=y_train.std(), size=len(y_val))\n",
    "        random_perf = evaluate_regression_performance(y_val, random_predictions)\n",
    "        print(\"Random Baseline Performance:\")\n",
    "        print_regression_performance(random_perf)\n",
    "        random_results.append(random_perf)\n",
    "        \n",
    "        # -------------------------------\n",
    "        # MLP\n",
    "        # -------------------------------\n",
    "        # KerasRegressor or direct model\n",
    "        mlp_model = create_mlp_model(input_shape=X_train_scaled.shape[1])\n",
    "        mlp_model.fit(X_train_scaled, y_train, \n",
    "                    epochs=10, \n",
    "                    batch_size=32,\n",
    "                    verbose=0)\n",
    "        \n",
    "        y_pred_mlp = mlp_model.predict(X_val_scaled).ravel()  # ensure shape (n,)\n",
    "        mlp_perf = evaluate_regression_performance(y_val, y_pred_mlp)\n",
    "        print(\"\\nMLP Performance on Validation:\")\n",
    "        print_regression_performance(mlp_perf)\n",
    "        mlp_results.append(mlp_perf)\n",
    "        \n",
    "        # Evaluate on control data\n",
    "        y_pred_mlp_ctrl = mlp_model.predict(X_control_scaled).ravel()\n",
    "        mlp_perf_ctrl = evaluate_regression_performance(y_control, y_pred_mlp_ctrl)\n",
    "        print(\"MLP Performance on Control:\")\n",
    "        print_regression_performance(mlp_perf_ctrl)\n",
    "        mlp_results_eval.append(mlp_perf_ctrl)\n",
    "        \n",
    "        # Keep best MLP model based on MSE\n",
    "        if mlp_perf['mse'] < best_mse_mlp:\n",
    "            best_mse_mlp = mlp_perf['mse']\n",
    "            model_dict[\"mlp\"] = mlp_model\n",
    "        \n",
    "        # Clean up\n",
    "        clean_up_cuda(mlp_model)\n",
    "\n",
    "        # -------------------------------\n",
    "        # (Hypothetical) TabPFN Regressor\n",
    "        # -------------------------------\n",
    "        # NOTE: If TabPFNClassifier is the only option, you must skip or replace this.\n",
    "        # try:\n",
    "            # tabclf = TabPFNRegressor()  # Ideally TabPFNRegressor() if available\n",
    "        #     tabclf.fit(X_train_scaled, y_train)\n",
    "        #     y_pred_tab = tabclf.predict(X_val_scaled)  # For regression, this should be continuous\n",
    "        #     tab_perf = evaluate_regression_performance(y_val, y_pred_tab)\n",
    "        #     print(\"\\nTabPFN Regressor Performance on Validation:\")\n",
    "        #     print_regression_performance(tab_perf)\n",
    "        #     tabpfn_results.append(tab_perf)\n",
    "            \n",
    "        #     # Evaluate on control data\n",
    "        #     y_pred_tab_ctrl = tabclf.predict(X_control_scaled)\n",
    "        #     tab_perf_ctrl = evaluate_regression_performance(y_control, y_pred_tab_ctrl)\n",
    "        #     print(\"TabPFN Regressor Performance on Control:\")\n",
    "        #     print_regression_performance(tab_perf_ctrl)\n",
    "        #     tabpfn_results_eval.append(tab_perf_ctrl)\n",
    "            \n",
    "        #     if tab_perf['mse'] < best_mse_tab:\n",
    "        #         best_mse_tab = tab_perf['mse']\n",
    "        #         model_dict[\"tabpfn\"] = tabclf\n",
    "            \n",
    "        #     clean_up_cuda(tabclf)\n",
    "        # except Exception as e:\n",
    "        #     print(\"TabPFN Regressor not available or failed. Skipping...\")\n",
    "        #     print(e)\n",
    "        \n",
    "        # -------------------------------\n",
    "        # LightGBM\n",
    "        # -------------------------------\n",
    "        lgb_train = lgb.Dataset(X_train_scaled, label=y_train)\n",
    "        lgb_eval  = lgb.Dataset(X_val_scaled,   label=y_val, reference=lgb_train)\n",
    "        \n",
    "        lgb_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'num_leaves': 31,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.9,\n",
    "            'seed': 42\n",
    "        }\n",
    "        \n",
    "        lgbclf = lgb.train(\n",
    "            params=lgb_params, \n",
    "            train_set=lgb_train, \n",
    "            valid_sets=[lgb_train, lgb_eval], \n",
    "            num_boost_round=1000\n",
    "        )\n",
    "        \n",
    "        y_pred_lgb = lgbclf.predict(X_val_scaled)\n",
    "        lgb_perf = evaluate_regression_performance(y_val, y_pred_lgb)\n",
    "        print(\"\\nLightGBM Performance on Validation:\")\n",
    "        print_regression_performance(lgb_perf)\n",
    "        lgb_results.append(lgb_perf)\n",
    "        \n",
    "        # Evaluate on control data\n",
    "        y_pred_lgb_ctrl = lgbclf.predict(X_control_scaled)\n",
    "        lgb_perf_ctrl = evaluate_regression_performance(y_control, y_pred_lgb_ctrl)\n",
    "        print(\"LightGBM Performance on Control:\")\n",
    "        print_regression_performance(lgb_perf_ctrl)\n",
    "        lgb_results_eval.append(lgb_perf_ctrl)\n",
    "        \n",
    "        if lgb_perf['mse'] < best_mse_lgb:\n",
    "            best_mse_lgb = lgb_perf['mse']\n",
    "            model_dict[\"lgb\"] = lgbclf\n",
    "        \n",
    "        clean_up_cuda(lgbclf)\n",
    "\n",
    "        random_summary = aggregate_cv_metrics_and_print(random_results, \"Random\")\n",
    "        # tabpfn_summary = aggregate_cv_metrics_and_print(tabpfn_results, \"TabPFN\")\n",
    "        lgb_summary = aggregate_cv_metrics_and_print(lgb_results, \"LGBM\")\n",
    "        mlp_summary = aggregate_cv_metrics_and_print(mlp_results, \"MLP\")\n",
    "\n",
    "        # tabpfn_eval_summary = aggregate_cv_metrics_and_print(tabpfn_results_eval, \"TabPFN\", \"Control\")\n",
    "        lgb_eval_summary = aggregate_cv_metrics_and_print(lgb_results_eval, \"LGBM\", \"Control\")\n",
    "        mlp_eval_summary = aggregate_cv_metrics_and_print(mlp_results_eval, \"MLP\", \"Control\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    result_dict[deconfounding_strategy] = {\n",
    "        # \"TabPFN\": {\n",
    "        #         \"results\": tabpfn_summary,\n",
    "        #         \"results_eval\": tabpfn_eval_summary,\n",
    "        #         \"cv_results\": tabpfn_results,\n",
    "        #         \"cv_results_eval\": tabpfn_results_eval\n",
    "        # },\n",
    "        \"LGBM\": {\n",
    "                \"results\": lgb_summary,\n",
    "                \"results_eval\": lgb_eval_summary,\n",
    "                \"cv_results\": lgb_results,\n",
    "                \"cv_results_eval\": lgb_results_eval\n",
    "        },\n",
    "        \"Random\": {\n",
    "                \"results\": random_summary,\n",
    "                \"cv_results\": random_results\n",
    "        },\n",
    "        \"MLP\": {\n",
    "                \"results\": mlp_summary,\n",
    "                \"results_eval\": mlp_eval_summary,\n",
    "                \"cv_results\": mlp_results,\n",
    "                \"cv_results_eval\": mlp_results_eval\n",
    "        }\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BE': {'LGBM': {'results': {'mean_mse': 43.65000615115399,\n",
       "    'std_mse': 1.2772158273380378,\n",
       "    'mean_mae': 5.21224345649815,\n",
       "    'std_mae': 0.08298314328253323,\n",
       "    'mean_r2': 0.7104260381354648,\n",
       "    'std_r2': 0.01227417591945383},\n",
       "   'results_eval': {'mean_mse': 19.00884284578549,\n",
       "    'std_mse': 0.26182934454275136,\n",
       "    'mean_mae': 2.769580824272991,\n",
       "    'std_mae': 0.018826497451006213,\n",
       "    'mean_r2': 0.8740328346331088,\n",
       "    'std_r2': 0.0017350819620897612},\n",
       "   'cv_results': [{'mse': 42.82771570629918,\n",
       "     'mae': 5.219730078749018,\n",
       "     'r2': 0.7053114828345186},\n",
       "    {'mse': 45.589120505202374,\n",
       "     'mae': 5.346681880851559,\n",
       "     'r2': 0.6902368982449067},\n",
       "    {'mse': 44.552988223187725,\n",
       "     'mae': 5.218030524601489,\n",
       "     'r2': 0.717293838266856},\n",
       "    {'mse': 43.297708882429475,\n",
       "     'mae': 5.190148129031788,\n",
       "     'r2': 0.7267997223530699},\n",
       "    {'mse': 41.98249743865116,\n",
       "     'mae': 5.086626669256897,\n",
       "     'r2': 0.7124882489779722},\n",
       "    {'mse': 52.89491412120471,\n",
       "     'mae': 5.770026511957709,\n",
       "     'r2': 0.6360412048387476},\n",
       "    {'mse': 54.09404994982421,\n",
       "     'mae': 5.848277149945044,\n",
       "     'r2': 0.632448695801439},\n",
       "    {'mse': 55.655481184043445,\n",
       "     'mae': 5.821046267516618,\n",
       "     'r2': 0.6468441715708924},\n",
       "    {'mse': 56.20369977194816,\n",
       "     'mae': 5.916585230581503,\n",
       "     'r2': 0.645365383554693},\n",
       "    {'mse': 52.96866050533886,\n",
       "     'mae': 5.765941417164514,\n",
       "     'r2': 0.637250919780665},\n",
       "    {'mse': 43.2891943323171,\n",
       "     'mae': 5.232469049909967,\n",
       "     'r2': 0.7021361453279054},\n",
       "    {'mse': 44.386905888269844,\n",
       "     'mae': 5.289315537465982,\n",
       "     'r2': 0.6984055517435817},\n",
       "    {'mse': 44.99566086105279,\n",
       "     'mae': 5.253750712525001,\n",
       "     'r2': 0.7144849069842178},\n",
       "    {'mse': 43.098193676619935,\n",
       "     'mae': 5.173427352350957,\n",
       "     'r2': 0.7280586252148809},\n",
       "    {'mse': 41.74073964033656,\n",
       "     'mae': 5.103376049584247,\n",
       "     'r2': 0.7141438962633258}],\n",
       "   'cv_results_eval': [{'mse': 18.920428070699813,\n",
       "     'mae': 2.7615102592950165,\n",
       "     'r2': 0.8746187387138804},\n",
       "    {'mse': 19.41224277934082,\n",
       "     'mae': 2.792543753456583,\n",
       "     'r2': 0.8713595974165455},\n",
       "    {'mse': 19.198555926052357,\n",
       "     'mae': 2.789985056461091,\n",
       "     'r2': 0.8727756503243049},\n",
       "    {'mse': 18.823101310656302,\n",
       "     'mae': 2.7435510779335694,\n",
       "     'r2': 0.875263700439141},\n",
       "    {'mse': 18.689886142178167,\n",
       "     'mae': 2.7603139742186946,\n",
       "     'r2': 0.8761464862716718},\n",
       "    {'mse': 24.200925569662804,\n",
       "     'mae': 3.2364050285864394,\n",
       "     'r2': 0.8396261141197535},\n",
       "    {'mse': 24.230191902134965,\n",
       "     'mae': 3.2195394141300104,\n",
       "     'r2': 0.8394321729644654},\n",
       "    {'mse': 25.28521812862991,\n",
       "     'mae': 3.3078309755900137,\n",
       "     'r2': 0.8324407603773093},\n",
       "    {'mse': 24.874127106100335,\n",
       "     'mae': 3.2744223452093455,\n",
       "     'r2': 0.8351649646456037},\n",
       "    {'mse': 24.9636842130744,\n",
       "     'mae': 3.316753761804627,\n",
       "     'r2': 0.8345714905979984},\n",
       "    {'mse': 18.855158467007357,\n",
       "     'mae': 2.7210816461823946,\n",
       "     'r2': 0.8750512651453135},\n",
       "    {'mse': 18.884707570730782,\n",
       "     'mae': 2.726434438621113,\n",
       "     'r2': 0.8748554501309347},\n",
       "    {'mse': 19.01181370535167,\n",
       "     'mae': 2.7393179993314756,\n",
       "     'r2': 0.8740131474400854},\n",
       "    {'mse': 18.650034054690163,\n",
       "     'mae': 2.694232932239966,\n",
       "     'r2': 0.8764105767550087},\n",
       "    {'mse': 18.491546549410472,\n",
       "     'mae': 2.709567403722354,\n",
       "     'r2': 0.8774608364656137}]},\n",
       "  'Random': {'results': {'mean_mse': 304.32798757753307,\n",
       "    'std_mse': 10.148186808433511,\n",
       "    'mean_mae': 14.002033226393035,\n",
       "    'std_mae': 0.20666472053733742,\n",
       "    'mean_r2': -1.0173446645603312,\n",
       "    'std_r2': 0.04354977514108109},\n",
       "   'cv_results': [{'mse': 296.4940621253477,\n",
       "     'mae': 13.80401778857771,\n",
       "     'r2': -1.0401133722674305},\n",
       "    {'mse': 293.4790360186278,\n",
       "     'mae': 13.794847288245586,\n",
       "     'r2': -0.9940936673005318},\n",
       "    {'mse': 306.6509472800333,\n",
       "     'mae': 14.10161878516028,\n",
       "     'r2': -0.9458203760225392},\n",
       "    {'mse': 322.4235589366754,\n",
       "     'mae': 14.348228840933572,\n",
       "     'r2': -1.034431107211705},\n",
       "    {'mse': 302.5923335269814,\n",
       "     'mae': 13.96145342904804,\n",
       "     'r2': -1.0722647999994495},\n",
       "    {'mse': 297.6961373604861,\n",
       "     'mae': 13.977272220885657,\n",
       "     'r2': -1.0483845995024659},\n",
       "    {'mse': 307.29266521604654,\n",
       "     'mae': 14.143725592986296,\n",
       "     'r2': -1.0879527411161556},\n",
       "    {'mse': 303.5847801454113,\n",
       "     'mae': 14.093258377603762,\n",
       "     'r2': -0.9263643445321497},\n",
       "    {'mse': 314.5977296112529,\n",
       "     'mae': 14.241053695471091,\n",
       "     'r2': -0.9850516180953524},\n",
       "    {'mse': 290.88555333964524,\n",
       "     'mae': 13.801256497879985,\n",
       "     'r2': -0.9920924168436003},\n",
       "    {'mse': 298.97487650891713,\n",
       "     'mae': 13.860764631356911,\n",
       "     'r2': -1.0571833350240327},\n",
       "    {'mse': 299.5764183752644,\n",
       "     'mae': 13.95615419519499,\n",
       "     'r2': -1.035523377951848},\n",
       "    {'mse': 301.9457366915921,\n",
       "     'mae': 14.023602313644068,\n",
       "     'r2': -0.9159639718024506},\n",
       "    {'mse': 302.9589484387516,\n",
       "     'mae': 13.853360187636564,\n",
       "     'r2': -0.9116131307048665},\n",
       "    {'mse': 305.7808208651894,\n",
       "     'mae': 13.954225329227945,\n",
       "     'r2': -1.094100746730807}]},\n",
       "  'MLP': {'results': {'mean_mse': 63.693210714977205,\n",
       "    'std_mse': 5.5353140741621685,\n",
       "    'mean_mae': 6.307818926811218,\n",
       "    'std_mae': 0.355801972285107,\n",
       "    'mean_r2': 0.578351616859436,\n",
       "    'std_r2': 0.02672552155737815},\n",
       "   'results_eval': {'mean_mse': 54.298876288043786,\n",
       "    'std_mse': 7.937083793718648,\n",
       "    'mean_mae': 5.847631807064917,\n",
       "    'std_mae': 0.4981305812722962,\n",
       "    'mean_r2': 0.6401740312576294,\n",
       "    'std_r2': 0.05259720096648417},\n",
       "   'cv_results': [{'mse': 58.10191623555477,\n",
       "     'mae': 6.132887510299683,\n",
       "     'r2': 0.6002129316329956},\n",
       "    {'mse': 59.36013281166988,\n",
       "     'mae': 5.96095097732544,\n",
       "     'r2': 0.5966674089431763},\n",
       "    {'mse': 62.97652827986074,\n",
       "     'mae': 6.120618876457215,\n",
       "     'r2': 0.6003892421722412},\n",
       "    {'mse': 73.8111704525179,\n",
       "     'mae': 6.9751068201065065,\n",
       "     'r2': 0.5342656373977661},\n",
       "    {'mse': 64.21630579528272,\n",
       "     'mae': 6.349530449867249,\n",
       "     'r2': 0.560222864151001},\n",
       "    {'mse': 64.80840075069034,\n",
       "     'mae': 6.31576212310791,\n",
       "     'r2': 0.5540670156478882},\n",
       "    {'mse': 77.96980344665062,\n",
       "     'mae': 6.985701063156128,\n",
       "     'r2': 0.4702208638191223},\n",
       "    {'mse': 81.93203235419877,\n",
       "     'mae': 6.994126333236695,\n",
       "     'r2': 0.48010915517807007},\n",
       "    {'mse': 71.67755267148259,\n",
       "     'mae': 6.629533333778381,\n",
       "     'r2': 0.547728419303894},\n",
       "    {'mse': 72.80324852735255,\n",
       "     'mae': 6.777009296417236,\n",
       "     'r2': 0.5014162659645081},\n",
       "    {'mse': 66.03900237386613,\n",
       "     'mae': 6.579191339492798,\n",
       "     'r2': 0.5455995202064514},\n",
       "    {'mse': 59.89992816732043,\n",
       "     'mae': 6.095466745376587,\n",
       "     'r2': 0.5929996967315674},\n",
       "    {'mse': 79.87471438819685,\n",
       "     'mae': 7.055834794998169,\n",
       "     'r2': 0.4931636452674866},\n",
       "    {'mse': 89.49456361971392,\n",
       "     'mae': 7.660850832462311,\n",
       "     'r2': 0.4353064298629761},\n",
       "    {'mse': 73.12985792079441,\n",
       "     'mae': 6.898727297782898,\n",
       "     'r2': 0.49917954206466675}],\n",
       "   'cv_results_eval': [{'mse': 50.980583499297886,\n",
       "     'mae': 5.714956482875318,\n",
       "     'r2': 0.6621636152267456},\n",
       "    {'mse': 47.14451882955644,\n",
       "     'mae': 5.371274849634666,\n",
       "     'r2': 0.6875842809677124},\n",
       "    {'mse': 46.78166968539649,\n",
       "     'mae': 5.374844763922138,\n",
       "     'r2': 0.6899887919425964},\n",
       "    {'mse': 67.44499298987648,\n",
       "     'mae': 6.694693044302324,\n",
       "     'r2': 0.5530577898025513},\n",
       "    {'mse': 59.14261643609165,\n",
       "     'mae': 6.08238989459014,\n",
       "     'r2': 0.6080756783485413},\n",
       "    {'mse': 55.59823281323481,\n",
       "     'mae': 5.876200455917365,\n",
       "     'r2': 0.6315634846687317},\n",
       "    {'mse': 65.20378556811559,\n",
       "     'mae': 6.404751284534884,\n",
       "     'r2': 0.5679097175598145},\n",
       "    {'mse': 62.38985073190684,\n",
       "     'mae': 6.180469574338333,\n",
       "     'r2': 0.5865570306777954},\n",
       "    {'mse': 58.60811536321041,\n",
       "     'mae': 6.032380058187479,\n",
       "     'r2': 0.6116176843643188},\n",
       "    {'mse': 63.677342334247044,\n",
       "     'mae': 6.318940488471089,\n",
       "     'r2': 0.5780251026153564},\n",
       "    {'mse': 58.336715018670866,\n",
       "     'mae': 6.163618920774156,\n",
       "     'r2': 0.6134161949157715},\n",
       "    {'mse': 47.051494849838676,\n",
       "     'mae': 5.393540918492247,\n",
       "     'r2': 0.6882007122039795},\n",
       "    {'mse': 62.83970079836421,\n",
       "     'mae': 6.397992477076345,\n",
       "     'r2': 0.583575963973999},\n",
       "    {'mse': 79.36120614130911,\n",
       "     'mae': 7.232168697339047,\n",
       "     'r2': 0.4740917682647705},\n",
       "    {'mse': 65.76925068419322,\n",
       "     'mae': 6.561631666554612,\n",
       "     'r2': 0.5641624927520752}]}},\n",
       " 'Correlation': {'LGBM': {'results': {'mean_mse': 49.00668362881292,\n",
       "    'std_mse': 5.516582391821467,\n",
       "    'mean_mae': 5.518309385965614,\n",
       "    'std_mae': 0.31410951971627415,\n",
       "    'mean_r2': 0.675008056622376,\n",
       "    'std_r2': 0.03667785796158815},\n",
       "   'results_eval': {'mean_mse': 21.85983611485299,\n",
       "    'std_mse': 2.8729068495242966,\n",
       "    'mean_mae': 3.0202855646685394,\n",
       "    'std_mae': 0.2525089101405143,\n",
       "    'mean_r2': 0.8551399675870675,\n",
       "    'std_r2': 0.01903808322966581},\n",
       "   'cv_results': [{'mse': 42.82771570629918,\n",
       "     'mae': 5.219730078749018,\n",
       "     'r2': 0.7053114828345186},\n",
       "    {'mse': 45.589120505202374,\n",
       "     'mae': 5.346681880851559,\n",
       "     'r2': 0.6902368982449067},\n",
       "    {'mse': 44.552988223187725,\n",
       "     'mae': 5.218030524601489,\n",
       "     'r2': 0.717293838266856},\n",
       "    {'mse': 43.297708882429475,\n",
       "     'mae': 5.190148129031788,\n",
       "     'r2': 0.7267997223530699},\n",
       "    {'mse': 41.98249743865116,\n",
       "     'mae': 5.086626669256897,\n",
       "     'r2': 0.7124882489779722},\n",
       "    {'mse': 52.89491412120471,\n",
       "     'mae': 5.770026511957709,\n",
       "     'r2': 0.6360412048387476},\n",
       "    {'mse': 54.09404994982421,\n",
       "     'mae': 5.848277149945044,\n",
       "     'r2': 0.632448695801439},\n",
       "    {'mse': 55.655481184043445,\n",
       "     'mae': 5.821046267516618,\n",
       "     'r2': 0.6468441715708924},\n",
       "    {'mse': 56.20369977194816,\n",
       "     'mae': 5.916585230581503,\n",
       "     'r2': 0.645365383554693},\n",
       "    {'mse': 52.96866050533886,\n",
       "     'mae': 5.765941417164514,\n",
       "     'r2': 0.637250919780665},\n",
       "    {'mse': 43.2891943323171,\n",
       "     'mae': 5.232469049909967,\n",
       "     'r2': 0.7021361453279054},\n",
       "    {'mse': 44.386905888269844,\n",
       "     'mae': 5.289315537465982,\n",
       "     'r2': 0.6984055517435817},\n",
       "    {'mse': 44.99566086105279,\n",
       "     'mae': 5.253750712525001,\n",
       "     'r2': 0.7144849069842178},\n",
       "    {'mse': 43.098193676619935,\n",
       "     'mae': 5.173427352350957,\n",
       "     'r2': 0.7280586252148809},\n",
       "    {'mse': 41.74073964033656,\n",
       "     'mae': 5.103376049584247,\n",
       "     'r2': 0.7141438962633258}],\n",
       "   'cv_results_eval': [{'mse': 18.920428070699813,\n",
       "     'mae': 2.7615102592950165,\n",
       "     'r2': 0.8746187387138804},\n",
       "    {'mse': 19.41224277934082,\n",
       "     'mae': 2.792543753456583,\n",
       "     'r2': 0.8713595974165455},\n",
       "    {'mse': 19.198555926052357,\n",
       "     'mae': 2.789985056461091,\n",
       "     'r2': 0.8727756503243049},\n",
       "    {'mse': 18.823101310656302,\n",
       "     'mae': 2.7435510779335694,\n",
       "     'r2': 0.875263700439141},\n",
       "    {'mse': 18.689886142178167,\n",
       "     'mae': 2.7603139742186946,\n",
       "     'r2': 0.8761464862716718},\n",
       "    {'mse': 24.200925569662804,\n",
       "     'mae': 3.2364050285864394,\n",
       "     'r2': 0.8396261141197535},\n",
       "    {'mse': 24.230191902134965,\n",
       "     'mae': 3.2195394141300104,\n",
       "     'r2': 0.8394321729644654},\n",
       "    {'mse': 25.28521812862991,\n",
       "     'mae': 3.3078309755900137,\n",
       "     'r2': 0.8324407603773093},\n",
       "    {'mse': 24.874127106100335,\n",
       "     'mae': 3.2744223452093455,\n",
       "     'r2': 0.8351649646456037},\n",
       "    {'mse': 24.9636842130744,\n",
       "     'mae': 3.316753761804627,\n",
       "     'r2': 0.8345714905979984},\n",
       "    {'mse': 18.855158467007357,\n",
       "     'mae': 2.7210816461823946,\n",
       "     'r2': 0.8750512651453135},\n",
       "    {'mse': 18.884707570730782,\n",
       "     'mae': 2.726434438621113,\n",
       "     'r2': 0.8748554501309347},\n",
       "    {'mse': 19.01181370535167,\n",
       "     'mae': 2.7393179993314756,\n",
       "     'r2': 0.8740131474400854},\n",
       "    {'mse': 18.650034054690163,\n",
       "     'mae': 2.694232932239966,\n",
       "     'r2': 0.8764105767550087},\n",
       "    {'mse': 18.491546549410472,\n",
       "     'mae': 2.709567403722354,\n",
       "     'r2': 0.8774608364656137}]},\n",
       "  'Random': {'results': {'mean_mse': 303.56968035605075,\n",
       "    'std_mse': 9.212317443730957,\n",
       "    'mean_mae': 14.026673251679199,\n",
       "    'std_mae': 0.18273865678107196,\n",
       "    'mean_r2': -1.012656904289138,\n",
       "    'std_r2': 0.05016978886130946},\n",
       "   'cv_results': [{'mse': 296.4940621253477,\n",
       "     'mae': 13.80401778857771,\n",
       "     'r2': -1.0401133722674305},\n",
       "    {'mse': 293.4790360186278,\n",
       "     'mae': 13.794847288245586,\n",
       "     'r2': -0.9940936673005318},\n",
       "    {'mse': 306.6509472800333,\n",
       "     'mae': 14.10161878516028,\n",
       "     'r2': -0.9458203760225392},\n",
       "    {'mse': 322.4235589366754,\n",
       "     'mae': 14.348228840933572,\n",
       "     'r2': -1.034431107211705},\n",
       "    {'mse': 302.5923335269814,\n",
       "     'mae': 13.96145342904804,\n",
       "     'r2': -1.0722647999994495},\n",
       "    {'mse': 297.6961373604861,\n",
       "     'mae': 13.977272220885657,\n",
       "     'r2': -1.0483845995024659},\n",
       "    {'mse': 307.29266521604654,\n",
       "     'mae': 14.143725592986296,\n",
       "     'r2': -1.0879527411161556},\n",
       "    {'mse': 303.5847801454113,\n",
       "     'mae': 14.093258377603762,\n",
       "     'r2': -0.9263643445321497},\n",
       "    {'mse': 314.5977296112529,\n",
       "     'mae': 14.241053695471091,\n",
       "     'r2': -0.9850516180953524},\n",
       "    {'mse': 290.88555333964524,\n",
       "     'mae': 13.801256497879985,\n",
       "     'r2': -0.9920924168436003},\n",
       "    {'mse': 298.97487650891713,\n",
       "     'mae': 13.860764631356911,\n",
       "     'r2': -1.0571833350240327},\n",
       "    {'mse': 299.5764183752644,\n",
       "     'mae': 13.95615419519499,\n",
       "     'r2': -1.035523377951848},\n",
       "    {'mse': 301.9457366915921,\n",
       "     'mae': 14.023602313644068,\n",
       "     'r2': -0.9159639718024506},\n",
       "    {'mse': 302.9589484387516,\n",
       "     'mae': 13.853360187636564,\n",
       "     'r2': -0.9116131307048665},\n",
       "    {'mse': 305.7808208651894,\n",
       "     'mae': 13.954225329227945,\n",
       "     'r2': -1.094100746730807}]},\n",
       "  'MLP': {'results': {'mean_mse': 68.76570913252608,\n",
       "    'std_mse': 7.6181229747767345,\n",
       "    'mean_mae': 6.524122678375245,\n",
       "    'std_mae': 0.37674221847860606,\n",
       "    'mean_r2': 0.5445299804210663,\n",
       "    'std_r2': 0.04574128106099801},\n",
       "   'results_eval': {'mean_mse': 57.69717082509337,\n",
       "    'std_mse': 7.0149614835811755,\n",
       "    'mean_mae': 6.005090089677374,\n",
       "    'std_mae': 0.4087765062989337,\n",
       "    'mean_r2': 0.6176543176174164,\n",
       "    'std_r2': 0.046486516647732144},\n",
       "   'cv_results': [{'mse': 58.10191623555477,\n",
       "     'mae': 6.132887510299683,\n",
       "     'r2': 0.6002129316329956},\n",
       "    {'mse': 59.36013281166988,\n",
       "     'mae': 5.96095097732544,\n",
       "     'r2': 0.5966674089431763},\n",
       "    {'mse': 62.97652827986074,\n",
       "     'mae': 6.120618876457215,\n",
       "     'r2': 0.6003892421722412},\n",
       "    {'mse': 73.8111704525179,\n",
       "     'mae': 6.9751068201065065,\n",
       "     'r2': 0.5342656373977661},\n",
       "    {'mse': 64.21630579528272,\n",
       "     'mae': 6.349530449867249,\n",
       "     'r2': 0.560222864151001},\n",
       "    {'mse': 64.80840075069034,\n",
       "     'mae': 6.31576212310791,\n",
       "     'r2': 0.5540670156478882},\n",
       "    {'mse': 77.96980344665062,\n",
       "     'mae': 6.985701063156128,\n",
       "     'r2': 0.4702208638191223},\n",
       "    {'mse': 81.93203235419877,\n",
       "     'mae': 6.994126333236695,\n",
       "     'r2': 0.48010915517807007},\n",
       "    {'mse': 71.67755267148259,\n",
       "     'mae': 6.629533333778381,\n",
       "     'r2': 0.547728419303894},\n",
       "    {'mse': 72.80324852735255,\n",
       "     'mae': 6.777009296417236,\n",
       "     'r2': 0.5014162659645081},\n",
       "    {'mse': 66.03900237386613,\n",
       "     'mae': 6.579191339492798,\n",
       "     'r2': 0.5455995202064514},\n",
       "    {'mse': 59.89992816732043,\n",
       "     'mae': 6.095466745376587,\n",
       "     'r2': 0.5929996967315674},\n",
       "    {'mse': 79.87471438819685,\n",
       "     'mae': 7.055834794998169,\n",
       "     'r2': 0.4931636452674866},\n",
       "    {'mse': 89.49456361971392,\n",
       "     'mae': 7.660850832462311,\n",
       "     'r2': 0.4353064298629761},\n",
       "    {'mse': 73.12985792079441,\n",
       "     'mae': 6.898727297782898,\n",
       "     'r2': 0.49917954206466675}],\n",
       "   'cv_results_eval': [{'mse': 50.980583499297886,\n",
       "     'mae': 5.714956482875318,\n",
       "     'r2': 0.6621636152267456},\n",
       "    {'mse': 47.14451882955644,\n",
       "     'mae': 5.371274849634666,\n",
       "     'r2': 0.6875842809677124},\n",
       "    {'mse': 46.78166968539649,\n",
       "     'mae': 5.374844763922138,\n",
       "     'r2': 0.6899887919425964},\n",
       "    {'mse': 67.44499298987648,\n",
       "     'mae': 6.694693044302324,\n",
       "     'r2': 0.5530577898025513},\n",
       "    {'mse': 59.14261643609165,\n",
       "     'mae': 6.08238989459014,\n",
       "     'r2': 0.6080756783485413},\n",
       "    {'mse': 55.59823281323481,\n",
       "     'mae': 5.876200455917365,\n",
       "     'r2': 0.6315634846687317},\n",
       "    {'mse': 65.20378556811559,\n",
       "     'mae': 6.404751284534884,\n",
       "     'r2': 0.5679097175598145},\n",
       "    {'mse': 62.38985073190684,\n",
       "     'mae': 6.180469574338333,\n",
       "     'r2': 0.5865570306777954},\n",
       "    {'mse': 58.60811536321041,\n",
       "     'mae': 6.032380058187479,\n",
       "     'r2': 0.6116176843643188},\n",
       "    {'mse': 63.677342334247044,\n",
       "     'mae': 6.318940488471089,\n",
       "     'r2': 0.5780251026153564},\n",
       "    {'mse': 58.336715018670866,\n",
       "     'mae': 6.163618920774156,\n",
       "     'r2': 0.6134161949157715},\n",
       "    {'mse': 47.051494849838676,\n",
       "     'mae': 5.393540918492247,\n",
       "     'r2': 0.6882007122039795},\n",
       "    {'mse': 62.83970079836421,\n",
       "     'mae': 6.397992477076345,\n",
       "     'r2': 0.583575963973999},\n",
       "    {'mse': 79.36120614130911,\n",
       "     'mae': 7.232168697339047,\n",
       "     'r2': 0.4740917682647705},\n",
       "    {'mse': 65.76925068419322,\n",
       "     'mae': 6.561631666554612,\n",
       "     'r2': 0.5641624927520752}]}},\n",
       " 'PCANothing': {'LGBM': {'results': {'mean_mse': 47.17183537911504,\n",
       "    'std_mse': 5.238646904154727,\n",
       "    'mean_mae': 5.415695504099486,\n",
       "    'std_mae': 0.29709159477618324,\n",
       "    'mean_r2': 0.6871539794505116,\n",
       "    'std_r2': 0.035050036127363585},\n",
       "   'results_eval': {'mean_mse': 20.832774766381352,\n",
       "    'std_mse': 2.7610629062760195,\n",
       "    'mean_mae': 2.9195660044521796,\n",
       "    'std_mae': 0.2507470686295219,\n",
       "    'mean_r2': 0.8619460634538421,\n",
       "    'std_r2': 0.018296919519242238},\n",
       "   'cv_results': [{'mse': 42.82771570629918,\n",
       "     'mae': 5.219730078749018,\n",
       "     'r2': 0.7053114828345186},\n",
       "    {'mse': 45.589120505202374,\n",
       "     'mae': 5.346681880851559,\n",
       "     'r2': 0.6902368982449067},\n",
       "    {'mse': 44.552988223187725,\n",
       "     'mae': 5.218030524601489,\n",
       "     'r2': 0.717293838266856},\n",
       "    {'mse': 43.297708882429475,\n",
       "     'mae': 5.190148129031788,\n",
       "     'r2': 0.7267997223530699},\n",
       "    {'mse': 41.98249743865116,\n",
       "     'mae': 5.086626669256897,\n",
       "     'r2': 0.7124882489779722},\n",
       "    {'mse': 52.89491412120471,\n",
       "     'mae': 5.770026511957709,\n",
       "     'r2': 0.6360412048387476},\n",
       "    {'mse': 54.09404994982421,\n",
       "     'mae': 5.848277149945044,\n",
       "     'r2': 0.632448695801439},\n",
       "    {'mse': 55.655481184043445,\n",
       "     'mae': 5.821046267516618,\n",
       "     'r2': 0.6468441715708924},\n",
       "    {'mse': 56.20369977194816,\n",
       "     'mae': 5.916585230581503,\n",
       "     'r2': 0.645365383554693},\n",
       "    {'mse': 52.96866050533886,\n",
       "     'mae': 5.765941417164514,\n",
       "     'r2': 0.637250919780665},\n",
       "    {'mse': 43.2891943323171,\n",
       "     'mae': 5.232469049909967,\n",
       "     'r2': 0.7021361453279054},\n",
       "    {'mse': 44.386905888269844,\n",
       "     'mae': 5.289315537465982,\n",
       "     'r2': 0.6984055517435817},\n",
       "    {'mse': 44.99566086105279,\n",
       "     'mae': 5.253750712525001,\n",
       "     'r2': 0.7144849069842178},\n",
       "    {'mse': 43.098193676619935,\n",
       "     'mae': 5.173427352350957,\n",
       "     'r2': 0.7280586252148809},\n",
       "    {'mse': 41.74073964033656,\n",
       "     'mae': 5.103376049584247,\n",
       "     'r2': 0.7141438962633258}],\n",
       "   'cv_results_eval': [{'mse': 18.920428070699813,\n",
       "     'mae': 2.7615102592950165,\n",
       "     'r2': 0.8746187387138804},\n",
       "    {'mse': 19.41224277934082,\n",
       "     'mae': 2.792543753456583,\n",
       "     'r2': 0.8713595974165455},\n",
       "    {'mse': 19.198555926052357,\n",
       "     'mae': 2.789985056461091,\n",
       "     'r2': 0.8727756503243049},\n",
       "    {'mse': 18.823101310656302,\n",
       "     'mae': 2.7435510779335694,\n",
       "     'r2': 0.875263700439141},\n",
       "    {'mse': 18.689886142178167,\n",
       "     'mae': 2.7603139742186946,\n",
       "     'r2': 0.8761464862716718},\n",
       "    {'mse': 24.200925569662804,\n",
       "     'mae': 3.2364050285864394,\n",
       "     'r2': 0.8396261141197535},\n",
       "    {'mse': 24.230191902134965,\n",
       "     'mae': 3.2195394141300104,\n",
       "     'r2': 0.8394321729644654},\n",
       "    {'mse': 25.28521812862991,\n",
       "     'mae': 3.3078309755900137,\n",
       "     'r2': 0.8324407603773093},\n",
       "    {'mse': 24.874127106100335,\n",
       "     'mae': 3.2744223452093455,\n",
       "     'r2': 0.8351649646456037},\n",
       "    {'mse': 24.9636842130744,\n",
       "     'mae': 3.316753761804627,\n",
       "     'r2': 0.8345714905979984},\n",
       "    {'mse': 18.855158467007357,\n",
       "     'mae': 2.7210816461823946,\n",
       "     'r2': 0.8750512651453135},\n",
       "    {'mse': 18.884707570730782,\n",
       "     'mae': 2.726434438621113,\n",
       "     'r2': 0.8748554501309347},\n",
       "    {'mse': 19.01181370535167,\n",
       "     'mae': 2.7393179993314756,\n",
       "     'r2': 0.8740131474400854},\n",
       "    {'mse': 18.650034054690163,\n",
       "     'mae': 2.694232932239966,\n",
       "     'r2': 0.8764105767550087},\n",
       "    {'mse': 18.491546549410472,\n",
       "     'mae': 2.709567403722354,\n",
       "     'r2': 0.8774608364656137}]},\n",
       "  'Random': {'results': {'mean_mse': 302.99557362934814,\n",
       "    'std_mse': 7.697106128618055,\n",
       "    'mean_mae': 13.994322611590162,\n",
       "    'std_mae': 0.16042233136929177,\n",
       "    'mean_r2': -1.009396907007026,\n",
       "    'std_r2': 0.059837897080995885},\n",
       "   'cv_results': [{'mse': 296.4940621253477,\n",
       "     'mae': 13.80401778857771,\n",
       "     'r2': -1.0401133722674305},\n",
       "    {'mse': 293.4790360186278,\n",
       "     'mae': 13.794847288245586,\n",
       "     'r2': -0.9940936673005318},\n",
       "    {'mse': 306.6509472800333,\n",
       "     'mae': 14.10161878516028,\n",
       "     'r2': -0.9458203760225392},\n",
       "    {'mse': 322.4235589366754,\n",
       "     'mae': 14.348228840933572,\n",
       "     'r2': -1.034431107211705},\n",
       "    {'mse': 302.5923335269814,\n",
       "     'mae': 13.96145342904804,\n",
       "     'r2': -1.0722647999994495},\n",
       "    {'mse': 297.6961373604861,\n",
       "     'mae': 13.977272220885657,\n",
       "     'r2': -1.0483845995024659},\n",
       "    {'mse': 307.29266521604654,\n",
       "     'mae': 14.143725592986296,\n",
       "     'r2': -1.0879527411161556},\n",
       "    {'mse': 303.5847801454113,\n",
       "     'mae': 14.093258377603762,\n",
       "     'r2': -0.9263643445321497},\n",
       "    {'mse': 314.5977296112529,\n",
       "     'mae': 14.241053695471091,\n",
       "     'r2': -0.9850516180953524},\n",
       "    {'mse': 290.88555333964524,\n",
       "     'mae': 13.801256497879985,\n",
       "     'r2': -0.9920924168436003},\n",
       "    {'mse': 298.97487650891713,\n",
       "     'mae': 13.860764631356911,\n",
       "     'r2': -1.0571833350240327},\n",
       "    {'mse': 299.5764183752644,\n",
       "     'mae': 13.95615419519499,\n",
       "     'r2': -1.035523377951848},\n",
       "    {'mse': 301.9457366915921,\n",
       "     'mae': 14.023602313644068,\n",
       "     'r2': -0.9159639718024506},\n",
       "    {'mse': 302.9589484387516,\n",
       "     'mae': 13.853360187636564,\n",
       "     'r2': -0.9116131307048665},\n",
       "    {'mse': 305.7808208651894,\n",
       "     'mae': 13.954225329227945,\n",
       "     'r2': -1.094100746730807}]},\n",
       "  'MLP': {'results': {'mean_mse': 70.40634385301017,\n",
       "    'std_mse': 8.937415528498676,\n",
       "    'mean_mae': 6.635419852924347,\n",
       "    'std_mae': 0.4572028604732781,\n",
       "    'mean_r2': 0.5341032425562541,\n",
       "    'std_r2': 0.05050894241010243},\n",
       "   'results_eval': {'mean_mse': 59.355338382887325,\n",
       "    'std_mse': 8.66228606901219,\n",
       "    'mean_mae': 6.119990238467343,\n",
       "    'std_mae': 0.506090121052507,\n",
       "    'mean_r2': 0.6066660205523173,\n",
       "    'std_r2': 0.057402957402811046},\n",
       "   'cv_results': [{'mse': 58.10191623555477,\n",
       "     'mae': 6.132887510299683,\n",
       "     'r2': 0.6002129316329956},\n",
       "    {'mse': 59.36013281166988,\n",
       "     'mae': 5.96095097732544,\n",
       "     'r2': 0.5966674089431763},\n",
       "    {'mse': 62.97652827986074,\n",
       "     'mae': 6.120618876457215,\n",
       "     'r2': 0.6003892421722412},\n",
       "    {'mse': 73.8111704525179,\n",
       "     'mae': 6.9751068201065065,\n",
       "     'r2': 0.5342656373977661},\n",
       "    {'mse': 64.21630579528272,\n",
       "     'mae': 6.349530449867249,\n",
       "     'r2': 0.560222864151001},\n",
       "    {'mse': 64.80840075069034,\n",
       "     'mae': 6.31576212310791,\n",
       "     'r2': 0.5540670156478882},\n",
       "    {'mse': 77.96980344665062,\n",
       "     'mae': 6.985701063156128,\n",
       "     'r2': 0.4702208638191223},\n",
       "    {'mse': 81.93203235419877,\n",
       "     'mae': 6.994126333236695,\n",
       "     'r2': 0.48010915517807007},\n",
       "    {'mse': 71.67755267148259,\n",
       "     'mae': 6.629533333778381,\n",
       "     'r2': 0.547728419303894},\n",
       "    {'mse': 72.80324852735255,\n",
       "     'mae': 6.777009296417236,\n",
       "     'r2': 0.5014162659645081},\n",
       "    {'mse': 66.03900237386613,\n",
       "     'mae': 6.579191339492798,\n",
       "     'r2': 0.5455995202064514},\n",
       "    {'mse': 59.89992816732043,\n",
       "     'mae': 6.095466745376587,\n",
       "     'r2': 0.5929996967315674},\n",
       "    {'mse': 79.87471438819685,\n",
       "     'mae': 7.055834794998169,\n",
       "     'r2': 0.4931636452674866},\n",
       "    {'mse': 89.49456361971392,\n",
       "     'mae': 7.660850832462311,\n",
       "     'r2': 0.4353064298629761},\n",
       "    {'mse': 73.12985792079441,\n",
       "     'mae': 6.898727297782898,\n",
       "     'r2': 0.49917954206466675}],\n",
       "   'cv_results_eval': [{'mse': 50.980583499297886,\n",
       "     'mae': 5.714956482875318,\n",
       "     'r2': 0.6621636152267456},\n",
       "    {'mse': 47.14451882955644,\n",
       "     'mae': 5.371274849634666,\n",
       "     'r2': 0.6875842809677124},\n",
       "    {'mse': 46.78166968539649,\n",
       "     'mae': 5.374844763922138,\n",
       "     'r2': 0.6899887919425964},\n",
       "    {'mse': 67.44499298987648,\n",
       "     'mae': 6.694693044302324,\n",
       "     'r2': 0.5530577898025513},\n",
       "    {'mse': 59.14261643609165,\n",
       "     'mae': 6.08238989459014,\n",
       "     'r2': 0.6080756783485413},\n",
       "    {'mse': 55.59823281323481,\n",
       "     'mae': 5.876200455917365,\n",
       "     'r2': 0.6315634846687317},\n",
       "    {'mse': 65.20378556811559,\n",
       "     'mae': 6.404751284534884,\n",
       "     'r2': 0.5679097175598145},\n",
       "    {'mse': 62.38985073190684,\n",
       "     'mae': 6.180469574338333,\n",
       "     'r2': 0.5865570306777954},\n",
       "    {'mse': 58.60811536321041,\n",
       "     'mae': 6.032380058187479,\n",
       "     'r2': 0.6116176843643188},\n",
       "    {'mse': 63.677342334247044,\n",
       "     'mae': 6.318940488471089,\n",
       "     'r2': 0.5780251026153564},\n",
       "    {'mse': 58.336715018670866,\n",
       "     'mae': 6.163618920774156,\n",
       "     'r2': 0.6134161949157715},\n",
       "    {'mse': 47.051494849838676,\n",
       "     'mae': 5.393540918492247,\n",
       "     'r2': 0.6882007122039795},\n",
       "    {'mse': 62.83970079836421,\n",
       "     'mae': 6.397992477076345,\n",
       "     'r2': 0.583575963973999},\n",
       "    {'mse': 79.36120614130911,\n",
       "     'mae': 7.232168697339047,\n",
       "     'r2': 0.4740917682647705},\n",
       "    {'mse': 65.76925068419322,\n",
       "     'mae': 6.561631666554612,\n",
       "     'r2': 0.5641624927520752}]}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation MLP control: 0.8337\n",
      "Pearson Correlation LGBM control: 0.9373\n",
      "Pearson Correlation MLP-val: 0.7919\n",
      "Pearson Correlation LGBM-val: 0.8451\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate Pearson correlation\n",
    "def pearson_correlation_coefficient(y_true, y_pred):\n",
    "    if len(y_true) <= 1 or len(y_pred) <= 1:\n",
    "        raise ValueError(\"Pearson correlation requires at least two points in each array.\")\n",
    "    \n",
    "    # Convert input to pandas series (if not already)\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_pred = pd.Series(y_pred).astype(float)\n",
    "\n",
    "    # Compute and return the correlation\n",
    "    return y_true.corr(y_pred)\n",
    "# calculate Pearson correlation and print for each model\n",
    "correlation_MLP = pearson_correlation_coefficient(y_control, y_pred_mlp_ctrl)\n",
    "correlation_LGBM = pearson_correlation_coefficient(y_control, y_pred_lgb_ctrl)\n",
    "# correlation_TabPFN = pearson_correlation_coefficient(y_control, y_pred_tab_ctrl)\n",
    "print(f\"Pearson Correlation MLP control: {correlation_MLP:.4f}\")\n",
    "print(f\"Pearson Correlation LGBM control: {correlation_LGBM:.4f}\")\n",
    "# Reset the index to align actual and predicted values\n",
    "y_val = y_val.reset_index(drop=True)\n",
    "y_pred_mlp = pd.Series(y_pred_mlp)\n",
    "y_pred_lgb = pd.Series(y_pred_lgb)\n",
    "# y_pred_tab = pd.Series(y_pred_tab)\n",
    "\n",
    "\n",
    "correlation_MLP_val = pearson_correlation_coefficient(y_val, y_pred_mlp)\n",
    "correlation_LGBM_val = pearson_correlation_coefficient(y_val, y_pred_lgb)\n",
    "# correlation_TabPFN_val = pearson_correlation_coefficient(y_val, y_pred_tab)\n",
    "print(f\"Pearson Correlation MLP-val: {correlation_MLP_val:.4f}\")\n",
    "print(f\"Pearson Correlation LGBM-val: {correlation_LGBM_val:.4f}\")\n",
    "# save the correlarions to a csv file for further analysis\n",
    "correlations = pd.DataFrame({\n",
    "    \"model\": [\"MLP\", \"LGBM\"],\n",
    "    \"correlation_control\": [correlation_MLP, correlation_LGBM],\n",
    "    \"correlation_val\": [correlation_MLP_val, correlation_LGBM_val]\n",
    "})\n",
    "correlations.to_csv(\"correlations.csv\", index=False)\n",
    "# save all actual and predicted values in control and val\n",
    "results = pd.DataFrame({\n",
    "    \"y_val\": y_val,\n",
    "    \"y_pred_mlp\": y_pred_mlp,\n",
    "    \"y_pred_lgb\": y_pred_lgb,\n",
    "    # \"y_pred_tab\": y_pred_tab\n",
    "})\n",
    "results.to_csv(\"results.csv\", index=False)\n",
    "# save all actual and predicted values in control\n",
    "results_control = pd.DataFrame({\n",
    "    \"y_control\": y_control,\n",
    "    \"y_pred_mlp\": y_pred_mlp_ctrl,\n",
    "    \"y_pred_lgb\": y_pred_lgb_ctrl,\n",
    "    # \"y_pred_tab\": y_pred_tab_ctrl\n",
    "})\n",
    "results_control.to_csv(\"results_control.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       49.660247\n",
       "1       58.613685\n",
       "2       44.392155\n",
       "3       55.553261\n",
       "4       55.051011\n",
       "          ...    \n",
       "1995    44.868957\n",
       "1996    67.064476\n",
       "1997    56.040554\n",
       "1998    43.085981\n",
       "1999    54.235907\n",
       "Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Function to calculate Pearson correlation between two values for a row\n",
    "def row_correlation(y_true, y_pred):\n",
    "    if y_true == y_pred:\n",
    "        return 100.0  # Perfect match gives 100%\n",
    "    else:\n",
    "        return 0.0  # Single-row correlation is 0% if not identical\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(\"final_results_with_correlation.csv\")\n",
    "\n",
    "# Ensure numeric conversion\n",
    "df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Calculate row-wise correlations in percentage\n",
    "df[\"Row_Correlation_LGBM\"] = df.apply(lambda row: row_correlation(row[\"Actual\"], row[\"Predicted_LGBM\"]), axis=1)\n",
    "df[\"Row_Correlation_MLP\"] = df.apply(lambda row: row_correlation(row[\"Actual\"], row[\"Predicted_MLP\"]), axis=1)\n",
    "\n",
    "# Calculate overall Pearson correlations and scale them to percentages\n",
    "overall_corr_lgb = df[\"Actual\"].corr(df[\"Predicted_LGBM\"]) * 100\n",
    "overall_corr_mlp = df[\"Actual\"].corr(df[\"Predicted_MLP\"]) * 100\n",
    "\n",
    "# Add overall Pearson correlation as a summary row\n",
    "summary_row = {\n",
    "    \"Actual\": \"Overall Pearson Correlation\",\n",
    "    \"Predicted_LGBM\": overall_corr_lgb,\n",
    "    \"Predicted_MLP\": overall_corr_mlp,\n",
    "    \"Row_Correlation_LGBM\": \"N/A\",\n",
    "    \"Row_Correlation_MLP\": \"N/A\"\n",
    "}\n",
    "df = pd.concat([df, pd.DataFrame([summary_row])], ignore_index=True)\n",
    "\n",
    "# Save the final CSV\n",
    "df.to_csv(\"final_results_with_correlation_scaled.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Deconfounding Strategy: BE ===\n",
      "  LGBM - Results: {'mean_mse': 43.65000615115399, 'std_mse': 1.2772158273380378, 'mean_mae': 5.21224345649815, 'std_mae': 0.08298314328253323, 'mean_r2': 0.7104260381354648, 'std_r2': 0.01227417591945383}\n",
      "  LGBM - Evaluation Results: {'mean_mse': 19.00884284578549, 'std_mse': 0.26182934454275136, 'mean_mae': 2.769580824272991, 'std_mae': 0.018826497451006213, 'mean_r2': 0.8740328346331088, 'std_r2': 0.0017350819620897612}\n",
      "  Random - Results: {'mean_mse': 304.32798757753307, 'std_mse': 10.148186808433511, 'mean_mae': 14.002033226393035, 'std_mae': 0.20666472053733742, 'mean_r2': -1.0173446645603312, 'std_r2': 0.04354977514108109}\n",
      "  MLP - Results: {'mean_mse': 63.693210714977205, 'std_mse': 5.5353140741621685, 'mean_mae': 6.307818926811218, 'std_mae': 0.355801972285107, 'mean_r2': 0.578351616859436, 'std_r2': 0.02672552155737815}\n",
      "  MLP - Evaluation Results: {'mean_mse': 54.298876288043786, 'std_mse': 7.937083793718648, 'mean_mae': 5.847631807064917, 'std_mae': 0.4981305812722962, 'mean_r2': 0.6401740312576294, 'std_r2': 0.05259720096648417}\n",
      "\n",
      "=== Deconfounding Strategy: Correlation ===\n",
      "  LGBM - Results: {'mean_mse': 49.00668362881292, 'std_mse': 5.516582391821467, 'mean_mae': 5.518309385965614, 'std_mae': 0.31410951971627415, 'mean_r2': 0.675008056622376, 'std_r2': 0.03667785796158815}\n",
      "  LGBM - Evaluation Results: {'mean_mse': 21.85983611485299, 'std_mse': 2.8729068495242966, 'mean_mae': 3.0202855646685394, 'std_mae': 0.2525089101405143, 'mean_r2': 0.8551399675870675, 'std_r2': 0.01903808322966581}\n",
      "  Random - Results: {'mean_mse': 303.56968035605075, 'std_mse': 9.212317443730957, 'mean_mae': 14.026673251679199, 'std_mae': 0.18273865678107196, 'mean_r2': -1.012656904289138, 'std_r2': 0.05016978886130946}\n",
      "  MLP - Results: {'mean_mse': 68.76570913252608, 'std_mse': 7.6181229747767345, 'mean_mae': 6.524122678375245, 'std_mae': 0.37674221847860606, 'mean_r2': 0.5445299804210663, 'std_r2': 0.04574128106099801}\n",
      "  MLP - Evaluation Results: {'mean_mse': 57.69717082509337, 'std_mse': 7.0149614835811755, 'mean_mae': 6.005090089677374, 'std_mae': 0.4087765062989337, 'mean_r2': 0.6176543176174164, 'std_r2': 0.046486516647732144}\n",
      "\n",
      "=== Deconfounding Strategy: PCANothing ===\n",
      "  LGBM - Results: {'mean_mse': 47.17183537911504, 'std_mse': 5.238646904154727, 'mean_mae': 5.415695504099486, 'std_mae': 0.29709159477618324, 'mean_r2': 0.6871539794505116, 'std_r2': 0.035050036127363585}\n",
      "  LGBM - Evaluation Results: {'mean_mse': 20.832774766381352, 'std_mse': 2.7610629062760195, 'mean_mae': 2.9195660044521796, 'std_mae': 0.2507470686295219, 'mean_r2': 0.8619460634538421, 'std_r2': 0.018296919519242238}\n",
      "  Random - Results: {'mean_mse': 302.99557362934814, 'std_mse': 7.697106128618055, 'mean_mae': 13.994322611590162, 'std_mae': 0.16042233136929177, 'mean_r2': -1.009396907007026, 'std_r2': 0.059837897080995885}\n",
      "  MLP - Results: {'mean_mse': 70.40634385301017, 'std_mse': 8.937415528498676, 'mean_mae': 6.635419852924347, 'std_mae': 0.4572028604732781, 'mean_r2': 0.5341032425562541, 'std_r2': 0.05050894241010243}\n",
      "  MLP - Evaluation Results: {'mean_mse': 59.355338382887325, 'std_mse': 8.66228606901219, 'mean_mae': 6.119990238467343, 'std_mae': 0.506090121052507, 'mean_r2': 0.6066660205523173, 'std_r2': 0.057402957402811046}\n"
     ]
    }
   ],
   "source": [
    "for result, models in result_dict.items():\n",
    "    print(f\"\\n=== Deconfounding Strategy: {result} ===\")\n",
    "    for model, results in models.items():\n",
    "        print(f\"  {model} - Results: {results['results']}\")\n",
    "        if 'results_eval' in results:\n",
    "            print(f\"  {model} - Evaluation Results: {results['results_eval']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pickle\\nsave_dir = \"../98_models/\"\\nwith open(os.path.join(save_dir, \"best_regressor.pkl\"), \"rb\") as f:\\n    loaded_model = pickle.load(f)\\n    # For example, if it\\'s a LightGBM model, you can just do:\\n    y_pred_control = loaded_model.predict(X_control_scaled)\\n    performance_control = evaluate_regression_performance(y_control, y_pred_control)\\n    print(\"\\nLoaded Model Performance on Control Data:\")\\n    print_regression_performance(performance_control)\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "###############################################################################\n",
    "# Example: Load a saved model & evaluate on control data\n",
    "###############################################################################\n",
    "# If you have a saved regression model:\n",
    "\"\"\"\n",
    "import pickle\n",
    "save_dir = \"../98_models/\"\n",
    "with open(os.path.join(save_dir, \"best_regressor.pkl\"), \"rb\") as f:\n",
    "    loaded_model = pickle.load(f)\n",
    "    # For example, if it's a LightGBM model, you can just do:\n",
    "    y_pred_control = loaded_model.predict(X_control_scaled)\n",
    "    performance_control = evaluate_regression_performance(y_control, y_pred_control)\n",
    "    print(\"\\nLoaded Model Performance on Control Data:\")\n",
    "    print_regression_performance(performance_control)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CLIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
