{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.api import OLS, add_constant\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../00_data/UKB_demographics_covariates_subset_healthy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Sex', 'Age', 'Site'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_old_csv_files(output_folder):\n",
    "    csv_files = glob.glob(os.path.join(output_folder, \"*.csv\"))\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            os.remove(file)\n",
    "            print(f\"Deleted: {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted: ../00_data/deconfounded_but_age/aseg.volume.csv\n",
      "Deleted: ../00_data/deconfounded_but_age/aparc.volume.csv\n",
      "Deleted: ../00_data/deconfounded_but_age/aparc.thickness.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnanexus/.local/lib/python3.12/site-packages/scipy/_lib/deprecation.py:234: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns to drop ['Sex', 'Site']\n",
      "Processed and saved: aseg.volume.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnanexus/.local/lib/python3.12/site-packages/scipy/_lib/deprecation.py:234: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns to drop ['Sex', 'Site']\n",
      "Processed and saved: aparc.volume.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dnanexus/.local/lib/python3.12/site-packages/scipy/_lib/deprecation.py:234: SmallSampleWarning: One or more sample arguments is too small; all returned values will be NaN. See documentation for sample size requirements.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns to drop ['Sex', 'Site']\n",
      "Processed and saved: aparc.thickness.csv\n"
     ]
    }
   ],
   "source": [
    "# Define folder paths\n",
    "input_folder = \"../00_data/freesurfer_finished/\"  # Folder containing the brain data files\n",
    "output_folder = \"../00_data/deconfounded_but_age/\"  # Folder to save the corrected files\n",
    "#make sure the output folder exists\n",
    "\n",
    "# Load the covariates data (this file is shared across all analyses)\n",
    "covariates_file = \"../00_data/UKB_demographics_covariates_subset_healthy.csv\"  # Adjust the path as needed\n",
    "covariates_data = pd.read_csv(covariates_file)\n",
    "covariates_data = covariates_data.drop(columns=[\"Age\"])\n",
    "filter_df = \"../00_data/age_label/all_ages_healthy.csv\"\n",
    "filter_df = pd.read_csv(filter_df)\n",
    "covariates_data = covariates_data[covariates_data[\"ID\"].isin(filter_df[\"ID\"])]\n",
    "#covariates_data = covariates_data.drop(columns=[\"p20252_i2\", \"p34\"])\n",
    "covariates_data.rename(\n",
    "    columns={\"ID\": \"ID\", \"basis_sex\": \"Sex\", \"basis_uort\": \"Site\", \"basis_age\": \"Age\"},\n",
    "    inplace=True,\n",
    ")\n",
    "site_mapping = {site: idx for idx, site in enumerate(covariates_data[\"Site\"].unique())}\n",
    "covariates_data[\"Site\"] = covariates_data[\"Site\"].map(site_mapping)\n",
    "sex_mapping = {\"Male\": 0, \"Female\": 1}\n",
    "covariates_data[\"Sex\"] = covariates_data[\"Sex\"].map(sex_mapping)\n",
    "covariates_data[\"ID\"] = covariates_data[\"ID\"].astype(str)\n",
    "\n",
    "# Ensure output folder exists\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "remove_old_csv_files(output_folder)\n",
    "# Process each brain data file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    if file_name.endswith(\".csv\"):\n",
    "        brain_volume_file = os.path.join(input_folder, file_name)\n",
    "        brain_data_filename = os.path.splitext(file_name)[0]\n",
    "\n",
    "        # Load the brain volume data\n",
    "        brain_data = pd.read_csv(brain_volume_file)\n",
    "        brain_data.rename(columns={\"eid\": \"ID\"}, inplace=True)\n",
    "        brain_data[\"ID\"] = brain_data[\"ID\"].astype(str)\n",
    "        if \"sub-\" in brain_data[\"ID\"].iloc[0]:\n",
    "            brain_data[\"ID\"] = brain_data[\"ID\"].str.replace(\"sub-\", \"\")\n",
    "\n",
    "\n",
    "        # Merge brain data with covariates\n",
    "        merged_data = pd.merge(brain_data, covariates_data, on=\"ID\", how=\"inner\")\n",
    "\n",
    "        # Define numerical columns for analysis\n",
    "        numerical_cols = brain_data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "        # Handle NaN values\n",
    "        nan_counts = merged_data.isnull().sum()\n",
    "        if nan_counts.sum() > 0:\n",
    "            merged_data[numerical_cols] = merged_data[numerical_cols].apply(\n",
    "                lambda col: col.fillna(col.mean())\n",
    "            )\n",
    "\n",
    "        # Step 1: Pre-Correction Analysis\n",
    "        pre_correction_results = []\n",
    "        for col in numerical_cols:\n",
    "            if col not in [\"Sex\", \"Site\", \"BMI\"]:\n",
    "                group1 = merged_data[merged_data[\"Sex\"] == 0][col]\n",
    "                group2 = merged_data[merged_data[\"Sex\"] == 1][col]\n",
    "                t_stat, p_value = ttest_ind(group1, group2, equal_var=False)\n",
    "                pre_correction_results.append({\"Variable\": col, \"t-statistic\": t_stat, \"p-value\": p_value})\n",
    "        pre_correction_df = pd.DataFrame(pre_correction_results)\n",
    "\n",
    "        # Identify significant variables\n",
    "        significant_vars = pre_correction_df[pre_correction_df[\"p-value\"] < 0.05][\"Variable\"].tolist()\n",
    "\n",
    "        # Step 2: Residualization\n",
    "        corrected_data = merged_data.copy()\n",
    "        for col in significant_vars:\n",
    "            predictors = [\"Sex\", \"Site\", \"BMI\"]\n",
    "            X = add_constant(merged_data[predictors])\n",
    "            y = merged_data[col]\n",
    "            model = OLS(y, X).fit()\n",
    "            residuals = y - model.predict(X)\n",
    "            corrected_data[col] = residuals + y.mean()\n",
    "\n",
    "        # Save corrected data\n",
    "        #check if columns are in the corrected data\n",
    "        columns_to_drop = [col for col in corrected_data.columns if col not in numerical_cols + [\"ID\"]]\n",
    "        print(\"columns to drop\", columns_to_drop)\n",
    "        corrected_data = corrected_data.drop(columns=columns_to_drop)\n",
    "        corrected_file_name = f\"{brain_data_filename}.csv\"\n",
    "        #remove all old files that are csvs in the output folder\n",
    "        \n",
    "        full_file_path = os.path.join(output_folder, corrected_file_name)\n",
    "        corrected_data.to_csv(full_file_path, index=False)\n",
    "\n",
    "        print(f\"Processed and saved: {corrected_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
